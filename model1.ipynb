{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PhuTuan\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from utils.graph import Graph\n",
    "# from utils.tgcn import ConvTemporalGraphical\n",
    "# from utils.graph import Graph\n",
    "# import os\n",
    "# os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class unit_gcn(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 A,\n",
    "                 adaptive='importance',\n",
    "                 conv_pos='pre',\n",
    "                 with_res=True,\n",
    "                 norm='BN',\n",
    "                 act='ReLU'):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_subsets = A.size(0)\n",
    "\n",
    "        assert adaptive in [None, 'init', 'offset', 'importance']\n",
    "        self.adaptive = adaptive\n",
    "        assert conv_pos in ['pre', 'post']\n",
    "        self.conv_pos = conv_pos\n",
    "        self.with_res = with_res\n",
    "\n",
    "        self.norm_cfg = norm if isinstance(norm, dict) else dict(type=norm)\n",
    "        self.act_cfg = act if isinstance(act, dict) else dict(type=act)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        if self.adaptive == 'init':\n",
    "            self.A = nn.Parameter(A.clone())\n",
    "        else:\n",
    "            self.register_buffer('A', A)\n",
    "\n",
    "        if self.adaptive in ['offset', 'importance']:\n",
    "            self.PA = nn.Parameter(A.clone())\n",
    "            if self.adaptive == 'offset':\n",
    "                nn.init.uniform_(self.PA, -1e-6, 1e-6)\n",
    "            elif self.adaptive == 'importance':\n",
    "                nn.init.constant_(self.PA, 1)\n",
    "\n",
    "        if self.conv_pos == 'pre':\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels * A.size(0), 1)\n",
    "        elif self.conv_pos == 'post':\n",
    "            self.conv = nn.Conv2d(A.size(0) * in_channels, out_channels, 1)\n",
    "\n",
    "        if self.with_res:\n",
    "            if in_channels != out_channels:\n",
    "                self.down = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels, 1),\n",
    "                    nn.BatchNorm2d(out_channels))\n",
    "            else:\n",
    "                self.down = lambda x: x\n",
    "\n",
    "    def forward(self, x, A=None):\n",
    "        \"\"\"Defines the computation performed at every call.\"\"\"\n",
    "        n, c, t, v = x.shape\n",
    "        res = self.down(x) if self.with_res else 0\n",
    "\n",
    "        A_switch = {None: self.A, 'init': self.A}\n",
    "        if hasattr(self, 'PA'):\n",
    "            A_switch.update({'offset': self.A + self.PA, 'importance': self.A * self.PA})\n",
    "        A = A_switch[self.adaptive]\n",
    "\n",
    "        if self.conv_pos == 'pre':\n",
    "            x = self.conv(x)\n",
    "            x = x.view(n, self.num_subsets, -1, t, v)\n",
    "            x = torch.einsum('nkctv,kvw->nctw', (x, A)).contiguous()\n",
    "        elif self.conv_pos == 'post':\n",
    "            x = torch.einsum('nctv,kvw->nkctw', (x, A)).contiguous()\n",
    "            x = x.view(n, -1, t, v)\n",
    "            x = self.conv(x)\n",
    "\n",
    "        return self.act(self.bn(x) + res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class unit_tcn(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=9, stride=1, dilation=1, norm='BN', dropout=0):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.norm_cfg = norm if isinstance(norm, dict) else dict(type=norm)\n",
    "        pad = (kernel_size + (kernel_size - 1) * (dilation - 1) - 1) // 2\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=(kernel_size, 1),\n",
    "            padding=(pad, 0),\n",
    "            stride=(stride, 1),\n",
    "            dilation=(dilation, 1))\n",
    "        self.bn = nn.BatchNorm2d(out_channels) if norm is not None else nn.Identity()\n",
    "        self.drop = nn.Dropout(dropout, inplace=True)\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.drop(self.bn(self.conv(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STGCNBlock(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 A,\n",
    "                 stride=1,\n",
    "                 residual=True):\n",
    "        super().__init__()\n",
    "        self.gcn = unit_gcn(in_channels, out_channels, A)\n",
    "        self.tcn = unit_tcn(out_channels, out_channels, 9, stride=stride)\n",
    "        self.relu = nn.ReLU()\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "        else:\n",
    "            self.residual = unit_tcn(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "\n",
    "    def forward(self, x, A=None):\n",
    "        \"\"\"Defines the computation performed at every call.\"\"\"\n",
    "        res = self.residual(x)\n",
    "        x = self.tcn(self.gcn(x)) + res\n",
    "        return self.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSTGCN(nn.Module):\n",
    "    r\"\"\"Spatial temporal graph convolutional networks.\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input data\n",
    "        num_class (int): Number of classes for the classification task\n",
    "        graph_args (dict): The arguments for building the graph\n",
    "        edge_importance_weighting (bool): If ``True``, adds a learnable\n",
    "            importance weighting to the edges of the graph\n",
    "        **kwargs (optional): Other parameters for graph convolution units\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in_channels, T_{in}, V_{in}, M_{in})`\n",
    "        - Output: :math:`(N, num_class)` where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`T_{in}` is a length of input sequence,\n",
    "            :math:`V_{in}` is the number of graph nodes,\n",
    "            :math:`M_{in}` is the number of instance in a frame.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, num_class,\n",
    "                 edge_importance_weighting=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # load graph\n",
    "        self.graph = Graph()\n",
    "        A = torch.tensor(self.graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        # build networks\n",
    "        spatial_kernel_size = A.size(0)\n",
    "        temporal_kernel_size = 9\n",
    "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * A.size(1))\n",
    "        self.st_gcn_networks = nn.ModuleList((\n",
    "            STGCNBlock(in_channels, 64,A=A ),\n",
    "            STGCNBlock(64, 64, A=A),\n",
    "            STGCNBlock(64, 64, A=A),\n",
    "            STGCNBlock(64, 64, A=A),\n",
    "            STGCNBlock(64, 128, A=A),\n",
    "            STGCNBlock(128, 128, A=A),\n",
    "            STGCNBlock(128, 128, A=A),\n",
    "            STGCNBlock(128, 256, A=A),\n",
    "            STGCNBlock(256, 256, A=A),\n",
    "            STGCNBlock(256, 256, A=A),\n",
    "        ))\n",
    "\n",
    "        # initialize parameters for edge importance weighting\n",
    "        # if edge_importance_weighting:\n",
    "        #     self.edge_importance = nn.ParameterList([\n",
    "        #         nn.Parameter(torch.ones(self.A.size()))\n",
    "        #         for i in self.st_gcn_networks\n",
    "        #     ])\n",
    "        # else:\n",
    "        #     self.edge_importance = [1] * len(self.st_gcn_networks)\n",
    "\n",
    "        # fcn for prediction\n",
    "        self.fcn = nn.Conv2d(256, num_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # data normalization\n",
    "        # have instance of person\n",
    "        # N, C, T, V, M = x.size()\n",
    "        # x = x.permute(0, 4, 3, 1, 2).contiguous()\n",
    "        # x = x.view(N * M, V * C, T)\n",
    "        # x = self.data_bn(x)\n",
    "        # x = x.view(N, M, V, C, T)\n",
    "        # x = x.permute(0, 1, 3, 4, 2).contiguous()\n",
    "        # x = x.view(N * M, C, T, V)\n",
    "\n",
    "        # dont have instance of person\n",
    "\n",
    "        N, C, T, V = x.size()\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()\n",
    "        x = x.view(N , V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, V, C, T)\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()\n",
    "        x = x.view(N , C, T, V)\n",
    "        # forwad\n",
    "        for gcn in (self.st_gcn_networks):\n",
    "            x = gcn(x)\n",
    "\n",
    "        # global pooling\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        # x = x.view(N, M, -1, 1, 1).mean(dim=1)\n",
    "        x = x.view(N, 1, -1, 1, 1).mean(dim=1)\n",
    "\n",
    "        # prediction\n",
    "        x = self.fcn(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelSTGCN(in_channels=3, num_class=5)\n",
    "x = torch.rand(5, 3, 50, 17)\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "out = model(x.to('cuda'))\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
