{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%cd ../content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jieRVaUzqYjM",
        "outputId": "2e12275c-5904-4e52-b9fa-32977198c0e7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install subversion\n",
        "!svn export https://github.com/phutuan123vn/project2/trunk/Data"
      ],
      "metadata": {
        "id": "UZWrI31CsNLb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11922d12-e80d-483f-974c-fec53530cb39"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "subversion is already the newest version (1.13.0-3ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "svn: E155000: Destination directory exists; please remove the directory or use --force to overwrite\n",
            "svn: E155000: 'Data' already exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import pandas as pds\n",
        "import numpy as np\n",
        "import copy"
      ],
      "metadata": {
        "id": "lgth8EOFtFNT"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GRAPH**"
      ],
      "metadata": {
        "id": "tZRgzhEttHVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) OpenMMLab. All rights reserved.\n",
        "\n",
        "def get_hop_distance(num_node, edge, max_hop=1):\n",
        "    adj_mat = np.zeros((num_node, num_node))\n",
        "    for i, j in edge:\n",
        "        adj_mat[i, j] = 1\n",
        "        adj_mat[j, i] = 1\n",
        "\n",
        "    # compute hop steps\n",
        "    hop_dis = np.zeros((num_node, num_node)) + np.inf\n",
        "    transfer_mat = [\n",
        "        np.linalg.matrix_power(adj_mat, d) for d in range(max_hop + 1)\n",
        "    ]\n",
        "    arrive_mat = (np.stack(transfer_mat) > 0)\n",
        "    for d in range(max_hop, -1, -1):\n",
        "        hop_dis[arrive_mat[d]] = d\n",
        "    return hop_dis\n",
        "\n",
        "\n",
        "def normalize_digraph(adj_matrix):\n",
        "    Dl = np.sum(adj_matrix, 0)\n",
        "    num_nodes = adj_matrix.shape[0]\n",
        "    Dn = np.zeros((num_nodes, num_nodes))\n",
        "    for i in range(num_nodes):\n",
        "        if Dl[i] > 0:\n",
        "            Dn[i, i] = Dl[i]**(-1)\n",
        "    norm_matrix = np.dot(adj_matrix, Dn)\n",
        "    return norm_matrix\n",
        "\n",
        "\n",
        "def edge2mat(link, num_node):\n",
        "    A = np.zeros((num_node, num_node))\n",
        "    for i, j in link:\n",
        "        A[j, i] = 1\n",
        "    return A\n",
        "\n",
        "\n",
        "class Graph:\n",
        "    \"\"\"The Graph to model the skeletons extracted by the openpose.\n",
        "\n",
        "    Args:\n",
        "        layout (str): must be one of the following candidates\n",
        "        - openpose: 18 or 25 joints. For more information, please refer to:\n",
        "            https://github.com/CMU-Perceptual-Computing-Lab/openpose#output\n",
        "        - ntu-rgb+d: Is consists of 25 joints. For more information, please\n",
        "            refer to https://github.com/shahroudy/NTURGB-D\n",
        "\n",
        "        strategy (str): must be one of the follow candidates\n",
        "        - uniform: Uniform Labeling\n",
        "        - distance: Distance Partitioning\n",
        "        - spatial: Spatial Configuration\n",
        "        For more information, please refer to the section 'Partition\n",
        "        Strategies' in our paper (https://arxiv.org/abs/1801.07455).\n",
        "\n",
        "        max_hop (int): the maximal distance between two connected nodes.\n",
        "            Default: 1\n",
        "        dilation (int): controls the spacing between the kernel points.\n",
        "            Default: 1\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 layout='coco',\n",
        "                 strategy='spatial',\n",
        "                 max_hop=1,\n",
        "                 dilation=1):\n",
        "        self.max_hop = max_hop\n",
        "        self.dilation = dilation\n",
        "\n",
        "        assert layout in [\n",
        "            'openpose-18', 'openpose-25', 'ntu-rgb+d', 'ntu_edge', 'coco'\n",
        "        ]\n",
        "        assert strategy in ['uniform', 'distance', 'spatial', 'agcn']\n",
        "        self.get_edge(layout)\n",
        "        self.hop_dis = get_hop_distance(\n",
        "            self.num_node, self.edge, max_hop=max_hop)\n",
        "        self.get_adjacency(strategy)\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.A\n",
        "\n",
        "    def get_edge(self, layout):\n",
        "        \"\"\"This method returns the edge pairs of the layout.\"\"\"\n",
        "\n",
        "        if layout == 'openpose-18':\n",
        "            self.num_node = 18\n",
        "            self_link = [(i, i) for i in range(self.num_node)]\n",
        "            neighbor_link = [(4, 3), (3, 2), (7, 6), (6, 5),\n",
        "                             (13, 12), (12, 11), (10, 9), (9, 8), (11, 5),\n",
        "                             (8, 2), (5, 1), (2, 1), (0, 1), (15, 0), (14, 0),\n",
        "                             (17, 15), (16, 14)]\n",
        "            self.edge = self_link + neighbor_link\n",
        "            self.center = 1\n",
        "        elif layout == 'openpose-25':\n",
        "            self.num_node = 25\n",
        "            self_link = [(i, i) for i in range(self.num_node)]\n",
        "            neighbor_link = [(4, 3), (3, 2), (7, 6), (6, 5), (23, 22),\n",
        "                             (22, 11), (24, 11), (11, 10), (10, 9), (9, 8),\n",
        "                             (20, 19), (19, 14), (21, 14), (14, 13), (13, 12),\n",
        "                             (12, 8), (8, 1), (5, 1), (2, 1), (0, 1), (15, 0),\n",
        "                             (16, 0), (17, 15), (18, 16)]\n",
        "            self.self_link = self_link\n",
        "            self.neighbor_link = neighbor_link\n",
        "            self.edge = self_link + neighbor_link\n",
        "            self.center = 1\n",
        "        elif layout == 'ntu-rgb+d':\n",
        "            self.num_node = 25\n",
        "            self_link = [(i, i) for i in range(self.num_node)]\n",
        "            neighbor_1base = [(1, 2), (2, 21), (3, 21),\n",
        "                              (4, 3), (5, 21), (6, 5), (7, 6), (8, 7), (9, 21),\n",
        "                              (10, 9), (11, 10), (12, 11), (13, 1), (14, 13),\n",
        "                              (15, 14), (16, 15), (17, 1), (18, 17), (19, 18),\n",
        "                              (20, 19), (22, 23), (23, 8), (24, 25), (25, 12)]\n",
        "            neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_1base]\n",
        "            self.self_link = self_link\n",
        "            self.neighbor_link = neighbor_link\n",
        "            self.edge = self_link + neighbor_link\n",
        "            self.center = 21 - 1\n",
        "        elif layout == 'ntu_edge':\n",
        "            self.num_node = 24\n",
        "            self_link = [(i, i) for i in range(self.num_node)]\n",
        "            neighbor_1base = [(1, 2), (3, 2), (4, 3), (5, 2), (6, 5), (7, 6),\n",
        "                              (8, 7), (9, 2), (10, 9), (11, 10), (12, 11),\n",
        "                              (13, 1), (14, 13), (15, 14), (16, 15), (17, 1),\n",
        "                              (18, 17), (19, 18), (20, 19), (21, 22), (22, 8),\n",
        "                              (23, 24), (24, 12)]\n",
        "            neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_1base]\n",
        "            self.edge = self_link + neighbor_link\n",
        "            self.center = 2\n",
        "        elif layout == 'coco':\n",
        "            self.num_node = 17\n",
        "            self_link = [(i, i) for i in range(self.num_node)]\n",
        "            neighbor_1base = [[16, 14], [14, 12], [17, 15], [15, 13], [12, 13],\n",
        "                              [6, 12], [7, 13], [6, 7], [8, 6], [9, 7],\n",
        "                              [10, 8], [11, 9], [2, 3], [2, 1], [3, 1], [4, 2],\n",
        "                              [5, 3], [4, 6], [5, 7]]\n",
        "            neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_1base]\n",
        "            self.edge = self_link + neighbor_link\n",
        "            self.center = 0\n",
        "        else:\n",
        "            raise ValueError(f'{layout} is not supported.')\n",
        "\n",
        "    def get_adjacency(self, strategy):\n",
        "        \"\"\"This method returns the adjacency matrix according to strategy.\"\"\"\n",
        "\n",
        "        valid_hop = range(0, self.max_hop + 1, self.dilation)\n",
        "        adjacency = np.zeros((self.num_node, self.num_node))\n",
        "        for hop in valid_hop:\n",
        "            adjacency[self.hop_dis == hop] = 1\n",
        "        normalize_adjacency = normalize_digraph(adjacency)\n",
        "\n",
        "        if strategy == 'uniform':\n",
        "            A = np.zeros((1, self.num_node, self.num_node))\n",
        "            A[0] = normalize_adjacency\n",
        "            self.A = A\n",
        "        elif strategy == 'distance':\n",
        "            A = np.zeros((len(valid_hop), self.num_node, self.num_node))\n",
        "            for i, hop in enumerate(valid_hop):\n",
        "                A[i][self.hop_dis == hop] = normalize_adjacency[self.hop_dis ==\n",
        "                                                                hop]\n",
        "            self.A = A\n",
        "        elif strategy == 'spatial':\n",
        "            A = []\n",
        "            for hop in valid_hop:\n",
        "                a_root = np.zeros((self.num_node, self.num_node))\n",
        "                a_close = np.zeros((self.num_node, self.num_node))\n",
        "                a_further = np.zeros((self.num_node, self.num_node))\n",
        "                for i in range(self.num_node):\n",
        "                    for j in range(self.num_node):\n",
        "                        if self.hop_dis[j, i] == hop:\n",
        "                            if self.hop_dis[j, self.center] == self.hop_dis[\n",
        "                                    i, self.center]:\n",
        "                                a_root[j, i] = normalize_adjacency[j, i]\n",
        "                            elif self.hop_dis[j, self.center] > self.hop_dis[\n",
        "                                    i, self.center]:\n",
        "                                a_close[j, i] = normalize_adjacency[j, i]\n",
        "                            else:\n",
        "                                a_further[j, i] = normalize_adjacency[j, i]\n",
        "                if hop == 0:\n",
        "                    A.append(a_root)\n",
        "                else:\n",
        "                    A.append(a_root + a_close)\n",
        "                    A.append(a_further)\n",
        "            A = np.stack(A)\n",
        "            self.A = A\n",
        "        elif strategy == 'agcn':\n",
        "            A = []\n",
        "            link_mat = edge2mat(self.self_link, self.num_node)\n",
        "            In = normalize_digraph(edge2mat(self.neighbor_link, self.num_node))\n",
        "            outward = [(j, i) for (i, j) in self.neighbor_link]\n",
        "            Out = normalize_digraph(edge2mat(outward, self.num_node))\n",
        "            A = np.stack((link_mat, In, Out))\n",
        "            self.A = A\n",
        "        else:\n",
        "            raise ValueError('Do Not Exist This Strategy')\n",
        "        \n",
        "\n",
        "if __name__ == '__main__': \n",
        "    g = Graph()"
      ],
      "metadata": {
        "id": "NFbQLdRHtMk1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MODEL ST-GCN**"
      ],
      "metadata": {
        "id": "A4BDzBdhs29S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "GtAbmwmvW_fx"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# from torch.autograd import Variable\n",
        "\n",
        "\n",
        "# # from utils.tgcn import ConvTemporalGraphical\n",
        "# # from utils.graph import Graph\n",
        "# # import os\n",
        "# # os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "# class unit_gcn(nn.Module):\n",
        "\n",
        "#     def __init__(self,\n",
        "#                  in_channels,\n",
        "#                  out_channels,\n",
        "#                  A,\n",
        "#                  adaptive='importance',\n",
        "#                  conv_pos='pre',\n",
        "#                  with_res=True,\n",
        "#                  norm='BN',\n",
        "#                  act='ReLU'):\n",
        "#         super().__init__()\n",
        "#         self.in_channels = in_channels\n",
        "#         self.out_channels = out_channels\n",
        "#         self.num_subsets = A.size(0)\n",
        "\n",
        "#         assert adaptive in [None, 'init', 'offset', 'importance']\n",
        "#         self.adaptive = adaptive\n",
        "#         assert conv_pos in ['pre', 'post']\n",
        "#         self.conv_pos = conv_pos\n",
        "#         self.with_res = with_res\n",
        "\n",
        "#         self.norm_cfg = norm if isinstance(norm, dict) else dict(type=norm)\n",
        "#         self.act_cfg = act if isinstance(act, dict) else dict(type=act)\n",
        "#         self.bn = nn.BatchNorm2d(out_channels)\n",
        "#         self.act = nn.ReLU()\n",
        "\n",
        "#         if self.adaptive == 'init':\n",
        "#             self.A = nn.Parameter(A.clone())\n",
        "#         else:\n",
        "#             self.register_buffer('A', A)\n",
        "\n",
        "#         if self.adaptive in ['offset', 'importance']:\n",
        "#             self.PA = nn.Parameter(A.clone())\n",
        "#             if self.adaptive == 'offset':\n",
        "#                 nn.init.uniform_(self.PA, -1e-6, 1e-6)\n",
        "#             elif self.adaptive == 'importance':\n",
        "#                 nn.init.constant_(self.PA, 1)\n",
        "\n",
        "#         if self.conv_pos == 'pre':\n",
        "#             self.conv = nn.Conv2d(in_channels, out_channels * A.size(0), 1)\n",
        "#         elif self.conv_pos == 'post':\n",
        "#             self.conv = nn.Conv2d(A.size(0) * in_channels, out_channels, 1)\n",
        "\n",
        "#         if self.with_res:\n",
        "#             if in_channels != out_channels:\n",
        "#                 self.down = nn.Sequential(\n",
        "#                     nn.Conv2d(in_channels, out_channels, 1),\n",
        "#                     nn.BatchNorm2d(out_channels))\n",
        "#             else:\n",
        "#                 self.down = lambda x: x\n",
        "\n",
        "#     def forward(self, x, A=None):\n",
        "#         \"\"\"Defines the computation performed at every call.\"\"\"\n",
        "#         n, c, t, v = x.shape\n",
        "#         res = self.down(x) if self.with_res else 0\n",
        "\n",
        "#         A_switch = {None: self.A, 'init': self.A}\n",
        "#         if hasattr(self, 'PA'):\n",
        "#             A_switch.update({'offset': self.A + self.PA, 'importance': self.A * self.PA})\n",
        "#         A = A_switch[self.adaptive]\n",
        "\n",
        "#         if self.conv_pos == 'pre':\n",
        "#             x = self.conv(x)\n",
        "#             x = x.view(n, self.num_subsets, -1, t, v)\n",
        "#             x = torch.einsum('nkctv,kvw->nctw', (x, A)).contiguous()\n",
        "#         elif self.conv_pos == 'post':\n",
        "#             x = torch.einsum('nctv,kvw->nkctw', (x, A)).contiguous()\n",
        "#             x = x.view(n, -1, t, v)\n",
        "#             x = self.conv(x)\n",
        "\n",
        "#         return self.act(self.bn(x) + res)\n",
        "\n",
        "\n",
        "# class unit_tcn(nn.Module):\n",
        "\n",
        "\n",
        "#     def __init__(self, in_channels, out_channels, kernel_size=9, stride=1, dilation=1, norm='BN', dropout=0.5):\n",
        "\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.in_channels = in_channels\n",
        "#         self.out_channels = out_channels\n",
        "#         self.norm_cfg = norm if isinstance(norm, dict) else dict(type=norm)\n",
        "#         pad = (kernel_size + (kernel_size - 1) * (dilation - 1) - 1) // 2\n",
        "\n",
        "#         self.conv = nn.Conv2d(\n",
        "#             in_channels,\n",
        "#             out_channels,\n",
        "#             kernel_size=(kernel_size, 1),\n",
        "#             padding=(pad, 0),\n",
        "#             stride=(stride, 1),\n",
        "#             dilation=(dilation, 1))\n",
        "#         self.bn = nn.BatchNorm2d(out_channels) if norm is not None else nn.Identity()\n",
        "#         self.drop = nn.Dropout(dropout, inplace=True)\n",
        "#         self.stride = stride\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.drop(self.bn(self.conv(x)))\n",
        "\n",
        "# class STGCNBlock(nn.Module):\n",
        "\n",
        "#     def __init__(self,\n",
        "#                  in_channels,\n",
        "#                  out_channels,\n",
        "#                  A,\n",
        "#                  stride=1,\n",
        "#                  dilation=1,\n",
        "#                  residual=True):\n",
        "#         super().__init__()\n",
        "#         self.gcn = unit_gcn(in_channels, out_channels, A)\n",
        "#         self.tcn = unit_tcn(out_channels, out_channels, 9, stride=stride,dilation=dilation)\n",
        "#         self.relu = nn.ReLU()\n",
        "#         if not residual:\n",
        "#             self.residual = lambda x: 0\n",
        "#         elif (in_channels == out_channels) and (stride == 1):\n",
        "#             self.residual = lambda x: x\n",
        "#         else:\n",
        "#             self.residual = unit_tcn(in_channels, out_channels, kernel_size=1, stride=stride)\n",
        "\n",
        "#     def forward(self, x, A=None):\n",
        "#         \"\"\"Defines the computation performed at every call.\"\"\"\n",
        "#         res = self.residual(x)\n",
        "#         x = self.tcn(self.gcn(x)) + res\n",
        "#         return self.relu(x)\n",
        "# class ModelSTGCN(nn.Module):\n",
        "#     r\"\"\"Spatial temporal graph convolutional networks.\n",
        "#     Args:\n",
        "#         in_channels (int): Number of channels in the input data\n",
        "#         num_class (int): Number of classes for the classification task\n",
        "#         graph_args (dict): The arguments for building the graph\n",
        "#         edge_importance_weighting (bool): If ``True``, adds a learnable\n",
        "#             importance weighting to the edges of the graph\n",
        "#         **kwargs (optional): Other parameters for graph convolution units\n",
        "#     Shape:\n",
        "#         - Input: :math:`(N, in_channels, T_{in}, V_{in}, M_{in})`\n",
        "#         - Output: :math:`(N, num_class)` where\n",
        "#             :math:`N` is a batch size,\n",
        "#             :math:`T_{in}` is a length of input sequence,\n",
        "#             :math:`V_{in}` is the number of graph nodes,\n",
        "#             :math:`M_{in}` is the number of instance in a frame.\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, in_channels, num_class,\n",
        "#                  edge_importance_weighting=True):\n",
        "#         super().__init__()\n",
        "\n",
        "#         # load graph\n",
        "#         self.graph = Graph()\n",
        "#         A = torch.tensor(self.graph.A, dtype=torch.float32, requires_grad=False)\n",
        "#         self.register_buffer('A', A)\n",
        "\n",
        "#         # build networks\n",
        "#         spatial_kernel_size = A.size(0)\n",
        "#         temporal_kernel_size = 9\n",
        "#         kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
        "#         self.data_bn = nn.BatchNorm1d(in_channels * A.size(1))\n",
        "#         self.st_gcn_networks = nn.ModuleList((\n",
        "#             STGCNBlock(in_channels, 32,A=A ),\n",
        "#             STGCNBlock(32, 32, A=A),\n",
        "#             STGCNBlock(32, 32, A=A),\n",
        "#             STGCNBlock(32, 64, A=A),\n",
        "#             STGCNBlock(64, 64, A=A),\n",
        "#             STGCNBlock(64, 64, A=A),\n",
        "#             STGCNBlock(64, 64, A=A),\n",
        "#             STGCNBlock(64, 128, A=A),\n",
        "#             STGCNBlock(128, 128, A=A),\n",
        "#             STGCNBlock(128, 128, A=A),\n",
        "#         ))\n",
        "\n",
        "#         # initialize parameters for edge importance weighting\n",
        "#         # if edge_importance_weighting:\n",
        "#         #     self.edge_importance = nn.ParameterList([\n",
        "#         #         nn.Parameter(torch.ones(self.A.size()))\n",
        "#         #         for i in self.st_gcn_networks\n",
        "#         #     ])\n",
        "#         # else:\n",
        "#         #     self.edge_importance = [1] * len(self.st_gcn_networks)\n",
        "\n",
        "#         # fcn for prediction\n",
        "#         self.fcn = nn.Conv2d(128, num_class, kernel_size=1)\n",
        "\n",
        "#     def forward(self, x):\n",
        "\n",
        "#         # data normalization\n",
        "#         # have instance of person\n",
        "#         # N, C, T, V, M = x.size()\n",
        "#         # x = x.permute(0, 4, 3, 1, 2).contiguous() # V C T\n",
        "#         # x = x.view(N * M, V * C, T)\n",
        "#         # x = self.data_bn(x)\n",
        "#         # x = x.view(N, M, V, C, T)\n",
        "#         # x = x.permute(0, 1, 3, 4, 2).contiguous()\n",
        "#         # x = x.view(N * M, C, T, V)\n",
        "\n",
        "#         # dont have instance of person\n",
        "\n",
        "#         N,T,V,C = x.size()\n",
        "#         x = x.permute(0, 2, 3, 1).contiguous() # N V C T\n",
        "#         x = x.view(N , V * C, T)\n",
        "#         x = self.data_bn(x)\n",
        "#         x = x.view(N, V, C, T)\n",
        "#         x = x.permute(0, 2, 3, 1).contiguous()\n",
        "#         # x = x.view(N , C, T, V)\n",
        "#         # forwad\n",
        "#         for gcn in (self.st_gcn_networks):\n",
        "#             x = gcn(x)\n",
        "\n",
        "#         # global pooling\n",
        "#         x = F.avg_pool2d(x, x.size()[2:])\n",
        "#         # # x = x.view(N, M, -1, 1, 1).mean(dim=1)\n",
        "#         # x = x.view(N, 1, -1, 1, 1).mean(dim=1)\n",
        "\n",
        "#         # prediction\n",
        "#         x = self.fcn(x)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "\n",
        "#         return x\n",
        "\n",
        "\n",
        "# # if __name__ == '__main__':\n",
        "# #     print(__package__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# from torch.autograd import Variable\n",
        "# from utils.graph import Graph\n",
        "\n",
        "# from utils.tgcn import ConvTemporalGraphical\n",
        "# from utils.graph import Graph\n",
        "# import os\n",
        "# os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "class unit_gcn(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 A,\n",
        "                 adaptive='importance',\n",
        "                 conv_pos='pre',\n",
        "                 with_res=True,\n",
        "                 norm='BN',\n",
        "                 act='ReLU'):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.num_subsets = A.size(0)\n",
        "\n",
        "        assert adaptive in [None, 'init', 'offset', 'importance']\n",
        "        self.adaptive = adaptive\n",
        "        assert conv_pos in ['pre', 'post']\n",
        "        self.conv_pos = conv_pos\n",
        "        self.with_res = with_res\n",
        "\n",
        "        self.norm_cfg = norm if isinstance(norm, dict) else dict(type=norm)\n",
        "        self.act_cfg = act if isinstance(act, dict) else dict(type=act)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "        if self.adaptive == 'init':\n",
        "            self.A = nn.Parameter(A.clone())\n",
        "        else:\n",
        "            self.register_buffer('A', A)\n",
        "\n",
        "        if self.adaptive in ['offset', 'importance']:\n",
        "            self.PA = nn.Parameter(A.clone())\n",
        "            if self.adaptive == 'offset':\n",
        "                nn.init.uniform_(self.PA, -1e-6, 1e-6)\n",
        "            elif self.adaptive == 'importance':\n",
        "                nn.init.constant_(self.PA, 1)\n",
        "\n",
        "        if self.conv_pos == 'pre':\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels * A.size(0), 1)\n",
        "        elif self.conv_pos == 'post':\n",
        "            self.conv = nn.Conv2d(A.size(0) * in_channels, out_channels, 1)\n",
        "\n",
        "        if self.with_res:\n",
        "            if in_channels != out_channels:\n",
        "                self.down = nn.Sequential(\n",
        "                    nn.Conv2d(in_channels, out_channels, 1),\n",
        "                    nn.BatchNorm2d(out_channels))\n",
        "            else:\n",
        "                self.down = lambda x: x\n",
        "\n",
        "    def forward(self, x, A=None):\n",
        "        \"\"\"Defines the computation performed at every call.\"\"\"\n",
        "        n, c, t, v = x.shape\n",
        "        res = self.down(x) if self.with_res else 0\n",
        "\n",
        "        A_switch = {None: self.A, 'init': self.A}\n",
        "        if hasattr(self, 'PA'):\n",
        "            A_switch.update({'offset': self.A + self.PA, 'importance': self.A * self.PA})\n",
        "        A = A_switch[self.adaptive]\n",
        "\n",
        "        if self.conv_pos == 'pre':\n",
        "            x = self.conv(x)\n",
        "            x = x.view(n, self.num_subsets, -1, t, v)\n",
        "            x = torch.einsum('nkctv,kvw->nctw', (x, A)).contiguous()\n",
        "        elif self.conv_pos == 'post':\n",
        "            x = torch.einsum('nctv,kvw->nkctw', (x, A)).contiguous()\n",
        "            x = x.view(n, -1, t, v)\n",
        "            x = self.conv(x)\n",
        "\n",
        "        return self.act(self.bn(x) + res)\n",
        "\n",
        "\n",
        "class unit_tcn(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=9, stride=1, dilation=1, norm='BN', dropout=0):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.norm_cfg = norm if isinstance(norm, dict) else dict(type=norm)\n",
        "        pad = (kernel_size + (kernel_size - 1) * (dilation - 1) - 1) // 2\n",
        "\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size=(kernel_size, 1),\n",
        "            padding=(pad, 0),\n",
        "            stride=(stride, 1),\n",
        "            dilation=(dilation, 1))\n",
        "        self.bn = nn.BatchNorm2d(out_channels) if norm is not None else nn.Identity()\n",
        "        self.drop = nn.Dropout(dropout, inplace=True)\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.drop(self.bn(self.conv(x)))\n",
        "\n",
        "class STGCNBlock(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 A,\n",
        "                 stride=1,\n",
        "                 dilation=1,\n",
        "                 residual=True):\n",
        "        super().__init__()\n",
        "        self.gcn = unit_gcn(in_channels, out_channels, A)\n",
        "        self.tcn = unit_tcn(out_channels, out_channels, 9, stride=stride,dilation=dilation)\n",
        "        self.relu = nn.ReLU()\n",
        "        if not residual:\n",
        "            self.residual = lambda x: 0\n",
        "        elif (in_channels == out_channels) and (stride == 1):\n",
        "            self.residual = lambda x: x\n",
        "        else:\n",
        "            self.residual = unit_tcn(in_channels, out_channels, kernel_size=1, stride=stride)\n",
        "\n",
        "    def forward(self, x, A=None):\n",
        "        \"\"\"Defines the computation performed at every call.\"\"\"\n",
        "        res = self.residual(x)\n",
        "        x = self.tcn(self.gcn(x)) + res\n",
        "        return self.relu(x)\n",
        "class ModelSTGCN(nn.Module):\n",
        "    r\"\"\"Spatial temporal graph convolutional networks.\n",
        "    Args:\n",
        "        in_channels (int): Number of channels in the input data\n",
        "        num_class (int): Number of classes for the classification task\n",
        "        graph_args (dict): The arguments for building the graph\n",
        "        edge_importance_weighting (bool): If ``True``, adds a learnable\n",
        "            importance weighting to the edges of the graph\n",
        "        **kwargs (optional): Other parameters for graph convolution units\n",
        "    Shape:\n",
        "        - Input: :math:`(N, in_channels, T_{in}, V_{in}, M_{in})`\n",
        "        - Output: :math:`(N, num_class)` where\n",
        "            :math:`N` is a batch size,\n",
        "            :math:`T_{in}` is a length of input sequence,\n",
        "            :math:`V_{in}` is the number of graph nodes,\n",
        "            :math:`M_{in}` is the number of instance in a frame.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, num_class,\n",
        "                 edge_importance_weighting=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # load graph\n",
        "        self.graph = Graph()\n",
        "        A = torch.tensor(self.graph.A, dtype=torch.float32, requires_grad=False)\n",
        "        self.register_buffer('A', A)\n",
        "\n",
        "        # build networks\n",
        "        spatial_kernel_size = A.size(0)\n",
        "        temporal_kernel_size = 9\n",
        "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
        "        self.data_bn = nn.BatchNorm1d(in_channels * A.size(1))\n",
        "        self.st_gcn_networks = nn.ModuleList((\n",
        "            STGCNBlock(in_channels, 64,A=A ),\n",
        "            STGCNBlock(64, 64, A=A),\n",
        "            STGCNBlock(64, 64, A=A),\n",
        "            STGCNBlock(64, 64, A=A),\n",
        "            STGCNBlock(64, 128, A=A),\n",
        "            STGCNBlock(128, 128, A=A),\n",
        "            STGCNBlock(128, 128, A=A),\n",
        "            STGCNBlock(128, 256, A=A),\n",
        "            STGCNBlock(256, 256, A=A),\n",
        "            STGCNBlock(256, 256, A=A),\n",
        "        ))\n",
        "\n",
        "        # initialize parameters for edge importance weighting\n",
        "        # if edge_importance_weighting:\n",
        "        #     self.edge_importance = nn.ParameterList([\n",
        "        #         nn.Parameter(torch.ones(self.A.size()))\n",
        "        #         for i in self.st_gcn_networks\n",
        "        #     ])\n",
        "        # else:\n",
        "        #     self.edge_importance = [1] * len(self.st_gcn_networks)\n",
        "\n",
        "        # fcn for prediction\n",
        "        self.fcn = nn.Conv2d(256, num_class, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # data normalization\n",
        "        # have instance of person\n",
        "        # N, C, T, V, M = x.size()\n",
        "        # x = x.permute(0, 4, 3, 1, 2).contiguous() # V C T\n",
        "        # x = x.view(N * M, V * C, T)\n",
        "        # x = self.data_bn(x)\n",
        "        # x = x.view(N, M, V, C, T)\n",
        "        # x = x.permute(0, 1, 3, 4, 2).contiguous()\n",
        "        # x = x.view(N * M, C, T, V)\n",
        "\n",
        "        # dont have instance of person\n",
        "\n",
        "        N,T,V,C = x.size()\n",
        "        x = x.permute(0, 2, 3, 1).contiguous() # N V C T\n",
        "        x = x.view(N , V * C, T)\n",
        "        x = self.data_bn(x)\n",
        "        x = x.view(N, V, C, T)\n",
        "        x = x.permute(0, 2, 3, 1).contiguous()\n",
        "        # x = x.view(N , C, T, V)\n",
        "        # forwad\n",
        "        for gcn in (self.st_gcn_networks):\n",
        "            x = gcn(x)\n",
        "\n",
        "        # global pooling\n",
        "        x = F.avg_pool2d(x, x.size()[2:])\n",
        "        # # x = x.view(N, M, -1, 1, 1).mean(dim=1)\n",
        "        # x = x.view(N, 1, -1, 1, 1).mean(dim=1)\n",
        "\n",
        "        # prediction\n",
        "        x = self.fcn(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     print(__package__)"
      ],
      "metadata": {
        "id": "v2CJ1XffeLV4"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Uniform Sample**\n"
      ],
      "metadata": {
        "id": "TLGNQJUmI-cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UniformSampleFrames:\n",
        "    \"\"\"Uniformly sample frames from the video.\n",
        "    To sample an n-frame clip from the video. UniformSampleFrames basically\n",
        "    divide the video into n segments of equal length and randomly sample one\n",
        "    frame from each segment. To make the testing results reproducible, a\n",
        "    random seed is set during testing, to make the sampling results\n",
        "    deterministic.\n",
        "    Required keys are \"total_frames\", \"start_index\" , added or modified keys\n",
        "    are \"frame_inds\", \"clip_len\", \"frame_interval\" and \"num_clips\".\n",
        "    Args:\n",
        "        clip_len (int): Frames of each sampled output clip.\n",
        "        num_clips (int): Number of clips to be sampled. Default: 1.\n",
        "        test_mode (bool): Store True when building test or validation dataset.\n",
        "            Default: False.\n",
        "        seed (int): The random seed used during test time. Default: 255.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, clip_len, num_clips=1, test_mode=False, seed=255):\n",
        "\n",
        "        self.clip_len = clip_len\n",
        "        self.num_clips = num_clips\n",
        "        self.test_mode = test_mode\n",
        "        self.seed = seed\n",
        "\n",
        "    def _get_train_clips(self, num_frames, clip_len):\n",
        "        \"\"\"Uniformly sample indices for training clips.\n",
        "        Args:\n",
        "            num_frames (int): The number of frames.\n",
        "            clip_len (int): The length of the clip.\n",
        "        \"\"\"\n",
        "\n",
        "        assert self.num_clips == 1\n",
        "        if num_frames < clip_len:\n",
        "            start = np.random.randint(0, num_frames)\n",
        "            inds = np.arange(start, start + clip_len)\n",
        "        elif clip_len <= num_frames < 2 * clip_len:\n",
        "            basic = np.arange(clip_len)\n",
        "            inds = np.random.choice(\n",
        "                clip_len + 1, num_frames - clip_len, replace=False)\n",
        "            offset = np.zeros(clip_len + 1, dtype=np.int64)\n",
        "            offset[inds] = 1\n",
        "            offset = np.cumsum(offset)\n",
        "            inds = basic + offset[:-1]\n",
        "        else:\n",
        "            bids = np.array(\n",
        "                [i * num_frames // clip_len for i in range(clip_len + 1)])\n",
        "            bsize = np.diff(bids)\n",
        "            bst = bids[:clip_len]\n",
        "            offset = np.random.randint(bsize)\n",
        "            inds = bst + offset\n",
        "        return inds\n",
        "\n",
        "    def _get_test_clips(self, num_frames, clip_len):\n",
        "        \"\"\"Uniformly sample indices for testing clips.\n",
        "        Args:\n",
        "            num_frames (int): The number of frames.\n",
        "            clip_len (int): The length of the clip.\n",
        "        \"\"\"\n",
        "\n",
        "        np.random.seed(self.seed)\n",
        "        if num_frames < clip_len:\n",
        "            # Then we use a simple strategy\n",
        "            if num_frames < self.num_clips:\n",
        "                start_inds = list(range(self.num_clips))\n",
        "            else:\n",
        "                start_inds = [\n",
        "                    i * num_frames // self.num_clips\n",
        "                    for i in range(self.num_clips)\n",
        "                ]\n",
        "            inds = np.concatenate(\n",
        "                [np.arange(i, i + clip_len) for i in start_inds])\n",
        "        elif clip_len <= num_frames < clip_len * 2:\n",
        "            all_inds = []\n",
        "            for i in range(self.num_clips):\n",
        "                basic = np.arange(clip_len)\n",
        "                inds = np.random.choice(\n",
        "                    clip_len + 1, num_frames - clip_len, replace=False)\n",
        "                offset = np.zeros(clip_len + 1, dtype=np.int64)\n",
        "                offset[inds] = 1\n",
        "                offset = np.cumsum(offset)\n",
        "                inds = basic + offset[:-1]\n",
        "                all_inds.append(inds)\n",
        "            inds = np.concatenate(all_inds)\n",
        "        else:\n",
        "            bids = np.array(\n",
        "                [i * num_frames // clip_len for i in range(clip_len + 1)])\n",
        "            bsize = np.diff(bids)\n",
        "            bst = bids[:clip_len]\n",
        "            all_inds = []\n",
        "            for i in range(self.num_clips):\n",
        "                offset = np.random.randint(bsize)\n",
        "                all_inds.append(bst + offset)\n",
        "            inds = np.concatenate(all_inds)\n",
        "        return inds\n",
        "\n",
        "    def __call__(self, results):\n",
        "        num_frames = results['total_frames']\n",
        "\n",
        "        if self.test_mode:\n",
        "            inds = self._get_test_clips(num_frames, self.clip_len)\n",
        "        else:\n",
        "            inds = self._get_train_clips(num_frames, self.clip_len)\n",
        "\n",
        "        inds = np.mod(inds, num_frames)\n",
        "        start_index = results['start_index']\n",
        "        inds = inds + start_index\n",
        "\n",
        "        results['frame_inds'] = inds.astype(np.int64)\n",
        "        results['clip_len'] = self.clip_len\n",
        "        results['frame_interval'] = None\n",
        "        results['num_clips'] = self.num_clips\n",
        "        return results\n",
        "\n",
        "    def __repr__(self):\n",
        "        repr_str = (f'{self.__class__.__name__}('\n",
        "                    f'clip_len={self.clip_len}, '\n",
        "                    f'num_clips={self.num_clips}, '\n",
        "                    f'test_mode={self.test_mode}, '\n",
        "                    f'seed={self.seed})')\n",
        "        return repr_str\n"
      ],
      "metadata": {
        "id": "HyrW6tDPJxZH"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class UniformSampleFrames:\n",
        "#     \"\"\"Uniformly sample frames from the video.\n",
        "\n",
        "#     To sample an n-frame clip from the video. UniformSampleFrames basically\n",
        "#     divide the video into n segments of equal length and randomly sample one\n",
        "#     frame from each segment. To make the testing results reproducible, a\n",
        "#     random seed is set during testing, to make the sampling results\n",
        "#     deterministic.\n",
        "\n",
        "#     Required keys are \"total_frames\", \"start_index\" , added or modified keys\n",
        "#     are \"frame_inds\", \"clip_len\", \"frame_interval\" and \"num_clips\".\n",
        "\n",
        "#     Args:\n",
        "#         clip_len (int): Frames of each sampled output clip.\n",
        "#         num_clips (int): Number of clips to be sampled. Default: 1.\n",
        "#         test_mode (bool): Store True when building test or validation dataset.\n",
        "#             Default: False.\n",
        "#         seed (int): The random seed used during test time. Default: 255.\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, clip_len, num_clips=1, test_mode=False, seed=255):\n",
        "\n",
        "#         self.clip_len = clip_len\n",
        "#         self.num_clips = num_clips\n",
        "#         self.test_mode = test_mode\n",
        "#         self.seed = seed\n",
        "\n",
        "#     def _get_train_clips(self, num_frames, clip_len):\n",
        "#         \"\"\"Uniformly sample indices for training clips.\n",
        "\n",
        "#         Args:\n",
        "#             num_frames (int): The number of frames.\n",
        "#             clip_len (int): The length of the clip.\n",
        "#         \"\"\"\n",
        "\n",
        "#         assert self.num_clips == 1\n",
        "#         if num_frames < clip_len:\n",
        "#             start = np.random.randint(0, num_frames)\n",
        "#             inds = np.arange(start, start + clip_len)\n",
        "#         elif clip_len <= num_frames < 2 * clip_len:\n",
        "#             basic = np.arange(clip_len)\n",
        "#             inds = np.random.choice(\n",
        "#                 clip_len + 1, num_frames - clip_len, replace=False)\n",
        "#             offset = np.zeros(clip_len + 1, dtype=np.int64)\n",
        "#             offset[inds] = 1\n",
        "#             offset = np.cumsum(offset)\n",
        "#             inds = basic + offset[:-1]\n",
        "#         else:\n",
        "#             bids = np.array(\n",
        "#                 [i * num_frames // clip_len for i in range(clip_len + 1)])\n",
        "#             bsize = np.diff(bids)\n",
        "#             bst = bids[:clip_len]\n",
        "#             offset = np.random.randint(bsize)\n",
        "#             inds = bst + offset\n",
        "#         return inds\n",
        "\n",
        "#     def _get_test_clips(self, num_frames, clip_len):\n",
        "#         \"\"\"Uniformly sample indices for testing clips.\n",
        "\n",
        "#         Args:\n",
        "#             num_frames (int): The number of frames.\n",
        "#             clip_len (int): The length of the clip.\n",
        "#         \"\"\"\n",
        "\n",
        "#         np.random.seed(self.seed)\n",
        "#         if num_frames < clip_len:\n",
        "#             # Then we use a simple strategy\n",
        "#             if num_frames < self.num_clips:\n",
        "#                 start_inds = list(range(self.num_clips))\n",
        "#             else:\n",
        "#                 start_inds = [\n",
        "#                     i * num_frames // self.num_clips\n",
        "#                     for i in range(self.num_clips)\n",
        "#                 ]\n",
        "#             inds = np.concatenate(\n",
        "#                 [np.arange(i, i + clip_len) for i in start_inds])\n",
        "#         elif clip_len <= num_frames < clip_len * 2:\n",
        "#             all_inds = []\n",
        "#             for i in range(self.num_clips):\n",
        "#                 basic = np.arange(clip_len)\n",
        "#                 inds = np.random.choice(\n",
        "#                     clip_len + 1, num_frames - clip_len, replace=False)\n",
        "#                 offset = np.zeros(clip_len + 1, dtype=np.int64)\n",
        "#                 offset[inds] = 1\n",
        "#                 offset = np.cumsum(offset)\n",
        "#                 inds = basic + offset[:-1]\n",
        "#                 all_inds.append(inds)\n",
        "#             inds = np.concatenate(all_inds)\n",
        "#         else:\n",
        "#             bids = np.array(\n",
        "#                 [i * num_frames // clip_len for i in range(clip_len + 1)])\n",
        "#             bsize = np.diff(bids)\n",
        "#             bst = bids[:clip_len]\n",
        "#             all_inds = []\n",
        "#             for i in range(self.num_clips):\n",
        "#                 offset = np.random.randint(bsize)\n",
        "#                 all_inds.append(bst + offset)\n",
        "#             inds = np.concatenate(all_inds)\n",
        "#         return inds\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "imDYkuBlTxSC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Some Function**"
      ],
      "metadata": {
        "id": "ITf5yFQkCFkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Interpolation(kp, num_frames):\n",
        "    \"\"\"\n",
        "    Repeat frames in a keypoints numpy array using linear interpolation.\n",
        "    \n",
        "    Args:\n",
        "        kp: numpy array of shape (num_person, num_frames, num_keypoints, 3) containing keypoints data.\n",
        "        num_frames: integer representing the number of frames to interpolate to.\n",
        "        \n",
        "    Returns:\n",
        "        sampled_kp: numpy array of shape (num_person, num_frames, num_keypoints, 3) containing the interpolated keypoints.\n",
        "    \"\"\"\n",
        "    # get the number of frames in the original keypoints array\n",
        "    num_original_frames = kp.shape[0]\n",
        "    \n",
        "    # create a new array of shape (num_person, num_frames, num_keypoints, 3) to store the interpolated keypoints\n",
        "    sampled_kp = np.zeros((num_frames, kp.shape[1], kp.shape[2]))\n",
        "    \n",
        "    # loop through each person in the keypoints array\n",
        "    # loop through each keypoint in the keypoints array\n",
        "    for kpt in range(kp.shape[1]):\n",
        "        # loop through each coordinate in the keypoint (x, y, z)\n",
        "        for coord in range(kp.shape[3]):\n",
        "            # create an array of x values representing the original frames\n",
        "            x = np.arange(num_original_frames)\n",
        "            # create an array of x values representing the new frames\n",
        "            new_x = np.linspace(0, num_original_frames-1, num_frames)\n",
        "            # use linear interpolation to calculate the y values (keypoint coordinates) at the new frames\n",
        "            new_y = np.interp(new_x, x, kp[:, kpt, coord])\n",
        "            # store the interpolated keypoint coordinates in the new array\n",
        "            sampled_kp[ :, kpt, coord] = new_y\n",
        "                \n",
        "    return sampled_kp\n",
        "\n",
        "def repeat_frames(kp, num_frames):\n",
        "  \"\"\"\n",
        "  Repeat frames in a keypoints numpy array to achieve uniform sampling.\n",
        "\n",
        "  Args:\n",
        "      kp: numpy array of shape (num_person, num_frames, num_keypoints, 3) containing keypoints data.\n",
        "      num_frames: integer representing the number of frames to sample to.\n",
        "      \n",
        "  Returns:\n",
        "      sampled_kp: numpy array of shape (num_person, num_frames, num_keypoints, 3) containing the keypoints after repeating frames.\n",
        "  \"\"\"\n",
        "  # check if the number of frames in the keypoints array is less than the desired number of frames\n",
        "  if kp.shape[1] < num_frames:\n",
        "      # calculate the number of frames to repeat\n",
        "      num_frames_to_repeat = num_frames - kp.shape[1]\n",
        "      # determine the indices of the frames to repeat\n",
        "      repeat_indices = np.random.choice(kp.shape[1], num_frames_to_repeat)\n",
        "      # sort the indices in ascending order\n",
        "      repeat_indices = np.sort(repeat_indices)\n",
        "      # create an array of zeros to store the sampled keypoints\n",
        "      sampled_kp = np.zeros((kp.shape[0], num_frames, kp.shape[2], kp.shape[3]))\n",
        "      # loop through each person in the keypoints array\n",
        "      for person in range(kp.shape[0]):\n",
        "          # loop through each keypoint in the keypoints array\n",
        "          for kpt in range(kp.shape[2]):\n",
        "              # loop through each coordinate in the keypoint (x, y, z)\n",
        "              for coord in range(kp.shape[3]):\n",
        "                  # create a new array of keypoint coordinates with repeated frames\n",
        "                  new_kp = np.repeat(kp[person, :, kpt, coord][np.newaxis, :], num_frames, axis=0)\n",
        "                  # repeat the frames at the specified indices using linear interpolation\n",
        "                  new_kp[repeat_indices] = Interpolation(kp[person, :, kpt, coord][np.newaxis, :], num_frames_to_repeat)\n",
        "                  # store the new keypoint coordinates in the sampled keypoints array\n",
        "                  sampled_kp[person, :, kpt, coord] = new_kp\n",
        "  else:\n",
        "      # if the number of frames in the keypoints array is greater than or equal to the desired number of frames, return the keypoints array as is\n",
        "      sampled_kp = kp\n",
        "\n",
        "  return sampled_kp\n",
        "\n"
      ],
      "metadata": {
        "id": "I-_E8bjRCFkT"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Action Dataset**"
      ],
      "metadata": {
        "id": "2WBSDmwgJ97-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "class ActionDataset(Dataset):\n",
        "    def __init__(self,path, train_mode, clip_len=100):\n",
        "        # super().__init__()\n",
        "        # # assert all(param is not None for param in [Data,label]),\"Data and label must be give in\"\n",
        "        # # self.transform = Transform\n",
        "        # self.feature=[]\n",
        "        # self.label=[]\n",
        "        # # self.append(Data,label)\n",
        "        self.train_mode = train_mode\n",
        "        self.file = pds.read_pickle(path)\n",
        "        self.clip_len = clip_len\n",
        "        self.sample = UniformSampleFrames(self.clip_len)\n",
        "        \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        kp = deepcopy(self.file[index]['kp'][0])\n",
        "        # score = deepcopy(self.file[index]['keypoint_score'][0])\n",
        "        # score = np.expand_dims(score,axis = 2)\n",
        "        # kp = np.concatenate((kp,score),axis=2)\n",
        "        w, h = self.file[index]['img_shape']\n",
        "        kp[:,:,0] = (kp[:,:,0]-w/2)/(w/2)\n",
        "        kp[:,:,1] = (kp[:,:,1]-h/2)/(h/2)\n",
        "        label = deepcopy(self.file[index]['label'])\n",
        "        if self.train_mode:\n",
        "            inds = self.sample._get_train_clips(len(kp), self.clip_len)\n",
        "        else: \n",
        "            inds = self.sample._get_test_clips(len(kp), self.clip_len)\n",
        "        start_index = 5\n",
        "        inds = inds + start_index\n",
        "        inds = np.mod(inds, len(kp))\n",
        "        kp = kp[inds] \n",
        "        # if self.transform:\n",
        "            # sample=self.transform(sample)\n",
        "        return torch.from_numpy(kp).float(), label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.file)\n",
        "    \n",
        "    # def SetTrans(self,Transform):\n",
        "    #     self.transform=Transform\n",
        "    \n",
        "    # def append(self,Data):\n",
        "    #     # super().__init__()\n",
        "    #     # assert all(param is not None for param in [Data,label]),\"Data and label must be give in\"\n",
        "    #     # assert label==None,\"Label must be give\"\n",
        "    #     # kpscore = np.expand_dims(Data['keypoint_score'][0],axis=2)\n",
        "    #     kp = Data['kp'][0]\n",
        "    #     h, w = Data['img_shape']\n",
        "    #     # shapeimg=Data['img_shape']\n",
        "    #     ## normalize pic\n",
        "    #     # kp[:,:,0] = kp[:,:,0]/w\n",
        "    #     # kp[:,:,1] = kp[:,:,1]/h\n",
        "    #     kp[:,:,0] = (kp[:,:,0]-w/2)/(w/2)\n",
        "    #     kp[:,:,1] = (kp[:,:,1]-h/2)/(h/2)\n",
        "    #     #############\n",
        "    #     # data = np.concatenate((kp,kpscore),axis=2)\n",
        "    #     # data = np.expand_dims(data,axis=0)\n",
        "    #     label = Data['label']\n",
        "    #     kp = torch.from_numpy(kp).float()\n",
        "    #     label = torch.tensor(label).long()\n",
        "    #     self.feature.append(kp)\n",
        "    #     self.label.append(label)\n",
        "    #     self.leng=len(self.feature)  \n",
        "\n",
        "class ToTensor():\n",
        "    def __call__(self,sample):\n",
        "        data,label=sample\n",
        "        return torch.from_numpy(data.astype(np.float32)),torch.tensor(label)"
      ],
      "metadata": {
        "id": "YQGAJ_75J97_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Model**"
      ],
      "metadata": {
        "id": "JsDAvSMfxiic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_epoch(model=None,loss_fn=None,train_loader=None,optimizer=None,device='cuda'):\n",
        "    model.train()\n",
        "    # model.training = True\n",
        "    total_loss=0\n",
        "    for index,(data,label) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        outputs = model(data)\n",
        "        label=label.to(device).long()\n",
        "        loss = loss_fn(outputs,label)\n",
        "        total_loss+=loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    total_loss/=len(train_loader)\n",
        "    return total_loss    \n",
        "\n",
        "def Val_epoch(model=None,loss_fn=None,val_loader=None,device='cuda'):\n",
        "    device=torch.device(device if torch.cuda.is_available() else 'cpu')\n",
        "    model.eval()\n",
        "    # model.to(device)\n",
        "    total_loss = 0\n",
        "    preds = []\n",
        "    labels = []\n",
        "    model.training = True\n",
        "    with torch.no_grad():\n",
        "        for index,(data,label) in enumerate(val_loader):\n",
        "            data = data.to(device)\n",
        "            outputs = model(data)\n",
        "            label = label.to(device).long()\n",
        "            loss = loss_fn(outputs,label)\n",
        "            # pred = torch.argmax(outputs,dim=1)\n",
        "            # labels.append(label.item())\n",
        "            # preds.append(pred.item())\n",
        "            total_loss+=loss\n",
        "    total_loss/=len(val_loader)\n",
        "    #acc multi class CrossEntropy\n",
        "    # acc = eval_acc(preds,labels)\n",
        "    return total_loss\n",
        "\n",
        "def eval_acc(preds,labels):\n",
        "    n_total = len(preds)\n",
        "    print(n_total)\n",
        "    n_correct = 0\n",
        "    for pred,label in zip(preds,labels):\n",
        "        if pred == label: n_correct+=1\n",
        "        else: continue\n",
        "    acc=n_correct/n_total\n",
        "    return acc\n",
        "        "
      ],
      "metadata": {
        "id": "gcyTHzWVXANq"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TRAIN N EVAL**"
      ],
      "metadata": {
        "id": "b314GMlDxrH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_n_Eval(model:nn.Module=None,epochs=None,loss_fn=None,lr=1e-4,optim:torch.optim.SGD=None,\n",
        "                 train_dataloader=None,eval_dataloader=None,lr_shedule=False,\n",
        "                 Step=10,miles=2,Gamma=0.1,device='cuda'):\n",
        "    assert all(param is not None for param in [model,epochs,loss_fn,optim,\n",
        "                                               train_dataloader,eval_dataloader]),\"All Param must be give in\"\n",
        "    device=torch.device(device if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    optim = optim(model.parameters(),lr,momentum=0.9,nesterov=True)\n",
        "    # optim = optim(model.parameters(),lr)\n",
        "    loss_history = {\n",
        "        'train': [],\n",
        "        'val' : [],\n",
        "    }\n",
        "    best_score=0\n",
        "    if lr_shedule:\n",
        "        Multistep=[Step * i for i in range(1,miles+1)]\n",
        "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optim,Multistep,Gamma)\n",
        "    for epoch in range(1,epochs+1):\n",
        "        lr=optim.param_groups[-1]['lr']\n",
        "        train_loss = Train_epoch(model,loss_fn,train_dataloader,optim)\n",
        "        val_loss = Val_epoch(model,loss_fn,eval_dataloader)\n",
        "        loss_history['train'].append(train_loss)\n",
        "        loss_history['val'].append(val_loss)\n",
        "        # if acc > best_score:\n",
        "        #     best_score = acc\n",
        "        #     model_best_wts = copy.deepcopy(model.state_dict())\n",
        "        #     torch.save(model.state_dict(),'Model_best_wts.pt')\n",
        "            # print(\"Copied best model weights!\")\n",
        "        if lr_shedule:\n",
        "            scheduler.step()\n",
        "        print(f'Epoch: {epoch}: Learning rate: {lr}\\n \\tTrain Loss: {train_loss}\\n\\tVal Loss: {val_loss}')\n",
        "    model_final = copy.deepcopy(model.state_dict())\n",
        "    torch.save(model.state_dict(),'model_final.pth')\n",
        "    return model_final\n",
        "        "
      ],
      "metadata": {
        "id": "lLopaXEyxqE2"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Read File and Train**"
      ],
      "metadata": {
        "id": "dx-ZsbTWx5RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ActionDataset('Data/train1.pkl', train_mode=True, clip_len=100)\n",
        "val_dataset = ActionDataset('Data/Valid1.pkl',train_mode=False, clip_len=100)"
      ],
      "metadata": {
        "id": "L1a7VSElKPI9"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=ModelSTGCN(3,2)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optim=torch.optim.SGD\n",
        "# datalst1 = pds.read_pickle('Data/train1.pkl')\n",
        "# datalst2 = pds.read_pickle('Data/Valid1.pkl')\n",
        "train_dataset = ActionDataset('Data/train1.pkl', train_mode=True, clip_len=100)\n",
        "val_dataset = ActionDataset('Data/Valid1.pkl',train_mode=False, clip_len=100)\n",
        "# for data in datalst1:\n",
        "#     train_dataset.append(data)\n",
        "# for data in datalst2:\n",
        "#     val_dataset.append(data)\n",
        "train_dataloader=DataLoader(dataset=train_dataset, batch_size=30,shuffle = True)\n",
        "val_dataloader=DataLoader(dataset=val_dataset, batch_size=10,shuffle = True)\n",
        "model_best = Train_n_Eval(model=model,epochs=200,loss_fn=criterion,optim=optim,\n",
        "                                      train_dataloader=train_dataloader,eval_dataloader=val_dataloader,\n",
        "                                      lr=1e-3,lr_shedule=False,Step=15)"
      ],
      "metadata": {
        "id": "jwfzqX_hXQrp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "outputId": "76f9cd46-6cbb-4a07-bb13-74e3e01755c1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1: Learning rate: 0.001\n",
            " \tTrain Loss: 0.42411094903945923\n",
            "\tVal Loss: 0.8675338625907898\n",
            "Epoch: 2: Learning rate: 0.001\n",
            " \tTrain Loss: 0.227898508310318\n",
            "\tVal Loss: 1.0990750789642334\n",
            "Epoch: 3: Learning rate: 0.001\n",
            " \tTrain Loss: 0.2262016087770462\n",
            "\tVal Loss: 0.6008313298225403\n",
            "Epoch: 4: Learning rate: 0.001\n",
            " \tTrain Loss: 0.12597350776195526\n",
            "\tVal Loss: 0.23241327702999115\n",
            "Epoch: 5: Learning rate: 0.001\n",
            " \tTrain Loss: 0.1411658525466919\n",
            "\tVal Loss: 0.2367052137851715\n",
            "Epoch: 6: Learning rate: 0.001\n",
            " \tTrain Loss: 0.10279134660959244\n",
            "\tVal Loss: 0.22950060665607452\n",
            "Epoch: 7: Learning rate: 0.001\n",
            " \tTrain Loss: 0.09307248145341873\n",
            "\tVal Loss: 0.22711072862148285\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-c396f5c0685d>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m model_best = Train_n_Eval(model=model,epochs=200,loss_fn=criterion,optim=optim,\n\u001b[0m\u001b[1;32m     15\u001b[0m                                       \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                       lr=1e-3,lr_shedule=False,Step=15)\n",
            "\u001b[0;32m<ipython-input-52-13a005b510e7>\u001b[0m in \u001b[0;36mTrain_n_Eval\u001b[0;34m(model, epochs, loss_fn, lr, optim, train_dataloader, eval_dataloader, lr_shedule, Step, miles, Gamma, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVal_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-cf4b85c84b29>\u001b[0m in \u001b[0;36mTrain_epoch\u001b[0;34m(model, loss_fn, train_loader, optimizer, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Keep Training**"
      ],
      "metadata": {
        "id": "Q441GYYxzsg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_best,model_final = Train_n_Eval(model=model,epochs=5,loss_fn=criterion,optim=optim.SGD,\n",
        "#                                       train_dataloader=train_dataloader,eval_dataloader=val_dataloader,\n",
        "#                                       lr=1e-3,lr_shedule=True,Step=4)"
      ],
      "metadata": {
        "id": "4S1d1sq5zsBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Eval Model**"
      ],
      "metadata": {
        "id": "X-ekuSuI3snb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),'model_modify.pth')"
      ],
      "metadata": {
        "id": "utdkcztvvUoI"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # model.load_state_dict(model_best)\n",
        "# model.eval()\n",
        "# # filetest=pds.read_pickle('/content/Data/test.pkl')\n",
        "# testdata=ActionDataset('/content/Data/test.pkl',train_mode=False, clip_len=30)\n",
        "# # for data in filetest:\n",
        "# #     testdata.append(data)\n",
        "# test_loader=DataLoader(testdata,shuffle=True,batch_size = 10)\n",
        "# total_loss = 0\n",
        "# preds = []\n",
        "# labels = []\n",
        "# with torch.no_grad():\n",
        "#     for index,(data,label) in enumerate(test_loader):\n",
        "#         outputs = model(data.to('cuda'))\n",
        "#         label = label.to('cuda')\n",
        "#         loss = criterion(outputs,label)\n",
        "#         pred = torch.argmax(outputs,dim=1)\n",
        "#         # labels.append(label.item())\n",
        "#         # preds.append(pred.item())\n",
        "#         total_loss+=loss\n",
        "# total_loss/=(index + 1)\n",
        "# #acc multi class CrossEntropy\n",
        "# # acc = eval_acc(preds,labels)\n",
        "# print(f'Total Loss: {total_loss} ')"
      ],
      "metadata": {
        "id": "7w-fEo2R3uab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eKLkKT9QWmHJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}