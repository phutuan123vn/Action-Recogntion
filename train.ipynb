{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.model import ModelSTGCN\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import pandas as pds\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Uniform Sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformSampleFrames:\n",
    "    \"\"\"Uniformly sample frames from the video.\n",
    "    To sample an n-frame clip from the video. UniformSampleFrames basically\n",
    "    divide the video into n segments of equal length and randomly sample one\n",
    "    frame from each segment. To make the testing results reproducible, a\n",
    "    random seed is set during testing, to make the sampling results\n",
    "    deterministic.\n",
    "    Required keys are \"total_frames\", \"start_index\" , added or modified keys\n",
    "    are \"frame_inds\", \"clip_len\", \"frame_interval\" and \"num_clips\".\n",
    "    Args:\n",
    "        clip_len (int): Frames of each sampled output clip.\n",
    "        num_clips (int): Number of clips to be sampled. Default: 1.\n",
    "        test_mode (bool): Store True when building test or validation dataset.\n",
    "            Default: False.\n",
    "        seed (int): The random seed used during test time. Default: 255.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, clip_len, num_clips=1, test_mode=False, seed=255):\n",
    "\n",
    "        self.clip_len = clip_len\n",
    "        self.num_clips = num_clips\n",
    "        self.test_mode = test_mode\n",
    "        self.seed = seed\n",
    "\n",
    "    def _get_train_clips(self, num_frames, clip_len):\n",
    "        \"\"\"Uniformly sample indices for training clips.\n",
    "        Args:\n",
    "            num_frames (int): The number of frames.\n",
    "            clip_len (int): The length of the clip.\n",
    "        \"\"\"\n",
    "\n",
    "        assert self.num_clips == 1\n",
    "        if num_frames < clip_len:\n",
    "            start = np.random.randint(0, num_frames)\n",
    "            inds = np.arange(start, start + clip_len)\n",
    "        elif clip_len <= num_frames < 2 * clip_len:\n",
    "            basic = np.arange(clip_len)\n",
    "            inds = np.random.choice(\n",
    "                clip_len + 1, num_frames - clip_len, replace=False)\n",
    "            offset = np.zeros(clip_len + 1, dtype=np.int64)\n",
    "            offset[inds] = 1\n",
    "            offset = np.cumsum(offset)\n",
    "            inds = basic + offset[:-1]\n",
    "        else:\n",
    "            bids = np.array(\n",
    "                [i * num_frames // clip_len for i in range(clip_len + 1)])\n",
    "            bsize = np.diff(bids)\n",
    "            bst = bids[:clip_len]\n",
    "            offset = np.random.randint(bsize)\n",
    "            inds = bst + offset\n",
    "        return inds\n",
    "\n",
    "    def _get_test_clips(self, num_frames, clip_len):\n",
    "        \"\"\"Uniformly sample indices for testing clips.\n",
    "        Args:\n",
    "            num_frames (int): The number of frames.\n",
    "            clip_len (int): The length of the clip.\n",
    "        \"\"\"\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "        if num_frames < clip_len:\n",
    "            # Then we use a simple strategy\n",
    "            if num_frames < self.num_clips:\n",
    "                start_inds = list(range(self.num_clips))\n",
    "            else:\n",
    "                start_inds = [\n",
    "                    i * num_frames // self.num_clips\n",
    "                    for i in range(self.num_clips)\n",
    "                ]\n",
    "            inds = np.concatenate(\n",
    "                [np.arange(i, i + clip_len) for i in start_inds])\n",
    "        elif clip_len <= num_frames < clip_len * 2:\n",
    "            all_inds = []\n",
    "            for i in range(self.num_clips):\n",
    "                basic = np.arange(clip_len)\n",
    "                inds = np.random.choice(\n",
    "                    clip_len + 1, num_frames - clip_len, replace=False)\n",
    "                offset = np.zeros(clip_len + 1, dtype=np.int64)\n",
    "                offset[inds] = 1\n",
    "                offset = np.cumsum(offset)\n",
    "                inds = basic + offset[:-1]\n",
    "                all_inds.append(inds)\n",
    "            inds = np.concatenate(all_inds)\n",
    "        else:\n",
    "            bids = np.array(\n",
    "                [i * num_frames // clip_len for i in range(clip_len + 1)])\n",
    "            bsize = np.diff(bids)\n",
    "            bst = bids[:clip_len]\n",
    "            all_inds = []\n",
    "            for i in range(self.num_clips):\n",
    "                offset = np.random.randint(bsize)\n",
    "                all_inds.append(bst + offset)\n",
    "            inds = np.concatenate(all_inds)\n",
    "        return inds\n",
    "\n",
    "    def __call__(self, results):\n",
    "        num_frames = results['total_frames']\n",
    "\n",
    "        if self.test_mode:\n",
    "            inds = self._get_test_clips(num_frames, self.clip_len)\n",
    "        else:\n",
    "            inds = self._get_train_clips(num_frames, self.clip_len)\n",
    "\n",
    "        inds = np.mod(inds, num_frames)\n",
    "        start_index = results['start_index']\n",
    "        inds = inds + start_index\n",
    "\n",
    "        results['frame_inds'] = inds.astype(np.int64)\n",
    "        results['clip_len'] = self.clip_len\n",
    "        results['frame_interval'] = None\n",
    "        results['num_clips'] = self.num_clips\n",
    "        return results\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr_str = (f'{self.__class__.__name__}('\n",
    "                    f'clip_len={self.clip_len}, '\n",
    "                    f'num_clips={self.num_clips}, '\n",
    "                    f'test_mode={self.test_mode}, '\n",
    "                    f'seed={self.seed})')\n",
    "        return repr_str\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Action Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "class ActionDataset(Dataset):\n",
    "    def __init__(self,path, train_mode, clip_len=100):\n",
    "        # super().__init__()\n",
    "        # # assert all(param is not None for param in [Data,label]),\"Data and label must be give in\"\n",
    "        # # self.transform = Transform\n",
    "        # self.feature=[]\n",
    "        # self.label=[]\n",
    "        # # self.append(Data,label)\n",
    "        self.train_mode = train_mode\n",
    "        self.file = pds.read_pickle(path)\n",
    "        self.clip_len = clip_len\n",
    "        self.sample = UniformSampleFrames\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        kp = deepcopy(self.file[index]['keypoint'][0])\n",
    "        # score = deepcopy(self.file[index]['keypoint_score'][0])\n",
    "        # score = np.expand_dims(score,axis = 2)\n",
    "        kp = np.concatenate((kp,score),axis=2)\n",
    "        w, h = self.file[index]['img_shape']\n",
    "        kp[:,:,0] = (kp[:,:,0]-w/2)/(w/2)\n",
    "        kp[:,:,1] = (kp[:,:,1]-h/2)/(h/2)\n",
    "        label = deepcopy(self.file[index]['label'])\n",
    "        if self.train_mode:\n",
    "          inds = self.sample._get_train_clips(len(kp), self.clip_len)\n",
    "          kp = kp[inds]\n",
    "        else: \n",
    "          inds = self.sample._get_test_clips(len(kp), self.clip_len)\n",
    "          kp = kp[inds]\n",
    "        # if self.transform:\n",
    "            # sample=self.transform(sample)\n",
    "        return torch.from_numpy(kp).float(), label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file)\n",
    "    \n",
    "    # def SetTrans(self,Transform):\n",
    "    #     self.transform=Transform\n",
    "    \n",
    "    # def append(self,Data):\n",
    "    #     # super().__init__()\n",
    "    #     # assert all(param is not None for param in [Data,label]),\"Data and label must be give in\"\n",
    "    #     # assert label==None,\"Label must be give\"\n",
    "    #     # kpscore = np.expand_dims(Data['keypoint_score'][0],axis=2)\n",
    "    #     kp = Data['kp'][0]\n",
    "    #     h, w = Data['img_shape']\n",
    "    #     # shapeimg=Data['img_shape']\n",
    "    #     ## normalize pic\n",
    "    #     # kp[:,:,0] = kp[:,:,0]/w\n",
    "    #     # kp[:,:,1] = kp[:,:,1]/h\n",
    "    #     kp[:,:,0] = (kp[:,:,0]-w/2)/(w/2)\n",
    "    #     kp[:,:,1] = (kp[:,:,1]-h/2)/(h/2)\n",
    "    #     #############\n",
    "    #     # data = np.concatenate((kp,kpscore),axis=2)\n",
    "    #     # data = np.expand_dims(data,axis=0)\n",
    "    #     label = Data['label']\n",
    "    #     kp = torch.from_numpy(kp).float()\n",
    "    #     label = torch.tensor(label).long()\n",
    "    #     self.feature.append(kp)\n",
    "    #     self.label.append(label)\n",
    "    #     self.leng=len(self.feature)  \n",
    "\n",
    "class ToTensor():\n",
    "    def __call__(self,sample):\n",
    "        data,label=sample\n",
    "        return torch.from_numpy(data.astype(np.float32)),torch.tensor(label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Some Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Interpolation(kp, num_frames):\n",
    "    \"\"\"\n",
    "    Repeat frames in a keypoints numpy array using linear interpolation.\n",
    "    \n",
    "    Args:\n",
    "        kp: numpy array of shape (num_person, num_frames, num_keypoints, 3) containing keypoints data.\n",
    "        num_frames: integer representing the number of frames to interpolate to.\n",
    "        \n",
    "    Returns:\n",
    "        sampled_kp: numpy array of shape (num_person, num_frames, num_keypoints, 3) containing the interpolated keypoints.\n",
    "    \"\"\"\n",
    "    # get the number of frames in the original keypoints array\n",
    "    num_original_frames = kp.shape[1]\n",
    "    \n",
    "    # create a new array of shape (num_person, num_frames, num_keypoints, 3) to store the interpolated keypoints\n",
    "    sampled_kp = np.zeros((kp.shape[0], num_frames, kp.shape[2], kp.shape[3]))\n",
    "    \n",
    "    # loop through each person in the keypoints array\n",
    "    for person in range(kp.shape[0]):\n",
    "        # loop through each keypoint in the keypoints array\n",
    "        for kpt in range(kp.shape[2]):\n",
    "            # loop through each coordinate in the keypoint (x, y, z)\n",
    "            for coord in range(kp.shape[3]):\n",
    "                # create an array of x values representing the original frames\n",
    "                x = np.arange(num_original_frames)\n",
    "                # create an array of x values representing the new frames\n",
    "                new_x = np.linspace(0, num_original_frames-1, num_frames)\n",
    "                # use linear interpolation to calculate the y values (keypoint coordinates) at the new frames\n",
    "                new_y = np.interp(new_x, x, kp[person, :, kpt, coord])\n",
    "                # store the interpolated keypoint coordinates in the new array\n",
    "                sampled_kp[person, :, kpt, coord] = new_y\n",
    "                \n",
    "    return sampled_kp\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train Eval in 1 Epoch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_epoch(model=None,loss_fn=None,train_loader=None,optimizer=None,device='cuda'):\n",
    "    model.train()\n",
    "    # model.training = True\n",
    "    total_loss=0\n",
    "    for index,(data,label) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        outputs = model(data)\n",
    "        label=label.to(device)\n",
    "        loss = loss_fn(outputs,label)\n",
    "        total_loss+=loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    total_loss/=(index+1)\n",
    "    return total_loss    \n",
    "\n",
    "def Val_epoch(model=None,loss_fn=None,val_loader=None,device='cuda'):\n",
    "    device=torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    total_loss = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    model.training = True\n",
    "    with torch.no_grad():\n",
    "        for index,(data,label) in enumerate(val_loader):\n",
    "            data = data.to(device)\n",
    "            outputs = model(data)\n",
    "            label = label.to(device)\n",
    "            loss = loss_fn(outputs,label)\n",
    "            pred = torch.argmax(outputs,dim=1)\n",
    "            labels.append(label.item())\n",
    "            preds.append(pred.item())\n",
    "            total_loss+=loss\n",
    "    total_loss/=(index + 1)\n",
    "    #acc multi class CrossEntropy\n",
    "    acc = eval_acc(preds,labels)\n",
    "    return total_loss,acc\n",
    "\n",
    "def eval_acc(preds,labels):\n",
    "    n_total = len(preds)\n",
    "    n_correct = 0\n",
    "    for pred,label in zip(preds,labels):\n",
    "        if pred == label: n_correct+=1\n",
    "        else: continue\n",
    "    acc=n_correct/n_total\n",
    "    return acc\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train N Eval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_n_Eval(model:nn.Module=None,epochs=None,loss_fn=None,lr=1e-4,optim:torch.optim.Adam=None,\n",
    "                 train_dataloader=None,eval_dataloader=None,lr_shedule=False,\n",
    "                 Step=10,miles=2,Gamma=0.1,device='cuda'):\n",
    "    assert all(param is not None for param in [model,epochs,loss_fn,optim,\n",
    "                                               train_dataloader,eval_dataloader]),\"All Param must be give in\"\n",
    "    device=torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    # optim = optim(model.parameters(),lr,momentum=0.9,nesterov=True)\n",
    "    optim = optim(model.parameters(),lr)\n",
    "    loss_history = {\n",
    "        'train': [],\n",
    "        'val' : [],\n",
    "    }\n",
    "    best_score=0\n",
    "    if lr_shedule:\n",
    "        Multistep=[Step * i for i in range(1,miles+1)]\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optim,Multistep,Gamma)\n",
    "    for epoch in range(1,epochs+1):\n",
    "        lr=optim.param_groups[-1]['lr']\n",
    "        train_loss = Train_epoch(model,loss_fn,train_dataloader,optim)\n",
    "        val_loss = Val_epoch(model,loss_fn,eval_dataloader)\n",
    "        loss_history['train'].append(train_loss)\n",
    "        loss_history['val'].append(val_loss)\n",
    "        # if acc > best_score:\n",
    "        #     best_score = acc\n",
    "        #     model_best_wts = copy.deepcopy(model.state_dict())\n",
    "        #     torch.save(model.state_dict(),'Model_best_wts.pt')\n",
    "            # print(\"Copied best model weights!\")\n",
    "        if lr_shedule:\n",
    "            scheduler.step()\n",
    "        print(f'Epoch: {epoch}: Learning rate: {lr}\\n \\tTrain Loss: {train_loss}\\n\\tVal Loss: {val_loss}')\n",
    "    model_final = copy.deepcopy(model.state_dict())\n",
    "    torch.save(model.state_dict(),'model_final.pth')\n",
    "    return model_final\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Read File and Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ModelSTGCN(3,2)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optim=torch.optim.Adam\n",
    "# datalst1 = pds.read_pickle('Data/train1.pkl')\n",
    "# datalst2 = pds.read_pickle('Data/Valid1.pkl')\n",
    "train_dataset = ActionDataset('Data/train1.pkl', train_mode=True, clip_len=34)\n",
    "val_dataset = ActionDataset('Data/Valid1.pkl',train_mode=False, clip_len=34)\n",
    "# for data in datalst1:\n",
    "#     train_dataset.append(data)\n",
    "# for data in datalst2:\n",
    "#     val_dataset.append(data)\n",
    "train_dataloader=DataLoader(dataset=train_dataset, batch_size=40)\n",
    "val_dataloader=DataLoader(dataset=val_dataset, batch_size=10)\n",
    "model_best = Train_n_Eval(model=model,epochs=200,loss_fn=criterion,optim=optim,\n",
    "                                      train_dataloader=train_dataloader,eval_dataloader=val_dataloader,\n",
    "                                      lr=1e-3,lr_shedule=True,Step=15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Keep Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best,model_final = Train_n_Eval(model=model,epochs=10,loss_fn=criterion,optim=optim,\n",
    "                                      train_dataloader=train_dataloader,eval_dataloader=val_dataloader,\n",
    "                                      lr=1e-3,lr_shedule=False,Step=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Eval Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ModelSTGCN(3,2)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "model.load_state_dict(torch.load('model_best.pth'))\n",
    "model.cuda()\n",
    "# model.load_state_dict(model_best)\n",
    "# model.load_state_dict(model_final)\n",
    "model.eval()\n",
    "filetest=pds.read_pickle('Data/Test1.pkl')\n",
    "testdata=ActionDataset()\n",
    "for data in filetest:\n",
    "    testdata.append(data)\n",
    "test_loader=DataLoader(testdata,shuffle=False)\n",
    "total_loss = 0\n",
    "preds = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for index,(data,label) in enumerate(test_loader):\n",
    "        outputs = model(data.to('cuda'))\n",
    "        label = label.to('cuda')\n",
    "        loss = criterion(outputs,label)\n",
    "        pred = torch.argmax(outputs,dim=1)\n",
    "        labels.append(label.item())\n",
    "        preds.append(pred.item())\n",
    "        total_loss+=loss\n",
    "        # print(f'label: {label} pred: {pred} Index:{index+1}')\n",
    "total_loss/=(index + 1)\n",
    "#acc multi class CrossEntropy\n",
    "acc = eval_acc(preds,labels)\n",
    "print(f'Accuracy: {acc} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'Model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=datalst1[0]['keypoint'][0]\n",
    "# shapeimg=datalst1[0]['img_shape']\n",
    "# datalst1[0]['keypoint'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a[...,0]=a[...,0]/shapeimg[1]\n",
    "# a[...,1]=a[...,1]/shapeimg[0]\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Train_val(model=None,dataloader=None,epochs=None,lr=1e-4,lr_schedule=None):\n",
    "#     assert all(param is not None for param in [model,dataloader,epochs]),\"All param must be give in: model,dataloader,epochs\"\n",
    "#     device=torch.device('cuda')\n",
    "#     model.to(device)\n",
    "#     optim=torch.optim.Adam(model.parameters(),lr)\n",
    "#     criteria=nn.CrossEntropyLoss()\n",
    "#     # criteria=nn.BCELoss()\n",
    "#     for epoch in range(epochs):\n",
    "#         for i,(data,label) in enumerate (dataloader):\n",
    "#             output=model(data.to(device))\n",
    "#             label=label.to(device)\n",
    "#             # _,predict=torch.max(output,dim=1)\n",
    "#             loss = criteria(output,label)\n",
    "#             optim.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optim.step()\n",
    "#             print(f'Epoch: {epoch}, step: {i}/{len(dataloader)}, Loss: {loss:.5f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datalst1 = pds.read_pickle('Data/train.pkl')\n",
    "# datalst2 = pds.read_pickle('Data/val.pkl')\n",
    "# train_dataset = ActionDataset(ToTensor())\n",
    "# val_dataset = ActionDataset(ToTensor())\n",
    "# for data in datalst1:\n",
    "#     train_dataset.append(data)\n",
    "# for data in datalst2:\n",
    "#     val_dataset.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for epoch in range(2):\n",
    "# #     for i,data in enumerate (dataloader):\n",
    "# #         print(f'Epoch: {epoch}, Step: {i+1}/{len(dataloader)}, label: {data[1]}')\n",
    "# dataview=iter(dataloader)\n",
    "# data = dataview.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testfile=pds.read_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testact=ActionDataset(ToTensor())\n",
    "# testact.append(testfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.expand_copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=4\n",
    "# datalst=pds.read_pickle('train.pkl')\n",
    "# actDataset=ActionDataset(datalst[0])\n",
    "# dataloader=DataLoader(dataset=actDataset,batch_size=batch_size,shuffle=True)\n",
    "# n_sample=len(actDataset)\n",
    "# epochs=10\n",
    "# n_iter=round(n_sample/batch_size)\n",
    "# for epoch in range(epochs-8):\n",
    "#     for i,data in enumerate (dataloader):\n",
    "#         if (i+1)% (batch_size)==0:\n",
    "#             print(f'Epoch: {epoch}, Step: {i+1}/{n_iter}, Input shap: {data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# math.ceil(len(actDataset)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=4\n",
    "# datalst=pds.read_pickle('train.pkl')\n",
    "# actDataset=ActionDataset(datalst[0])\n",
    "# dataloader=DataLoader(dataset=actDataset,batch_size=batch_size,shuffle=True)\n",
    "# n_sample=len(actDataset)\n",
    "# n_iter=round(n_sample/batch_size)\n",
    "# model = ModelSTGCN(3,5)\n",
    "# lr = 1e-3\n",
    "# optim = torch.optim.Adam(model.parameters(),lr)\n",
    "# lr_schedule = torch.optim.lr_scheduler.MultiStepLR(optim,[15,30],gamma=0.1)\n",
    "# epochs = 10\n",
    "# for epoch in range(epochs):\n",
    "#     for i,data in enumerate (dataloader):\n",
    "#         if (i+1)% (batch_size)==0:\n",
    "#             print(f'Epoch: {epoch}, Step: {i+1}/{n_iter}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
