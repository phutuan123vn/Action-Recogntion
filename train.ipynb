{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.model import ModelSTGCN\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import pandas as pds\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionDataset(Dataset):\n",
    "    def __init__(self,Transform=None):\n",
    "        super().__init__()\n",
    "        # assert all(param is not None for param in [Data,label]),\"Data and label must be give in\"\n",
    "        self.transform = Transform\n",
    "        self.lst=[]\n",
    "        self.label=[]\n",
    "        # self.append(Data,label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.lst[index],self.label[index]\n",
    "        if self.transform:\n",
    "            sample=self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.leng\n",
    "    \n",
    "    def SetTrans(self,Transform):\n",
    "        self.transform=Transform\n",
    "    \n",
    "    def append(self,Data):\n",
    "        # super().__init__()\n",
    "        # assert all(param is not None for param in [Data,label]),\"Data and label must be give in\"\n",
    "        # assert label==None,\"Label must be give\"\n",
    "        kpscore = np.expand_dims(Data['kp_score'][0],axis=2)\n",
    "        kp = Data['kp'][0]\n",
    "        data = np.concatenate((kp,kpscore),axis=2)\n",
    "        # data = np.expand_dims(data,axis=0)\n",
    "        label = Data['label']\n",
    "        self.lst.append(data)\n",
    "        self.label.append(label)\n",
    "        self.leng=len(self.lst)  \n",
    "\n",
    "class ToTensor():\n",
    "    def __call__(self,sample):\n",
    "        data,label=sample\n",
    "        return torch.from_numpy(data.astype(np.float32)),torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_val(model=None,dataloader=None,epochs=None,lr=1e-4,lr_schedule=None):\n",
    "    assert all(param is not None for param in [model,dataloader,epochs]),\"All param must be give in: model,dataloader,epochs\"\n",
    "    device=torch.device('cuda')\n",
    "    model.to(device)\n",
    "    optim=torch.optim.Adam(model.parameters(),lr)\n",
    "    criteria=nn.CrossEntropyLoss()\n",
    "    # criteria=nn.BCELoss()\n",
    "    for epoch in range(epochs):\n",
    "        for i,(data,label) in enumerate (dataloader):\n",
    "            output=model(data.to(device))\n",
    "            label=label.to(device)\n",
    "            # _,predict=torch.max(output,dim=1)\n",
    "            loss = criteria(output,label)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            print(f'Epoch: {epoch}, step: {i}/{len(dataloader)}, Loss: {loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalst=pds.read_pickle('train.pkl')\n",
    "actDataset=ActionDataset(ToTensor())\n",
    "for data in datalst:\n",
    "    actDataset.append(data)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, step: 0/300, Loss: 1.28960\n",
      "Epoch: 0, step: 1/300, Loss: 1.00683\n",
      "Epoch: 0, step: 2/300, Loss: 0.77650\n",
      "Epoch: 0, step: 3/300, Loss: 0.98086\n",
      "Epoch: 0, step: 4/300, Loss: 0.61973\n",
      "Epoch: 0, step: 5/300, Loss: 0.43845\n",
      "Epoch: 0, step: 6/300, Loss: 1.11863\n",
      "Epoch: 0, step: 7/300, Loss: 0.94405\n",
      "Epoch: 0, step: 8/300, Loss: 0.92631\n",
      "Epoch: 0, step: 9/300, Loss: 0.57284\n",
      "Epoch: 0, step: 10/300, Loss: 0.48638\n",
      "Epoch: 0, step: 11/300, Loss: 0.82558\n",
      "Epoch: 0, step: 12/300, Loss: 0.92353\n",
      "Epoch: 0, step: 13/300, Loss: 0.51953\n",
      "Epoch: 0, step: 14/300, Loss: 0.51706\n",
      "Epoch: 0, step: 15/300, Loss: 0.60638\n",
      "Epoch: 0, step: 16/300, Loss: 0.82432\n",
      "Epoch: 0, step: 17/300, Loss: 0.39549\n",
      "Epoch: 0, step: 18/300, Loss: 1.05845\n",
      "Epoch: 0, step: 19/300, Loss: 0.38261\n",
      "Epoch: 0, step: 20/300, Loss: 0.38169\n",
      "Epoch: 0, step: 21/300, Loss: 0.32370\n",
      "Epoch: 0, step: 22/300, Loss: 1.01604\n",
      "Epoch: 0, step: 23/300, Loss: 0.24156\n",
      "Epoch: 0, step: 24/300, Loss: 0.37343\n",
      "Epoch: 0, step: 25/300, Loss: 0.39336\n",
      "Epoch: 0, step: 26/300, Loss: 0.23155\n",
      "Epoch: 0, step: 27/300, Loss: 0.26181\n",
      "Epoch: 0, step: 28/300, Loss: 0.16047\n",
      "Epoch: 0, step: 29/300, Loss: 0.20606\n",
      "Epoch: 0, step: 30/300, Loss: 1.33717\n",
      "Epoch: 0, step: 31/300, Loss: 1.31993\n",
      "Epoch: 0, step: 32/300, Loss: 0.31110\n",
      "Epoch: 0, step: 33/300, Loss: 0.16699\n",
      "Epoch: 0, step: 34/300, Loss: 1.49488\n",
      "Epoch: 0, step: 35/300, Loss: 0.20006\n",
      "Epoch: 0, step: 36/300, Loss: 1.09903\n",
      "Epoch: 0, step: 37/300, Loss: 1.17720\n",
      "Epoch: 0, step: 38/300, Loss: 0.19192\n",
      "Epoch: 0, step: 39/300, Loss: 0.34583\n",
      "Epoch: 0, step: 40/300, Loss: 0.58863\n",
      "Epoch: 0, step: 41/300, Loss: 0.32629\n",
      "Epoch: 0, step: 42/300, Loss: 0.85637\n",
      "Epoch: 0, step: 43/300, Loss: 0.47772\n",
      "Epoch: 0, step: 44/300, Loss: 0.67041\n",
      "Epoch: 0, step: 45/300, Loss: 0.24945\n",
      "Epoch: 0, step: 46/300, Loss: 0.40653\n",
      "Epoch: 0, step: 47/300, Loss: 0.36074\n",
      "Epoch: 0, step: 48/300, Loss: 0.40426\n",
      "Epoch: 0, step: 49/300, Loss: 1.34816\n",
      "Epoch: 0, step: 50/300, Loss: 0.61325\n",
      "Epoch: 0, step: 51/300, Loss: 0.41160\n",
      "Epoch: 0, step: 52/300, Loss: 0.30958\n",
      "Epoch: 0, step: 53/300, Loss: 0.28876\n",
      "Epoch: 0, step: 54/300, Loss: 0.26949\n",
      "Epoch: 0, step: 55/300, Loss: 0.83616\n",
      "Epoch: 0, step: 56/300, Loss: 0.61385\n",
      "Epoch: 0, step: 57/300, Loss: 0.43968\n",
      "Epoch: 0, step: 58/300, Loss: 0.18490\n",
      "Epoch: 0, step: 59/300, Loss: 1.40331\n",
      "Epoch: 0, step: 60/300, Loss: 0.30819\n",
      "Epoch: 0, step: 61/300, Loss: 0.41030\n",
      "Epoch: 0, step: 62/300, Loss: 0.50155\n",
      "Epoch: 0, step: 63/300, Loss: 0.64741\n",
      "Epoch: 0, step: 64/300, Loss: 0.33918\n",
      "Epoch: 0, step: 65/300, Loss: 0.15941\n",
      "Epoch: 0, step: 66/300, Loss: 1.35416\n",
      "Epoch: 0, step: 67/300, Loss: 0.27777\n",
      "Epoch: 0, step: 68/300, Loss: 0.93436\n",
      "Epoch: 0, step: 69/300, Loss: 0.81019\n",
      "Epoch: 0, step: 70/300, Loss: 0.29323\n",
      "Epoch: 0, step: 71/300, Loss: 0.44857\n",
      "Epoch: 0, step: 72/300, Loss: 0.27432\n",
      "Epoch: 0, step: 73/300, Loss: 0.30037\n",
      "Epoch: 0, step: 74/300, Loss: 0.68949\n",
      "Epoch: 0, step: 75/300, Loss: 0.35479\n",
      "Epoch: 0, step: 76/300, Loss: 0.28108\n",
      "Epoch: 0, step: 77/300, Loss: 0.73904\n",
      "Epoch: 0, step: 78/300, Loss: 0.14491\n",
      "Epoch: 0, step: 79/300, Loss: 0.27262\n",
      "Epoch: 0, step: 80/300, Loss: 0.30490\n",
      "Epoch: 0, step: 81/300, Loss: 0.26328\n",
      "Epoch: 0, step: 82/300, Loss: 1.42660\n",
      "Epoch: 0, step: 83/300, Loss: 0.17035\n",
      "Epoch: 0, step: 84/300, Loss: 0.09679\n",
      "Epoch: 0, step: 85/300, Loss: 0.43882\n",
      "Epoch: 0, step: 86/300, Loss: 0.08383\n",
      "Epoch: 0, step: 87/300, Loss: 0.45880\n",
      "Epoch: 0, step: 88/300, Loss: 0.69885\n",
      "Epoch: 0, step: 89/300, Loss: 0.24574\n",
      "Epoch: 0, step: 90/300, Loss: 0.29973\n",
      "Epoch: 0, step: 91/300, Loss: 0.45799\n",
      "Epoch: 0, step: 92/300, Loss: 0.32827\n",
      "Epoch: 0, step: 93/300, Loss: 0.69830\n",
      "Epoch: 0, step: 94/300, Loss: 0.96937\n",
      "Epoch: 0, step: 95/300, Loss: 0.41271\n",
      "Epoch: 0, step: 96/300, Loss: 0.24030\n",
      "Epoch: 0, step: 97/300, Loss: 0.25998\n",
      "Epoch: 0, step: 98/300, Loss: 0.71244\n",
      "Epoch: 0, step: 99/300, Loss: 0.64470\n",
      "Epoch: 0, step: 100/300, Loss: 1.13291\n",
      "Epoch: 0, step: 101/300, Loss: 0.06483\n",
      "Epoch: 0, step: 102/300, Loss: 0.96765\n",
      "Epoch: 0, step: 103/300, Loss: 0.38420\n",
      "Epoch: 0, step: 104/300, Loss: 0.24879\n",
      "Epoch: 0, step: 105/300, Loss: 0.83358\n",
      "Epoch: 0, step: 106/300, Loss: 0.04093\n",
      "Epoch: 0, step: 107/300, Loss: 0.84526\n",
      "Epoch: 0, step: 108/300, Loss: 0.04757\n",
      "Epoch: 0, step: 109/300, Loss: 0.04375\n",
      "Epoch: 0, step: 110/300, Loss: 0.03124\n",
      "Epoch: 0, step: 111/300, Loss: 2.27586\n",
      "Epoch: 0, step: 112/300, Loss: 1.26054\n",
      "Epoch: 0, step: 113/300, Loss: 1.65634\n",
      "Epoch: 0, step: 114/300, Loss: 0.44984\n",
      "Epoch: 0, step: 115/300, Loss: 0.97542\n",
      "Epoch: 0, step: 116/300, Loss: 1.18869\n",
      "Epoch: 0, step: 117/300, Loss: 0.17130\n",
      "Epoch: 0, step: 118/300, Loss: 0.74973\n",
      "Epoch: 0, step: 119/300, Loss: 1.11626\n",
      "Epoch: 0, step: 120/300, Loss: 1.09210\n",
      "Epoch: 0, step: 121/300, Loss: 0.32271\n",
      "Epoch: 0, step: 122/300, Loss: 0.30724\n",
      "Epoch: 0, step: 123/300, Loss: 0.42473\n",
      "Epoch: 0, step: 124/300, Loss: 1.67352\n",
      "Epoch: 0, step: 125/300, Loss: 0.22134\n",
      "Epoch: 0, step: 126/300, Loss: 0.39343\n",
      "Epoch: 0, step: 127/300, Loss: 0.31597\n",
      "Epoch: 0, step: 128/300, Loss: 0.32719\n",
      "Epoch: 0, step: 129/300, Loss: 0.26075\n",
      "Epoch: 0, step: 130/300, Loss: 0.75187\n",
      "Epoch: 0, step: 131/300, Loss: 0.40739\n",
      "Epoch: 0, step: 132/300, Loss: 0.15782\n",
      "Epoch: 0, step: 133/300, Loss: 0.36623\n",
      "Epoch: 0, step: 134/300, Loss: 0.30410\n",
      "Epoch: 0, step: 135/300, Loss: 0.29484\n",
      "Epoch: 0, step: 136/300, Loss: 0.44319\n",
      "Epoch: 0, step: 137/300, Loss: 0.32253\n",
      "Epoch: 0, step: 138/300, Loss: 0.19034\n",
      "Epoch: 0, step: 139/300, Loss: 0.23683\n",
      "Epoch: 0, step: 140/300, Loss: 1.05066\n",
      "Epoch: 0, step: 141/300, Loss: 0.21454\n",
      "Epoch: 0, step: 142/300, Loss: 0.33412\n",
      "Epoch: 0, step: 143/300, Loss: 0.42667\n",
      "Epoch: 0, step: 144/300, Loss: 0.06700\n",
      "Epoch: 0, step: 145/300, Loss: 0.38512\n",
      "Epoch: 0, step: 146/300, Loss: 0.15156\n",
      "Epoch: 0, step: 147/300, Loss: 0.36706\n",
      "Epoch: 0, step: 148/300, Loss: 0.16949\n",
      "Epoch: 0, step: 149/300, Loss: 0.61202\n",
      "Epoch: 0, step: 150/300, Loss: 2.05890\n",
      "Epoch: 0, step: 151/300, Loss: 2.28888\n",
      "Epoch: 0, step: 152/300, Loss: 0.18053\n",
      "Epoch: 0, step: 153/300, Loss: 0.29655\n",
      "Epoch: 0, step: 154/300, Loss: 0.16530\n",
      "Epoch: 0, step: 155/300, Loss: 0.16759\n",
      "Epoch: 0, step: 156/300, Loss: 1.09535\n",
      "Epoch: 0, step: 157/300, Loss: 1.42929\n",
      "Epoch: 0, step: 158/300, Loss: 0.35114\n",
      "Epoch: 0, step: 159/300, Loss: 0.14371\n",
      "Epoch: 0, step: 160/300, Loss: 0.48986\n",
      "Epoch: 0, step: 161/300, Loss: 0.24382\n",
      "Epoch: 0, step: 162/300, Loss: 0.24155\n",
      "Epoch: 0, step: 163/300, Loss: 0.54786\n",
      "Epoch: 0, step: 164/300, Loss: 1.00360\n",
      "Epoch: 0, step: 165/300, Loss: 0.23590\n",
      "Epoch: 0, step: 166/300, Loss: 0.41689\n",
      "Epoch: 0, step: 167/300, Loss: 0.50481\n",
      "Epoch: 0, step: 168/300, Loss: 0.11151\n",
      "Epoch: 0, step: 169/300, Loss: 0.17337\n",
      "Epoch: 0, step: 170/300, Loss: 0.31544\n",
      "Epoch: 0, step: 171/300, Loss: 0.19747\n",
      "Epoch: 0, step: 172/300, Loss: 0.75616\n",
      "Epoch: 0, step: 173/300, Loss: 0.97097\n",
      "Epoch: 0, step: 174/300, Loss: 0.35754\n",
      "Epoch: 0, step: 175/300, Loss: 0.13280\n",
      "Epoch: 0, step: 176/300, Loss: 0.29608\n",
      "Epoch: 0, step: 177/300, Loss: 0.29749\n",
      "Epoch: 0, step: 178/300, Loss: 0.58665\n",
      "Epoch: 0, step: 179/300, Loss: 0.30826\n",
      "Epoch: 0, step: 180/300, Loss: 0.47343\n",
      "Epoch: 0, step: 181/300, Loss: 0.16103\n",
      "Epoch: 0, step: 182/300, Loss: 0.12606\n",
      "Epoch: 0, step: 183/300, Loss: 0.19964\n",
      "Epoch: 0, step: 184/300, Loss: 0.35721\n",
      "Epoch: 0, step: 185/300, Loss: 2.15827\n",
      "Epoch: 0, step: 186/300, Loss: 0.06237\n",
      "Epoch: 0, step: 187/300, Loss: 0.28158\n",
      "Epoch: 0, step: 188/300, Loss: 0.10794\n",
      "Epoch: 0, step: 189/300, Loss: 0.29167\n",
      "Epoch: 0, step: 190/300, Loss: 0.44901\n",
      "Epoch: 0, step: 191/300, Loss: 0.18479\n",
      "Epoch: 0, step: 192/300, Loss: 0.15550\n",
      "Epoch: 0, step: 193/300, Loss: 0.51491\n",
      "Epoch: 0, step: 194/300, Loss: 0.12889\n",
      "Epoch: 0, step: 195/300, Loss: 0.15447\n",
      "Epoch: 0, step: 196/300, Loss: 0.20244\n",
      "Epoch: 0, step: 197/300, Loss: 0.26781\n",
      "Epoch: 0, step: 198/300, Loss: 1.85662\n",
      "Epoch: 0, step: 199/300, Loss: 0.11003\n",
      "Epoch: 0, step: 200/300, Loss: 0.25779\n",
      "Epoch: 0, step: 201/300, Loss: 0.81038\n",
      "Epoch: 0, step: 202/300, Loss: 0.24583\n",
      "Epoch: 0, step: 203/300, Loss: 0.20658\n",
      "Epoch: 0, step: 204/300, Loss: 2.00073\n",
      "Epoch: 0, step: 205/300, Loss: 0.02816\n",
      "Epoch: 0, step: 206/300, Loss: 1.23381\n",
      "Epoch: 0, step: 207/300, Loss: 0.41353\n",
      "Epoch: 0, step: 208/300, Loss: 0.34542\n",
      "Epoch: 0, step: 209/300, Loss: 2.13787\n",
      "Epoch: 0, step: 210/300, Loss: 0.15957\n",
      "Epoch: 0, step: 211/300, Loss: 0.22017\n",
      "Epoch: 0, step: 212/300, Loss: 0.13408\n",
      "Epoch: 0, step: 213/300, Loss: 0.11943\n",
      "Epoch: 0, step: 214/300, Loss: 0.18978\n",
      "Epoch: 0, step: 215/300, Loss: 0.29550\n",
      "Epoch: 0, step: 216/300, Loss: 0.35041\n",
      "Epoch: 0, step: 217/300, Loss: 0.25825\n",
      "Epoch: 0, step: 218/300, Loss: 1.05840\n",
      "Epoch: 0, step: 219/300, Loss: 1.79774\n",
      "Epoch: 0, step: 220/300, Loss: 0.41732\n",
      "Epoch: 0, step: 221/300, Loss: 0.43071\n",
      "Epoch: 0, step: 222/300, Loss: 0.30290\n",
      "Epoch: 0, step: 223/300, Loss: 0.38448\n",
      "Epoch: 0, step: 224/300, Loss: 0.71139\n",
      "Epoch: 0, step: 225/300, Loss: 0.38417\n",
      "Epoch: 0, step: 226/300, Loss: 0.27875\n",
      "Epoch: 0, step: 227/300, Loss: 0.49106\n",
      "Epoch: 0, step: 228/300, Loss: 0.08380\n",
      "Epoch: 0, step: 229/300, Loss: 1.55007\n",
      "Epoch: 0, step: 230/300, Loss: 0.42667\n",
      "Epoch: 0, step: 231/300, Loss: 1.24765\n",
      "Epoch: 0, step: 232/300, Loss: 0.27943\n",
      "Epoch: 0, step: 233/300, Loss: 0.70259\n",
      "Epoch: 0, step: 234/300, Loss: 0.24535\n",
      "Epoch: 0, step: 235/300, Loss: 0.28487\n",
      "Epoch: 0, step: 236/300, Loss: 0.80716\n",
      "Epoch: 0, step: 237/300, Loss: 0.12994\n",
      "Epoch: 0, step: 238/300, Loss: 1.28658\n",
      "Epoch: 0, step: 239/300, Loss: 0.23350\n",
      "Epoch: 0, step: 240/300, Loss: 0.12886\n",
      "Epoch: 0, step: 241/300, Loss: 0.19160\n",
      "Epoch: 0, step: 242/300, Loss: 0.39743\n",
      "Epoch: 0, step: 243/300, Loss: 0.18147\n",
      "Epoch: 0, step: 244/300, Loss: 0.13920\n",
      "Epoch: 0, step: 245/300, Loss: 0.22805\n",
      "Epoch: 0, step: 246/300, Loss: 0.12247\n",
      "Epoch: 0, step: 247/300, Loss: 0.15296\n",
      "Epoch: 0, step: 248/300, Loss: 0.71293\n",
      "Epoch: 0, step: 249/300, Loss: 1.71305\n",
      "Epoch: 0, step: 250/300, Loss: 0.21804\n",
      "Epoch: 0, step: 251/300, Loss: 0.50946\n",
      "Epoch: 0, step: 252/300, Loss: 0.18811\n",
      "Epoch: 0, step: 253/300, Loss: 0.67667\n",
      "Epoch: 0, step: 254/300, Loss: 0.66279\n",
      "Epoch: 0, step: 255/300, Loss: 1.24413\n",
      "Epoch: 0, step: 256/300, Loss: 0.16010\n",
      "Epoch: 0, step: 257/300, Loss: 1.39673\n",
      "Epoch: 0, step: 258/300, Loss: 0.49519\n",
      "Epoch: 0, step: 259/300, Loss: 0.61281\n",
      "Epoch: 0, step: 260/300, Loss: 1.00955\n",
      "Epoch: 0, step: 261/300, Loss: 0.17522\n",
      "Epoch: 0, step: 262/300, Loss: 0.76252\n",
      "Epoch: 0, step: 263/300, Loss: 0.15039\n",
      "Epoch: 0, step: 264/300, Loss: 0.25214\n",
      "Epoch: 0, step: 265/300, Loss: 0.69715\n",
      "Epoch: 0, step: 266/300, Loss: 0.41119\n",
      "Epoch: 0, step: 267/300, Loss: 0.23946\n",
      "Epoch: 0, step: 268/300, Loss: 0.55148\n",
      "Epoch: 0, step: 269/300, Loss: 0.55480\n",
      "Epoch: 0, step: 270/300, Loss: 0.53361\n",
      "Epoch: 0, step: 271/300, Loss: 0.60334\n",
      "Epoch: 0, step: 272/300, Loss: 0.56098\n",
      "Epoch: 0, step: 273/300, Loss: 0.55438\n",
      "Epoch: 0, step: 274/300, Loss: 1.23027\n",
      "Epoch: 0, step: 275/300, Loss: 0.42391\n",
      "Epoch: 0, step: 276/300, Loss: 0.37516\n",
      "Epoch: 0, step: 277/300, Loss: 0.62894\n",
      "Epoch: 0, step: 278/300, Loss: 1.55331\n",
      "Epoch: 0, step: 279/300, Loss: 0.26815\n",
      "Epoch: 0, step: 280/300, Loss: 1.42833\n",
      "Epoch: 0, step: 281/300, Loss: 1.63471\n",
      "Epoch: 0, step: 282/300, Loss: 1.32126\n",
      "Epoch: 0, step: 283/300, Loss: 0.49873\n",
      "Epoch: 0, step: 284/300, Loss: 0.38201\n",
      "Epoch: 0, step: 285/300, Loss: 1.19556\n",
      "Epoch: 0, step: 286/300, Loss: 0.28807\n",
      "Epoch: 0, step: 287/300, Loss: 1.11577\n",
      "Epoch: 0, step: 288/300, Loss: 0.45274\n",
      "Epoch: 0, step: 289/300, Loss: 0.23787\n",
      "Epoch: 0, step: 290/300, Loss: 0.51081\n",
      "Epoch: 0, step: 291/300, Loss: 0.62559\n",
      "Epoch: 0, step: 292/300, Loss: 0.27582\n",
      "Epoch: 0, step: 293/300, Loss: 1.54508\n",
      "Epoch: 0, step: 294/300, Loss: 0.18172\n",
      "Epoch: 0, step: 295/300, Loss: 1.02667\n",
      "Epoch: 0, step: 296/300, Loss: 0.82915\n",
      "Epoch: 0, step: 297/300, Loss: 0.26297\n",
      "Epoch: 0, step: 298/300, Loss: 0.26205\n",
      "Epoch: 0, step: 299/300, Loss: 0.35768\n",
      "Epoch: 1, step: 0/300, Loss: 0.72751\n",
      "Epoch: 1, step: 1/300, Loss: 0.79873\n",
      "Epoch: 1, step: 2/300, Loss: 0.41423\n",
      "Epoch: 1, step: 3/300, Loss: 0.55954\n",
      "Epoch: 1, step: 4/300, Loss: 0.64915\n",
      "Epoch: 1, step: 5/300, Loss: 0.35960\n",
      "Epoch: 1, step: 6/300, Loss: 0.51930\n",
      "Epoch: 1, step: 7/300, Loss: 0.48767\n",
      "Epoch: 1, step: 8/300, Loss: 0.80187\n",
      "Epoch: 1, step: 9/300, Loss: 0.47869\n",
      "Epoch: 1, step: 10/300, Loss: 0.87759\n",
      "Epoch: 1, step: 11/300, Loss: 0.20131\n",
      "Epoch: 1, step: 12/300, Loss: 0.25280\n",
      "Epoch: 1, step: 13/300, Loss: 0.23101\n",
      "Epoch: 1, step: 14/300, Loss: 0.37823\n",
      "Epoch: 1, step: 15/300, Loss: 0.32264\n",
      "Epoch: 1, step: 16/300, Loss: 0.23599\n",
      "Epoch: 1, step: 17/300, Loss: 0.19600\n",
      "Epoch: 1, step: 18/300, Loss: 0.30230\n",
      "Epoch: 1, step: 19/300, Loss: 0.36974\n",
      "Epoch: 1, step: 20/300, Loss: 0.12574\n",
      "Epoch: 1, step: 21/300, Loss: 1.28992\n",
      "Epoch: 1, step: 22/300, Loss: 0.28297\n",
      "Epoch: 1, step: 23/300, Loss: 0.50822\n",
      "Epoch: 1, step: 24/300, Loss: 0.47693\n",
      "Epoch: 1, step: 25/300, Loss: 0.25593\n",
      "Epoch: 1, step: 26/300, Loss: 0.29670\n",
      "Epoch: 1, step: 27/300, Loss: 0.21792\n",
      "Epoch: 1, step: 28/300, Loss: 0.05797\n",
      "Epoch: 1, step: 29/300, Loss: 0.25518\n",
      "Epoch: 1, step: 30/300, Loss: 0.13053\n",
      "Epoch: 1, step: 31/300, Loss: 0.08602\n",
      "Epoch: 1, step: 32/300, Loss: 0.10226\n",
      "Epoch: 1, step: 33/300, Loss: 0.16749\n",
      "Epoch: 1, step: 34/300, Loss: 0.07787\n",
      "Epoch: 1, step: 35/300, Loss: 0.06075\n",
      "Epoch: 1, step: 36/300, Loss: 0.76639\n",
      "Epoch: 1, step: 37/300, Loss: 0.54127\n",
      "Epoch: 1, step: 38/300, Loss: 0.19964\n",
      "Epoch: 1, step: 39/300, Loss: 0.36000\n",
      "Epoch: 1, step: 40/300, Loss: 0.28180\n",
      "Epoch: 1, step: 41/300, Loss: 0.05382\n",
      "Epoch: 1, step: 42/300, Loss: 0.74719\n",
      "Epoch: 1, step: 43/300, Loss: 0.04917\n",
      "Epoch: 1, step: 44/300, Loss: 0.06971\n",
      "Epoch: 1, step: 45/300, Loss: 0.09896\n",
      "Epoch: 1, step: 46/300, Loss: 0.04675\n",
      "Epoch: 1, step: 47/300, Loss: 2.39050\n",
      "Epoch: 1, step: 48/300, Loss: 0.38399\n",
      "Epoch: 1, step: 49/300, Loss: 0.04764\n",
      "Epoch: 1, step: 50/300, Loss: 0.13826\n",
      "Epoch: 1, step: 51/300, Loss: 0.36081\n",
      "Epoch: 1, step: 52/300, Loss: 0.12892\n",
      "Epoch: 1, step: 53/300, Loss: 0.10671\n",
      "Epoch: 1, step: 54/300, Loss: 0.16870\n",
      "Epoch: 1, step: 55/300, Loss: 0.06583\n",
      "Epoch: 1, step: 56/300, Loss: 0.30671\n",
      "Epoch: 1, step: 57/300, Loss: 0.72866\n",
      "Epoch: 1, step: 58/300, Loss: 0.06607\n",
      "Epoch: 1, step: 59/300, Loss: 0.13401\n",
      "Epoch: 1, step: 60/300, Loss: 1.30947\n",
      "Epoch: 1, step: 61/300, Loss: 0.03878\n",
      "Epoch: 1, step: 62/300, Loss: 0.03245\n",
      "Epoch: 1, step: 63/300, Loss: 0.44472\n",
      "Epoch: 1, step: 64/300, Loss: 0.11142\n",
      "Epoch: 1, step: 65/300, Loss: 0.04008\n",
      "Epoch: 1, step: 66/300, Loss: 0.14940\n",
      "Epoch: 1, step: 67/300, Loss: 0.21867\n",
      "Epoch: 1, step: 68/300, Loss: 0.12965\n",
      "Epoch: 1, step: 69/300, Loss: 0.04605\n",
      "Epoch: 1, step: 70/300, Loss: 0.03162\n",
      "Epoch: 1, step: 71/300, Loss: 0.10205\n",
      "Epoch: 1, step: 72/300, Loss: 0.11516\n",
      "Epoch: 1, step: 73/300, Loss: 0.20834\n",
      "Epoch: 1, step: 74/300, Loss: 0.11069\n",
      "Epoch: 1, step: 75/300, Loss: 0.03374\n",
      "Epoch: 1, step: 76/300, Loss: 0.07913\n",
      "Epoch: 1, step: 77/300, Loss: 2.10910\n",
      "Epoch: 1, step: 78/300, Loss: 0.58570\n",
      "Epoch: 1, step: 79/300, Loss: 0.69726\n",
      "Epoch: 1, step: 80/300, Loss: 0.52481\n",
      "Epoch: 1, step: 81/300, Loss: 0.04470\n",
      "Epoch: 1, step: 82/300, Loss: 2.03351\n",
      "Epoch: 1, step: 83/300, Loss: 0.10226\n",
      "Epoch: 1, step: 84/300, Loss: 0.03057\n",
      "Epoch: 1, step: 85/300, Loss: 0.03039\n",
      "Epoch: 1, step: 86/300, Loss: 0.15292\n",
      "Epoch: 1, step: 87/300, Loss: 0.05634\n",
      "Epoch: 1, step: 88/300, Loss: 0.06395\n",
      "Epoch: 1, step: 89/300, Loss: 1.06790\n",
      "Epoch: 1, step: 90/300, Loss: 0.08181\n",
      "Epoch: 1, step: 91/300, Loss: 0.05433\n",
      "Epoch: 1, step: 92/300, Loss: 0.18026\n",
      "Epoch: 1, step: 93/300, Loss: 0.04184\n",
      "Epoch: 1, step: 94/300, Loss: 0.05860\n",
      "Epoch: 1, step: 95/300, Loss: 0.05374\n",
      "Epoch: 1, step: 96/300, Loss: 2.94044\n",
      "Epoch: 1, step: 97/300, Loss: 0.04766\n",
      "Epoch: 1, step: 98/300, Loss: 0.03857\n",
      "Epoch: 1, step: 99/300, Loss: 0.06744\n",
      "Epoch: 1, step: 100/300, Loss: 0.11067\n",
      "Epoch: 1, step: 101/300, Loss: 0.04161\n",
      "Epoch: 1, step: 102/300, Loss: 0.03367\n",
      "Epoch: 1, step: 103/300, Loss: 0.40564\n",
      "Epoch: 1, step: 104/300, Loss: 1.53330\n",
      "Epoch: 1, step: 105/300, Loss: 0.02280\n",
      "Epoch: 1, step: 106/300, Loss: 0.15044\n",
      "Epoch: 1, step: 107/300, Loss: 0.29433\n",
      "Epoch: 1, step: 108/300, Loss: 0.03108\n",
      "Epoch: 1, step: 109/300, Loss: 0.38106\n",
      "Epoch: 1, step: 110/300, Loss: 0.61692\n",
      "Epoch: 1, step: 111/300, Loss: 0.27102\n",
      "Epoch: 1, step: 112/300, Loss: 0.02049\n",
      "Epoch: 1, step: 113/300, Loss: 0.01883\n",
      "Epoch: 1, step: 114/300, Loss: 0.33856\n",
      "Epoch: 1, step: 115/300, Loss: 0.04125\n",
      "Epoch: 1, step: 116/300, Loss: 0.79748\n",
      "Epoch: 1, step: 117/300, Loss: 0.21874\n",
      "Epoch: 1, step: 118/300, Loss: 0.68183\n",
      "Epoch: 1, step: 119/300, Loss: 0.01107\n",
      "Epoch: 1, step: 120/300, Loss: 1.04353\n",
      "Epoch: 1, step: 121/300, Loss: 0.22586\n",
      "Epoch: 1, step: 122/300, Loss: 0.60536\n",
      "Epoch: 1, step: 123/300, Loss: 0.28419\n",
      "Epoch: 1, step: 124/300, Loss: 0.18061\n",
      "Epoch: 1, step: 125/300, Loss: 0.19976\n",
      "Epoch: 1, step: 126/300, Loss: 0.11916\n",
      "Epoch: 1, step: 127/300, Loss: 0.08997\n",
      "Epoch: 1, step: 128/300, Loss: 0.05246\n",
      "Epoch: 1, step: 129/300, Loss: 0.09242\n",
      "Epoch: 1, step: 130/300, Loss: 1.22289\n",
      "Epoch: 1, step: 131/300, Loss: 0.07538\n",
      "Epoch: 1, step: 132/300, Loss: 0.24772\n",
      "Epoch: 1, step: 133/300, Loss: 0.09062\n",
      "Epoch: 1, step: 134/300, Loss: 0.06728\n",
      "Epoch: 1, step: 135/300, Loss: 0.15430\n",
      "Epoch: 1, step: 136/300, Loss: 1.56278\n",
      "Epoch: 1, step: 137/300, Loss: 2.44269\n",
      "Epoch: 1, step: 138/300, Loss: 2.01725\n",
      "Epoch: 1, step: 139/300, Loss: 0.11370\n",
      "Epoch: 1, step: 140/300, Loss: 0.26647\n",
      "Epoch: 1, step: 141/300, Loss: 0.02603\n",
      "Epoch: 1, step: 142/300, Loss: 0.11075\n",
      "Epoch: 1, step: 143/300, Loss: 0.07697\n",
      "Epoch: 1, step: 144/300, Loss: 0.56847\n",
      "Epoch: 1, step: 145/300, Loss: 0.03454\n",
      "Epoch: 1, step: 146/300, Loss: 0.82611\n",
      "Epoch: 1, step: 147/300, Loss: 0.52418\n",
      "Epoch: 1, step: 148/300, Loss: 0.06555\n",
      "Epoch: 1, step: 149/300, Loss: 0.60103\n",
      "Epoch: 1, step: 150/300, Loss: 0.48016\n",
      "Epoch: 1, step: 151/300, Loss: 2.56075\n",
      "Epoch: 1, step: 152/300, Loss: 1.16397\n",
      "Epoch: 1, step: 153/300, Loss: 0.11909\n",
      "Epoch: 1, step: 154/300, Loss: 0.06691\n",
      "Epoch: 1, step: 155/300, Loss: 0.03039\n",
      "Epoch: 1, step: 156/300, Loss: 2.42701\n",
      "Epoch: 1, step: 157/300, Loss: 0.93522\n",
      "Epoch: 1, step: 158/300, Loss: 0.12928\n",
      "Epoch: 1, step: 159/300, Loss: 0.52460\n",
      "Epoch: 1, step: 160/300, Loss: 0.10786\n",
      "Epoch: 1, step: 161/300, Loss: 0.11220\n",
      "Epoch: 1, step: 162/300, Loss: 0.19153\n",
      "Epoch: 1, step: 163/300, Loss: 0.41112\n",
      "Epoch: 1, step: 164/300, Loss: 0.09731\n",
      "Epoch: 1, step: 165/300, Loss: 0.26595\n",
      "Epoch: 1, step: 166/300, Loss: 0.16354\n",
      "Epoch: 1, step: 167/300, Loss: 0.12176\n",
      "Epoch: 1, step: 168/300, Loss: 0.12639\n",
      "Epoch: 1, step: 169/300, Loss: 0.72859\n",
      "Epoch: 1, step: 170/300, Loss: 0.14276\n",
      "Epoch: 1, step: 171/300, Loss: 0.38364\n",
      "Epoch: 1, step: 172/300, Loss: 0.28766\n",
      "Epoch: 1, step: 173/300, Loss: 0.79352\n",
      "Epoch: 1, step: 174/300, Loss: 0.11760\n",
      "Epoch: 1, step: 175/300, Loss: 0.30567\n",
      "Epoch: 1, step: 176/300, Loss: 0.10404\n",
      "Epoch: 1, step: 177/300, Loss: 1.30438\n",
      "Epoch: 1, step: 178/300, Loss: 1.09230\n",
      "Epoch: 1, step: 179/300, Loss: 0.96838\n",
      "Epoch: 1, step: 180/300, Loss: 1.39186\n",
      "Epoch: 1, step: 181/300, Loss: 0.23685\n",
      "Epoch: 1, step: 182/300, Loss: 0.02451\n",
      "Epoch: 1, step: 183/300, Loss: 0.35387\n",
      "Epoch: 1, step: 184/300, Loss: 0.46096\n",
      "Epoch: 1, step: 185/300, Loss: 0.20519\n",
      "Epoch: 1, step: 186/300, Loss: 0.60810\n",
      "Epoch: 1, step: 187/300, Loss: 0.05320\n",
      "Epoch: 1, step: 188/300, Loss: 0.26739\n",
      "Epoch: 1, step: 189/300, Loss: 0.54315\n",
      "Epoch: 1, step: 190/300, Loss: 0.05717\n",
      "Epoch: 1, step: 191/300, Loss: 1.62697\n",
      "Epoch: 1, step: 192/300, Loss: 0.17088\n",
      "Epoch: 1, step: 193/300, Loss: 0.19713\n",
      "Epoch: 1, step: 194/300, Loss: 0.45465\n",
      "Epoch: 1, step: 195/300, Loss: 0.07573\n",
      "Epoch: 1, step: 196/300, Loss: 0.33655\n",
      "Epoch: 1, step: 197/300, Loss: 0.97336\n",
      "Epoch: 1, step: 198/300, Loss: 0.13001\n",
      "Epoch: 1, step: 199/300, Loss: 0.50343\n",
      "Epoch: 1, step: 200/300, Loss: 0.10480\n",
      "Epoch: 1, step: 201/300, Loss: 2.44208\n",
      "Epoch: 1, step: 202/300, Loss: 0.09674\n",
      "Epoch: 1, step: 203/300, Loss: 0.60158\n",
      "Epoch: 1, step: 204/300, Loss: 0.11508\n",
      "Epoch: 1, step: 205/300, Loss: 0.14951\n",
      "Epoch: 1, step: 206/300, Loss: 0.80009\n",
      "Epoch: 1, step: 207/300, Loss: 0.06846\n",
      "Epoch: 1, step: 208/300, Loss: 0.27020\n",
      "Epoch: 1, step: 209/300, Loss: 0.17232\n",
      "Epoch: 1, step: 210/300, Loss: 0.20516\n",
      "Epoch: 1, step: 211/300, Loss: 1.21719\n",
      "Epoch: 1, step: 212/300, Loss: 0.15608\n",
      "Epoch: 1, step: 213/300, Loss: 0.09784\n",
      "Epoch: 1, step: 214/300, Loss: 0.06623\n",
      "Epoch: 1, step: 215/300, Loss: 0.13971\n",
      "Epoch: 1, step: 216/300, Loss: 0.16553\n",
      "Epoch: 1, step: 217/300, Loss: 0.08922\n",
      "Epoch: 1, step: 218/300, Loss: 1.07767\n",
      "Epoch: 1, step: 219/300, Loss: 0.42396\n",
      "Epoch: 1, step: 220/300, Loss: 0.22368\n",
      "Epoch: 1, step: 221/300, Loss: 0.38700\n",
      "Epoch: 1, step: 222/300, Loss: 0.19013\n",
      "Epoch: 1, step: 223/300, Loss: 0.54636\n",
      "Epoch: 1, step: 224/300, Loss: 1.08539\n",
      "Epoch: 1, step: 225/300, Loss: 0.18339\n",
      "Epoch: 1, step: 226/300, Loss: 0.11524\n",
      "Epoch: 1, step: 227/300, Loss: 0.34592\n",
      "Epoch: 1, step: 228/300, Loss: 0.07006\n",
      "Epoch: 1, step: 229/300, Loss: 0.30502\n",
      "Epoch: 1, step: 230/300, Loss: 0.04359\n",
      "Epoch: 1, step: 231/300, Loss: 0.19356\n",
      "Epoch: 1, step: 232/300, Loss: 0.39593\n",
      "Epoch: 1, step: 233/300, Loss: 0.05296\n",
      "Epoch: 1, step: 234/300, Loss: 0.60958\n",
      "Epoch: 1, step: 235/300, Loss: 0.98638\n",
      "Epoch: 1, step: 236/300, Loss: 0.73658\n",
      "Epoch: 1, step: 237/300, Loss: 0.03527\n",
      "Epoch: 1, step: 238/300, Loss: 0.01357\n",
      "Epoch: 1, step: 239/300, Loss: 0.02475\n",
      "Epoch: 1, step: 240/300, Loss: 0.02090\n",
      "Epoch: 1, step: 241/300, Loss: 0.02159\n",
      "Epoch: 1, step: 242/300, Loss: 0.98801\n",
      "Epoch: 1, step: 243/300, Loss: 0.99131\n",
      "Epoch: 1, step: 244/300, Loss: 0.53350\n",
      "Epoch: 1, step: 245/300, Loss: 0.74078\n",
      "Epoch: 1, step: 246/300, Loss: 0.73196\n",
      "Epoch: 1, step: 247/300, Loss: 0.14140\n",
      "Epoch: 1, step: 248/300, Loss: 0.09021\n",
      "Epoch: 1, step: 249/300, Loss: 0.54672\n",
      "Epoch: 1, step: 250/300, Loss: 0.06894\n",
      "Epoch: 1, step: 251/300, Loss: 0.05683\n",
      "Epoch: 1, step: 252/300, Loss: 0.06066\n",
      "Epoch: 1, step: 253/300, Loss: 0.80528\n",
      "Epoch: 1, step: 254/300, Loss: 0.06973\n",
      "Epoch: 1, step: 255/300, Loss: 1.12568\n",
      "Epoch: 1, step: 256/300, Loss: 2.92021\n",
      "Epoch: 1, step: 257/300, Loss: 0.04081\n",
      "Epoch: 1, step: 258/300, Loss: 2.22737\n",
      "Epoch: 1, step: 259/300, Loss: 0.26121\n",
      "Epoch: 1, step: 260/300, Loss: 0.04194\n",
      "Epoch: 1, step: 261/300, Loss: 0.56259\n",
      "Epoch: 1, step: 262/300, Loss: 1.91035\n",
      "Epoch: 1, step: 263/300, Loss: 0.05125\n",
      "Epoch: 1, step: 264/300, Loss: 0.06588\n",
      "Epoch: 1, step: 265/300, Loss: 0.11381\n",
      "Epoch: 1, step: 266/300, Loss: 0.09272\n",
      "Epoch: 1, step: 267/300, Loss: 0.08606\n",
      "Epoch: 1, step: 268/300, Loss: 1.31885\n",
      "Epoch: 1, step: 269/300, Loss: 0.09239\n",
      "Epoch: 1, step: 270/300, Loss: 0.62803\n",
      "Epoch: 1, step: 271/300, Loss: 0.49309\n",
      "Epoch: 1, step: 272/300, Loss: 0.60797\n",
      "Epoch: 1, step: 273/300, Loss: 0.34407\n",
      "Epoch: 1, step: 274/300, Loss: 0.26698\n",
      "Epoch: 1, step: 275/300, Loss: 0.24596\n",
      "Epoch: 1, step: 276/300, Loss: 0.49271\n",
      "Epoch: 1, step: 277/300, Loss: 0.27489\n",
      "Epoch: 1, step: 278/300, Loss: 0.27299\n",
      "Epoch: 1, step: 279/300, Loss: 0.23349\n",
      "Epoch: 1, step: 280/300, Loss: 0.56418\n",
      "Epoch: 1, step: 281/300, Loss: 0.52973\n",
      "Epoch: 1, step: 282/300, Loss: 0.02780\n",
      "Epoch: 1, step: 283/300, Loss: 1.12460\n",
      "Epoch: 1, step: 284/300, Loss: 0.17323\n",
      "Epoch: 1, step: 285/300, Loss: 0.02461\n",
      "Epoch: 1, step: 286/300, Loss: 0.69937\n",
      "Epoch: 1, step: 287/300, Loss: 0.57623\n",
      "Epoch: 1, step: 288/300, Loss: 0.04442\n",
      "Epoch: 1, step: 289/300, Loss: 0.36689\n",
      "Epoch: 1, step: 290/300, Loss: 0.27301\n",
      "Epoch: 1, step: 291/300, Loss: 0.40104\n",
      "Epoch: 1, step: 292/300, Loss: 1.29968\n",
      "Epoch: 1, step: 293/300, Loss: 0.64150\n",
      "Epoch: 1, step: 294/300, Loss: 0.25184\n",
      "Epoch: 1, step: 295/300, Loss: 0.57140\n",
      "Epoch: 1, step: 296/300, Loss: 0.21317\n",
      "Epoch: 1, step: 297/300, Loss: 0.02032\n",
      "Epoch: 1, step: 298/300, Loss: 0.58153\n",
      "Epoch: 1, step: 299/300, Loss: 0.96720\n",
      "Epoch: 2, step: 0/300, Loss: 0.01287\n",
      "Epoch: 2, step: 1/300, Loss: 0.27103\n",
      "Epoch: 2, step: 2/300, Loss: 0.78554\n",
      "Epoch: 2, step: 3/300, Loss: 0.03440\n",
      "Epoch: 2, step: 4/300, Loss: 0.93250\n",
      "Epoch: 2, step: 5/300, Loss: 1.09481\n",
      "Epoch: 2, step: 6/300, Loss: 0.45390\n",
      "Epoch: 2, step: 7/300, Loss: 0.13297\n",
      "Epoch: 2, step: 8/300, Loss: 0.57111\n",
      "Epoch: 2, step: 9/300, Loss: 0.21198\n",
      "Epoch: 2, step: 10/300, Loss: 0.48330\n",
      "Epoch: 2, step: 11/300, Loss: 0.05295\n",
      "Epoch: 2, step: 12/300, Loss: 0.24467\n",
      "Epoch: 2, step: 13/300, Loss: 0.12034\n",
      "Epoch: 2, step: 14/300, Loss: 0.07428\n",
      "Epoch: 2, step: 15/300, Loss: 1.40113\n",
      "Epoch: 2, step: 16/300, Loss: 0.14764\n",
      "Epoch: 2, step: 17/300, Loss: 0.11021\n",
      "Epoch: 2, step: 18/300, Loss: 0.03836\n",
      "Epoch: 2, step: 19/300, Loss: 0.51862\n",
      "Epoch: 2, step: 20/300, Loss: 0.02336\n",
      "Epoch: 2, step: 21/300, Loss: 0.12394\n",
      "Epoch: 2, step: 22/300, Loss: 0.03962\n",
      "Epoch: 2, step: 23/300, Loss: 0.14557\n",
      "Epoch: 2, step: 24/300, Loss: 0.29511\n",
      "Epoch: 2, step: 25/300, Loss: 0.42255\n",
      "Epoch: 2, step: 26/300, Loss: 0.09475\n",
      "Epoch: 2, step: 27/300, Loss: 0.10333\n",
      "Epoch: 2, step: 28/300, Loss: 0.26688\n",
      "Epoch: 2, step: 29/300, Loss: 0.24682\n",
      "Epoch: 2, step: 30/300, Loss: 0.03260\n",
      "Epoch: 2, step: 31/300, Loss: 0.33209\n",
      "Epoch: 2, step: 32/300, Loss: 0.45117\n",
      "Epoch: 2, step: 33/300, Loss: 0.05147\n",
      "Epoch: 2, step: 34/300, Loss: 0.18379\n",
      "Epoch: 2, step: 35/300, Loss: 0.05662\n",
      "Epoch: 2, step: 36/300, Loss: 0.08117\n",
      "Epoch: 2, step: 37/300, Loss: 2.49794\n",
      "Epoch: 2, step: 38/300, Loss: 0.06959\n",
      "Epoch: 2, step: 39/300, Loss: 2.44947\n",
      "Epoch: 2, step: 40/300, Loss: 0.04537\n",
      "Epoch: 2, step: 41/300, Loss: 0.04215\n",
      "Epoch: 2, step: 42/300, Loss: 0.03378\n",
      "Epoch: 2, step: 43/300, Loss: 0.50958\n",
      "Epoch: 2, step: 44/300, Loss: 0.14342\n",
      "Epoch: 2, step: 45/300, Loss: 0.17779\n",
      "Epoch: 2, step: 46/300, Loss: 0.14351\n",
      "Epoch: 2, step: 47/300, Loss: 1.37285\n",
      "Epoch: 2, step: 48/300, Loss: 0.01092\n",
      "Epoch: 2, step: 49/300, Loss: 1.45789\n",
      "Epoch: 2, step: 50/300, Loss: 0.40125\n",
      "Epoch: 2, step: 51/300, Loss: 0.18037\n",
      "Epoch: 2, step: 52/300, Loss: 0.33869\n",
      "Epoch: 2, step: 53/300, Loss: 0.13621\n",
      "Epoch: 2, step: 54/300, Loss: 1.20236\n",
      "Epoch: 2, step: 55/300, Loss: 0.15006\n",
      "Epoch: 2, step: 56/300, Loss: 0.11536\n",
      "Epoch: 2, step: 57/300, Loss: 0.04000\n",
      "Epoch: 2, step: 58/300, Loss: 1.14362\n",
      "Epoch: 2, step: 59/300, Loss: 0.06587\n",
      "Epoch: 2, step: 60/300, Loss: 0.16893\n",
      "Epoch: 2, step: 61/300, Loss: 0.15633\n",
      "Epoch: 2, step: 62/300, Loss: 0.12825\n",
      "Epoch: 2, step: 63/300, Loss: 0.59514\n",
      "Epoch: 2, step: 64/300, Loss: 0.12055\n",
      "Epoch: 2, step: 65/300, Loss: 0.36632\n",
      "Epoch: 2, step: 66/300, Loss: 0.30728\n",
      "Epoch: 2, step: 67/300, Loss: 0.21901\n",
      "Epoch: 2, step: 68/300, Loss: 0.05614\n",
      "Epoch: 2, step: 69/300, Loss: 0.26302\n",
      "Epoch: 2, step: 70/300, Loss: 0.11246\n",
      "Epoch: 2, step: 71/300, Loss: 0.02549\n",
      "Epoch: 2, step: 72/300, Loss: 0.15680\n",
      "Epoch: 2, step: 73/300, Loss: 0.05488\n",
      "Epoch: 2, step: 74/300, Loss: 0.39100\n",
      "Epoch: 2, step: 75/300, Loss: 0.56717\n",
      "Epoch: 2, step: 76/300, Loss: 0.14262\n",
      "Epoch: 2, step: 77/300, Loss: 0.54340\n",
      "Epoch: 2, step: 78/300, Loss: 0.09038\n",
      "Epoch: 2, step: 79/300, Loss: 0.01571\n",
      "Epoch: 2, step: 80/300, Loss: 0.03409\n",
      "Epoch: 2, step: 81/300, Loss: 0.01966\n",
      "Epoch: 2, step: 82/300, Loss: 0.19372\n",
      "Epoch: 2, step: 83/300, Loss: 0.90837\n",
      "Epoch: 2, step: 84/300, Loss: 0.64160\n",
      "Epoch: 2, step: 85/300, Loss: 0.01600\n",
      "Epoch: 2, step: 86/300, Loss: 0.02923\n",
      "Epoch: 2, step: 87/300, Loss: 0.12525\n",
      "Epoch: 2, step: 88/300, Loss: 0.14511\n",
      "Epoch: 2, step: 89/300, Loss: 0.00962\n",
      "Epoch: 2, step: 90/300, Loss: 0.20623\n",
      "Epoch: 2, step: 91/300, Loss: 0.01106\n",
      "Epoch: 2, step: 92/300, Loss: 0.13910\n",
      "Epoch: 2, step: 93/300, Loss: 0.02135\n",
      "Epoch: 2, step: 94/300, Loss: 0.01662\n",
      "Epoch: 2, step: 95/300, Loss: 0.07496\n",
      "Epoch: 2, step: 96/300, Loss: 0.07807\n",
      "Epoch: 2, step: 97/300, Loss: 1.16023\n",
      "Epoch: 2, step: 98/300, Loss: 0.41075\n",
      "Epoch: 2, step: 99/300, Loss: 0.71796\n",
      "Epoch: 2, step: 100/300, Loss: 0.26513\n",
      "Epoch: 2, step: 101/300, Loss: 0.01531\n",
      "Epoch: 2, step: 102/300, Loss: 0.49053\n",
      "Epoch: 2, step: 103/300, Loss: 0.01582\n",
      "Epoch: 2, step: 104/300, Loss: 0.02250\n",
      "Epoch: 2, step: 105/300, Loss: 0.20204\n",
      "Epoch: 2, step: 106/300, Loss: 0.01742\n",
      "Epoch: 2, step: 107/300, Loss: 0.01793\n",
      "Epoch: 2, step: 108/300, Loss: 0.05328\n",
      "Epoch: 2, step: 109/300, Loss: 0.24895\n",
      "Epoch: 2, step: 110/300, Loss: 2.50900\n",
      "Epoch: 2, step: 111/300, Loss: 0.24898\n",
      "Epoch: 2, step: 112/300, Loss: 0.01277\n",
      "Epoch: 2, step: 113/300, Loss: 0.20087\n",
      "Epoch: 2, step: 114/300, Loss: 0.72154\n",
      "Epoch: 2, step: 115/300, Loss: 0.01749\n",
      "Epoch: 2, step: 116/300, Loss: 0.02078\n",
      "Epoch: 2, step: 117/300, Loss: 0.00919\n",
      "Epoch: 2, step: 118/300, Loss: 0.31728\n",
      "Epoch: 2, step: 119/300, Loss: 0.01953\n",
      "Epoch: 2, step: 120/300, Loss: 0.03504\n",
      "Epoch: 2, step: 121/300, Loss: 0.24924\n",
      "Epoch: 2, step: 122/300, Loss: 0.13752\n",
      "Epoch: 2, step: 123/300, Loss: 1.49492\n",
      "Epoch: 2, step: 124/300, Loss: 0.06684\n",
      "Epoch: 2, step: 125/300, Loss: 0.08942\n",
      "Epoch: 2, step: 126/300, Loss: 0.99567\n",
      "Epoch: 2, step: 127/300, Loss: 0.15966\n",
      "Epoch: 2, step: 128/300, Loss: 0.24362\n",
      "Epoch: 2, step: 129/300, Loss: 0.08702\n",
      "Epoch: 2, step: 130/300, Loss: 0.10576\n",
      "Epoch: 2, step: 131/300, Loss: 1.03916\n",
      "Epoch: 2, step: 132/300, Loss: 0.18604\n",
      "Epoch: 2, step: 133/300, Loss: 0.06501\n",
      "Epoch: 2, step: 134/300, Loss: 0.13695\n",
      "Epoch: 2, step: 135/300, Loss: 0.54441\n",
      "Epoch: 2, step: 136/300, Loss: 0.03435\n",
      "Epoch: 2, step: 137/300, Loss: 0.17483\n",
      "Epoch: 2, step: 138/300, Loss: 0.03473\n",
      "Epoch: 2, step: 139/300, Loss: 0.14558\n",
      "Epoch: 2, step: 140/300, Loss: 0.98274\n",
      "Epoch: 2, step: 141/300, Loss: 0.62864\n",
      "Epoch: 2, step: 142/300, Loss: 0.04481\n",
      "Epoch: 2, step: 143/300, Loss: 0.09470\n",
      "Epoch: 2, step: 144/300, Loss: 0.03465\n",
      "Epoch: 2, step: 145/300, Loss: 1.92696\n",
      "Epoch: 2, step: 146/300, Loss: 0.05995\n",
      "Epoch: 2, step: 147/300, Loss: 0.09721\n",
      "Epoch: 2, step: 148/300, Loss: 0.28978\n",
      "Epoch: 2, step: 149/300, Loss: 0.18354\n",
      "Epoch: 2, step: 150/300, Loss: 0.03959\n",
      "Epoch: 2, step: 151/300, Loss: 0.07018\n",
      "Epoch: 2, step: 152/300, Loss: 0.05841\n",
      "Epoch: 2, step: 153/300, Loss: 0.13412\n",
      "Epoch: 2, step: 154/300, Loss: 0.12189\n",
      "Epoch: 2, step: 155/300, Loss: 0.38229\n",
      "Epoch: 2, step: 156/300, Loss: 0.35131\n",
      "Epoch: 2, step: 157/300, Loss: 0.11455\n",
      "Epoch: 2, step: 158/300, Loss: 0.22089\n",
      "Epoch: 2, step: 159/300, Loss: 0.04280\n",
      "Epoch: 2, step: 160/300, Loss: 0.15975\n",
      "Epoch: 2, step: 161/300, Loss: 0.05041\n",
      "Epoch: 2, step: 162/300, Loss: 0.04422\n",
      "Epoch: 2, step: 163/300, Loss: 0.05600\n",
      "Epoch: 2, step: 164/300, Loss: 0.06286\n",
      "Epoch: 2, step: 165/300, Loss: 0.71095\n",
      "Epoch: 2, step: 166/300, Loss: 0.60974\n",
      "Epoch: 2, step: 167/300, Loss: 0.02503\n",
      "Epoch: 2, step: 168/300, Loss: 2.70055\n",
      "Epoch: 2, step: 169/300, Loss: 0.03614\n",
      "Epoch: 2, step: 170/300, Loss: 0.55381\n",
      "Epoch: 2, step: 171/300, Loss: 0.11326\n",
      "Epoch: 2, step: 172/300, Loss: 0.17736\n",
      "Epoch: 2, step: 173/300, Loss: 0.38537\n",
      "Epoch: 2, step: 174/300, Loss: 0.13879\n",
      "Epoch: 2, step: 175/300, Loss: 0.12670\n",
      "Epoch: 2, step: 176/300, Loss: 0.41826\n",
      "Epoch: 2, step: 177/300, Loss: 0.06865\n",
      "Epoch: 2, step: 178/300, Loss: 0.16522\n",
      "Epoch: 2, step: 179/300, Loss: 0.79898\n",
      "Epoch: 2, step: 180/300, Loss: 0.02381\n",
      "Epoch: 2, step: 181/300, Loss: 0.04798\n",
      "Epoch: 2, step: 182/300, Loss: 0.09021\n",
      "Epoch: 2, step: 183/300, Loss: 0.05882\n",
      "Epoch: 2, step: 184/300, Loss: 0.15082\n",
      "Epoch: 2, step: 185/300, Loss: 0.02293\n",
      "Epoch: 2, step: 186/300, Loss: 0.13643\n",
      "Epoch: 2, step: 187/300, Loss: 0.07616\n",
      "Epoch: 2, step: 188/300, Loss: 0.32593\n",
      "Epoch: 2, step: 189/300, Loss: 0.46787\n",
      "Epoch: 2, step: 190/300, Loss: 0.09285\n",
      "Epoch: 2, step: 191/300, Loss: 2.58936\n",
      "Epoch: 2, step: 192/300, Loss: 0.02504\n",
      "Epoch: 2, step: 193/300, Loss: 1.12721\n",
      "Epoch: 2, step: 194/300, Loss: 0.05244\n",
      "Epoch: 2, step: 195/300, Loss: 0.08713\n",
      "Epoch: 2, step: 196/300, Loss: 0.05375\n",
      "Epoch: 2, step: 197/300, Loss: 0.06581\n",
      "Epoch: 2, step: 198/300, Loss: 0.05731\n",
      "Epoch: 2, step: 199/300, Loss: 0.02183\n",
      "Epoch: 2, step: 200/300, Loss: 0.06387\n",
      "Epoch: 2, step: 201/300, Loss: 0.47058\n",
      "Epoch: 2, step: 202/300, Loss: 0.02009\n",
      "Epoch: 2, step: 203/300, Loss: 0.13340\n",
      "Epoch: 2, step: 204/300, Loss: 0.23217\n",
      "Epoch: 2, step: 205/300, Loss: 0.54046\n",
      "Epoch: 2, step: 206/300, Loss: 0.23399\n",
      "Epoch: 2, step: 207/300, Loss: 0.86064\n",
      "Epoch: 2, step: 208/300, Loss: 0.27265\n",
      "Epoch: 2, step: 209/300, Loss: 1.55230\n",
      "Epoch: 2, step: 210/300, Loss: 0.12865\n",
      "Epoch: 2, step: 211/300, Loss: 0.25128\n",
      "Epoch: 2, step: 212/300, Loss: 0.09361\n",
      "Epoch: 2, step: 213/300, Loss: 0.00582\n",
      "Epoch: 2, step: 214/300, Loss: 0.01111\n",
      "Epoch: 2, step: 215/300, Loss: 0.06644\n",
      "Epoch: 2, step: 216/300, Loss: 0.41922\n",
      "Epoch: 2, step: 217/300, Loss: 0.34472\n",
      "Epoch: 2, step: 218/300, Loss: 0.00900\n",
      "Epoch: 2, step: 219/300, Loss: 3.04011\n",
      "Epoch: 2, step: 220/300, Loss: 0.01042\n",
      "Epoch: 2, step: 221/300, Loss: 0.19589\n",
      "Epoch: 2, step: 222/300, Loss: 0.94825\n",
      "Epoch: 2, step: 223/300, Loss: 0.88854\n",
      "Epoch: 2, step: 224/300, Loss: 0.08651\n",
      "Epoch: 2, step: 225/300, Loss: 0.06594\n",
      "Epoch: 2, step: 226/300, Loss: 0.09765\n",
      "Epoch: 2, step: 227/300, Loss: 0.07672\n",
      "Epoch: 2, step: 228/300, Loss: 0.04468\n",
      "Epoch: 2, step: 229/300, Loss: 0.37115\n",
      "Epoch: 2, step: 230/300, Loss: 0.11586\n",
      "Epoch: 2, step: 231/300, Loss: 0.08519\n",
      "Epoch: 2, step: 232/300, Loss: 0.07819\n",
      "Epoch: 2, step: 233/300, Loss: 0.02201\n",
      "Epoch: 2, step: 234/300, Loss: 0.06679\n",
      "Epoch: 2, step: 235/300, Loss: 0.08380\n",
      "Epoch: 2, step: 236/300, Loss: 0.05938\n",
      "Epoch: 2, step: 237/300, Loss: 0.04434\n",
      "Epoch: 2, step: 238/300, Loss: 0.03221\n",
      "Epoch: 2, step: 239/300, Loss: 0.81702\n",
      "Epoch: 2, step: 240/300, Loss: 0.07737\n",
      "Epoch: 2, step: 241/300, Loss: 0.85034\n",
      "Epoch: 2, step: 242/300, Loss: 0.07325\n",
      "Epoch: 2, step: 243/300, Loss: 0.04564\n",
      "Epoch: 2, step: 244/300, Loss: 0.03737\n",
      "Epoch: 2, step: 245/300, Loss: 0.86464\n",
      "Epoch: 2, step: 246/300, Loss: 0.09888\n",
      "Epoch: 2, step: 247/300, Loss: 0.72513\n",
      "Epoch: 2, step: 248/300, Loss: 0.61164\n",
      "Epoch: 2, step: 249/300, Loss: 0.10571\n",
      "Epoch: 2, step: 250/300, Loss: 0.22398\n",
      "Epoch: 2, step: 251/300, Loss: 0.39779\n",
      "Epoch: 2, step: 252/300, Loss: 0.58797\n",
      "Epoch: 2, step: 253/300, Loss: 0.27457\n",
      "Epoch: 2, step: 254/300, Loss: 0.34796\n",
      "Epoch: 2, step: 255/300, Loss: 0.08994\n",
      "Epoch: 2, step: 256/300, Loss: 0.33429\n",
      "Epoch: 2, step: 257/300, Loss: 0.07037\n",
      "Epoch: 2, step: 258/300, Loss: 0.01982\n",
      "Epoch: 2, step: 259/300, Loss: 0.22998\n",
      "Epoch: 2, step: 260/300, Loss: 0.45383\n",
      "Epoch: 2, step: 261/300, Loss: 0.26113\n",
      "Epoch: 2, step: 262/300, Loss: 0.19936\n",
      "Epoch: 2, step: 263/300, Loss: 1.96938\n",
      "Epoch: 2, step: 264/300, Loss: 0.05504\n",
      "Epoch: 2, step: 265/300, Loss: 0.04349\n",
      "Epoch: 2, step: 266/300, Loss: 0.08764\n",
      "Epoch: 2, step: 267/300, Loss: 0.02458\n",
      "Epoch: 2, step: 268/300, Loss: 0.03905\n",
      "Epoch: 2, step: 269/300, Loss: 0.03316\n",
      "Epoch: 2, step: 270/300, Loss: 0.19618\n",
      "Epoch: 2, step: 271/300, Loss: 0.04142\n",
      "Epoch: 2, step: 272/300, Loss: 0.08993\n",
      "Epoch: 2, step: 273/300, Loss: 0.07926\n",
      "Epoch: 2, step: 274/300, Loss: 0.05208\n",
      "Epoch: 2, step: 275/300, Loss: 0.38703\n",
      "Epoch: 2, step: 276/300, Loss: 0.16857\n",
      "Epoch: 2, step: 277/300, Loss: 0.43501\n",
      "Epoch: 2, step: 278/300, Loss: 0.03252\n",
      "Epoch: 2, step: 279/300, Loss: 0.41252\n",
      "Epoch: 2, step: 280/300, Loss: 1.01533\n",
      "Epoch: 2, step: 281/300, Loss: 0.50528\n",
      "Epoch: 2, step: 282/300, Loss: 0.02112\n",
      "Epoch: 2, step: 283/300, Loss: 0.03272\n",
      "Epoch: 2, step: 284/300, Loss: 0.25012\n",
      "Epoch: 2, step: 285/300, Loss: 1.50175\n",
      "Epoch: 2, step: 286/300, Loss: 0.29710\n",
      "Epoch: 2, step: 287/300, Loss: 2.57572\n",
      "Epoch: 2, step: 288/300, Loss: 1.41320\n",
      "Epoch: 2, step: 289/300, Loss: 0.73996\n",
      "Epoch: 2, step: 290/300, Loss: 0.09272\n",
      "Epoch: 2, step: 291/300, Loss: 0.02858\n",
      "Epoch: 2, step: 292/300, Loss: 0.02878\n",
      "Epoch: 2, step: 293/300, Loss: 0.42190\n",
      "Epoch: 2, step: 294/300, Loss: 0.03344\n",
      "Epoch: 2, step: 295/300, Loss: 0.28076\n",
      "Epoch: 2, step: 296/300, Loss: 0.02865\n",
      "Epoch: 2, step: 297/300, Loss: 0.78305\n",
      "Epoch: 2, step: 298/300, Loss: 1.20037\n",
      "Epoch: 2, step: 299/300, Loss: 0.02777\n",
      "Epoch: 3, step: 0/300, Loss: 2.36488\n",
      "Epoch: 3, step: 1/300, Loss: 0.09929\n",
      "Epoch: 3, step: 2/300, Loss: 0.02915\n",
      "Epoch: 3, step: 3/300, Loss: 0.02912\n",
      "Epoch: 3, step: 4/300, Loss: 0.04392\n",
      "Epoch: 3, step: 5/300, Loss: 0.37729\n",
      "Epoch: 3, step: 6/300, Loss: 0.04741\n",
      "Epoch: 3, step: 7/300, Loss: 0.04221\n",
      "Epoch: 3, step: 8/300, Loss: 0.31755\n",
      "Epoch: 3, step: 9/300, Loss: 0.13374\n",
      "Epoch: 3, step: 10/300, Loss: 0.47525\n",
      "Epoch: 3, step: 11/300, Loss: 0.42671\n",
      "Epoch: 3, step: 12/300, Loss: 0.06555\n",
      "Epoch: 3, step: 13/300, Loss: 0.15261\n",
      "Epoch: 3, step: 14/300, Loss: 0.12442\n",
      "Epoch: 3, step: 15/300, Loss: 0.30591\n",
      "Epoch: 3, step: 16/300, Loss: 0.08215\n",
      "Epoch: 3, step: 17/300, Loss: 0.01211\n",
      "Epoch: 3, step: 18/300, Loss: 1.19965\n",
      "Epoch: 3, step: 19/300, Loss: 2.71200\n",
      "Epoch: 3, step: 20/300, Loss: 1.84816\n",
      "Epoch: 3, step: 21/300, Loss: 0.28158\n",
      "Epoch: 3, step: 22/300, Loss: 0.09385\n",
      "Epoch: 3, step: 23/300, Loss: 0.02111\n",
      "Epoch: 3, step: 24/300, Loss: 0.73745\n",
      "Epoch: 3, step: 25/300, Loss: 0.24696\n",
      "Epoch: 3, step: 26/300, Loss: 0.05129\n",
      "Epoch: 3, step: 27/300, Loss: 1.04030\n",
      "Epoch: 3, step: 28/300, Loss: 0.10537\n",
      "Epoch: 3, step: 29/300, Loss: 0.23794\n",
      "Epoch: 3, step: 30/300, Loss: 0.05256\n",
      "Epoch: 3, step: 31/300, Loss: 0.35571\n",
      "Epoch: 3, step: 32/300, Loss: 0.52366\n",
      "Epoch: 3, step: 33/300, Loss: 0.83761\n",
      "Epoch: 3, step: 34/300, Loss: 0.03399\n",
      "Epoch: 3, step: 35/300, Loss: 0.08300\n",
      "Epoch: 3, step: 36/300, Loss: 0.62362\n",
      "Epoch: 3, step: 37/300, Loss: 0.15918\n",
      "Epoch: 3, step: 38/300, Loss: 0.38039\n",
      "Epoch: 3, step: 39/300, Loss: 0.41301\n",
      "Epoch: 3, step: 40/300, Loss: 0.02071\n",
      "Epoch: 3, step: 41/300, Loss: 0.19744\n",
      "Epoch: 3, step: 42/300, Loss: 0.21673\n",
      "Epoch: 3, step: 43/300, Loss: 0.55023\n",
      "Epoch: 3, step: 44/300, Loss: 0.03972\n",
      "Epoch: 3, step: 45/300, Loss: 0.06942\n",
      "Epoch: 3, step: 46/300, Loss: 0.03085\n",
      "Epoch: 3, step: 47/300, Loss: 1.23936\n",
      "Epoch: 3, step: 48/300, Loss: 2.07587\n",
      "Epoch: 3, step: 49/300, Loss: 0.60582\n",
      "Epoch: 3, step: 50/300, Loss: 0.19118\n",
      "Epoch: 3, step: 51/300, Loss: 0.11017\n",
      "Epoch: 3, step: 52/300, Loss: 0.02997\n",
      "Epoch: 3, step: 53/300, Loss: 0.16175\n",
      "Epoch: 3, step: 54/300, Loss: 0.25613\n",
      "Epoch: 3, step: 55/300, Loss: 0.63326\n",
      "Epoch: 3, step: 56/300, Loss: 0.85176\n",
      "Epoch: 3, step: 57/300, Loss: 0.09795\n",
      "Epoch: 3, step: 58/300, Loss: 0.20587\n",
      "Epoch: 3, step: 59/300, Loss: 0.22281\n",
      "Epoch: 3, step: 60/300, Loss: 0.56260\n",
      "Epoch: 3, step: 61/300, Loss: 0.18572\n",
      "Epoch: 3, step: 62/300, Loss: 0.08307\n",
      "Epoch: 3, step: 63/300, Loss: 0.08533\n",
      "Epoch: 3, step: 64/300, Loss: 0.10573\n",
      "Epoch: 3, step: 65/300, Loss: 0.17365\n",
      "Epoch: 3, step: 66/300, Loss: 0.09324\n",
      "Epoch: 3, step: 67/300, Loss: 0.02400\n",
      "Epoch: 3, step: 68/300, Loss: 0.36097\n",
      "Epoch: 3, step: 69/300, Loss: 0.01973\n",
      "Epoch: 3, step: 70/300, Loss: 0.34977\n",
      "Epoch: 3, step: 71/300, Loss: 0.52157\n",
      "Epoch: 3, step: 72/300, Loss: 0.15400\n",
      "Epoch: 3, step: 73/300, Loss: 0.08179\n",
      "Epoch: 3, step: 74/300, Loss: 0.02935\n",
      "Epoch: 3, step: 75/300, Loss: 0.08411\n",
      "Epoch: 3, step: 76/300, Loss: 0.07942\n",
      "Epoch: 3, step: 77/300, Loss: 0.03541\n",
      "Epoch: 3, step: 78/300, Loss: 0.98265\n",
      "Epoch: 3, step: 79/300, Loss: 0.05989\n",
      "Epoch: 3, step: 80/300, Loss: 0.01841\n",
      "Epoch: 3, step: 81/300, Loss: 0.01093\n",
      "Epoch: 3, step: 82/300, Loss: 0.09581\n",
      "Epoch: 3, step: 83/300, Loss: 0.08649\n",
      "Epoch: 3, step: 84/300, Loss: 0.04823\n",
      "Epoch: 3, step: 85/300, Loss: 0.14045\n",
      "Epoch: 3, step: 86/300, Loss: 0.13283\n",
      "Epoch: 3, step: 87/300, Loss: 0.04668\n",
      "Epoch: 3, step: 88/300, Loss: 0.01472\n",
      "Epoch: 3, step: 89/300, Loss: 0.04334\n",
      "Epoch: 3, step: 90/300, Loss: 0.07868\n",
      "Epoch: 3, step: 91/300, Loss: 0.06359\n",
      "Epoch: 3, step: 92/300, Loss: 0.43191\n",
      "Epoch: 3, step: 93/300, Loss: 0.16412\n",
      "Epoch: 3, step: 94/300, Loss: 0.09850\n",
      "Epoch: 3, step: 95/300, Loss: 1.01171\n",
      "Epoch: 3, step: 96/300, Loss: 0.70161\n",
      "Epoch: 3, step: 97/300, Loss: 0.06419\n",
      "Epoch: 3, step: 98/300, Loss: 0.44424\n",
      "Epoch: 3, step: 99/300, Loss: 0.34359\n",
      "Epoch: 3, step: 100/300, Loss: 0.04627\n",
      "Epoch: 3, step: 101/300, Loss: 0.09194\n",
      "Epoch: 3, step: 102/300, Loss: 0.05108\n",
      "Epoch: 3, step: 103/300, Loss: 0.81193\n",
      "Epoch: 3, step: 104/300, Loss: 0.02008\n",
      "Epoch: 3, step: 105/300, Loss: 0.04488\n",
      "Epoch: 3, step: 106/300, Loss: 0.38798\n",
      "Epoch: 3, step: 107/300, Loss: 0.51342\n",
      "Epoch: 3, step: 108/300, Loss: 0.04789\n",
      "Epoch: 3, step: 109/300, Loss: 0.01870\n",
      "Epoch: 3, step: 110/300, Loss: 0.33098\n",
      "Epoch: 3, step: 111/300, Loss: 0.05393\n",
      "Epoch: 3, step: 112/300, Loss: 0.89946\n",
      "Epoch: 3, step: 113/300, Loss: 0.04615\n",
      "Epoch: 3, step: 114/300, Loss: 0.09329\n",
      "Epoch: 3, step: 115/300, Loss: 0.02947\n",
      "Epoch: 3, step: 116/300, Loss: 0.01778\n",
      "Epoch: 3, step: 117/300, Loss: 0.01139\n",
      "Epoch: 3, step: 118/300, Loss: 0.01353\n",
      "Epoch: 3, step: 119/300, Loss: 0.15992\n",
      "Epoch: 3, step: 120/300, Loss: 0.08068\n",
      "Epoch: 3, step: 121/300, Loss: 0.03161\n",
      "Epoch: 3, step: 122/300, Loss: 0.03534\n",
      "Epoch: 3, step: 123/300, Loss: 0.09442\n",
      "Epoch: 3, step: 124/300, Loss: 0.03157\n",
      "Epoch: 3, step: 125/300, Loss: 0.02389\n",
      "Epoch: 3, step: 126/300, Loss: 0.00984\n",
      "Epoch: 3, step: 127/300, Loss: 0.03071\n",
      "Epoch: 3, step: 128/300, Loss: 0.01755\n",
      "Epoch: 3, step: 129/300, Loss: 0.61835\n",
      "Epoch: 3, step: 130/300, Loss: 0.02975\n",
      "Epoch: 3, step: 131/300, Loss: 0.03092\n",
      "Epoch: 3, step: 132/300, Loss: 0.02265\n",
      "Epoch: 3, step: 133/300, Loss: 0.04959\n",
      "Epoch: 3, step: 134/300, Loss: 0.15570\n",
      "Epoch: 3, step: 135/300, Loss: 0.04260\n",
      "Epoch: 3, step: 136/300, Loss: 0.06094\n",
      "Epoch: 3, step: 137/300, Loss: 0.26388\n",
      "Epoch: 3, step: 138/300, Loss: 0.48650\n",
      "Epoch: 3, step: 139/300, Loss: 0.04949\n",
      "Epoch: 3, step: 140/300, Loss: 0.03703\n",
      "Epoch: 3, step: 141/300, Loss: 0.19359\n",
      "Epoch: 3, step: 142/300, Loss: 0.41993\n",
      "Epoch: 3, step: 143/300, Loss: 0.03320\n",
      "Epoch: 3, step: 144/300, Loss: 0.03586\n",
      "Epoch: 3, step: 145/300, Loss: 0.01432\n",
      "Epoch: 3, step: 146/300, Loss: 0.04700\n",
      "Epoch: 3, step: 147/300, Loss: 0.03130\n",
      "Epoch: 3, step: 148/300, Loss: 0.04076\n",
      "Epoch: 3, step: 149/300, Loss: 0.06712\n",
      "Epoch: 3, step: 150/300, Loss: 0.15293\n",
      "Epoch: 3, step: 151/300, Loss: 0.11873\n",
      "Epoch: 3, step: 152/300, Loss: 0.02929\n",
      "Epoch: 3, step: 153/300, Loss: 0.06018\n",
      "Epoch: 3, step: 154/300, Loss: 0.03261\n",
      "Epoch: 3, step: 155/300, Loss: 0.07568\n",
      "Epoch: 3, step: 156/300, Loss: 0.21605\n",
      "Epoch: 3, step: 157/300, Loss: 0.01239\n",
      "Epoch: 3, step: 158/300, Loss: 0.17473\n",
      "Epoch: 3, step: 159/300, Loss: 0.15896\n",
      "Epoch: 3, step: 160/300, Loss: 0.02056\n",
      "Epoch: 3, step: 161/300, Loss: 0.76562\n",
      "Epoch: 3, step: 162/300, Loss: 0.03228\n",
      "Epoch: 3, step: 163/300, Loss: 0.01710\n",
      "Epoch: 3, step: 164/300, Loss: 0.36313\n",
      "Epoch: 3, step: 165/300, Loss: 0.00619\n",
      "Epoch: 3, step: 166/300, Loss: 1.68620\n",
      "Epoch: 3, step: 167/300, Loss: 0.26310\n",
      "Epoch: 3, step: 168/300, Loss: 0.05815\n",
      "Epoch: 3, step: 169/300, Loss: 0.11340\n",
      "Epoch: 3, step: 170/300, Loss: 0.06982\n",
      "Epoch: 3, step: 171/300, Loss: 0.03010\n",
      "Epoch: 3, step: 172/300, Loss: 0.01712\n",
      "Epoch: 3, step: 173/300, Loss: 0.18249\n",
      "Epoch: 3, step: 174/300, Loss: 0.06429\n",
      "Epoch: 3, step: 175/300, Loss: 0.04930\n",
      "Epoch: 3, step: 176/300, Loss: 0.13150\n",
      "Epoch: 3, step: 177/300, Loss: 0.70101\n",
      "Epoch: 3, step: 178/300, Loss: 0.08789\n",
      "Epoch: 3, step: 179/300, Loss: 0.04503\n",
      "Epoch: 3, step: 180/300, Loss: 0.26170\n",
      "Epoch: 3, step: 181/300, Loss: 0.01041\n",
      "Epoch: 3, step: 182/300, Loss: 0.16609\n",
      "Epoch: 3, step: 183/300, Loss: 0.32705\n",
      "Epoch: 3, step: 184/300, Loss: 0.45742\n",
      "Epoch: 3, step: 185/300, Loss: 0.01159\n",
      "Epoch: 3, step: 186/300, Loss: 0.01070\n",
      "Epoch: 3, step: 187/300, Loss: 0.05518\n",
      "Epoch: 3, step: 188/300, Loss: 0.01917\n",
      "Epoch: 3, step: 189/300, Loss: 0.03414\n",
      "Epoch: 3, step: 190/300, Loss: 0.05690\n",
      "Epoch: 3, step: 191/300, Loss: 0.01481\n",
      "Epoch: 3, step: 192/300, Loss: 0.08435\n",
      "Epoch: 3, step: 193/300, Loss: 0.01645\n",
      "Epoch: 3, step: 194/300, Loss: 0.01746\n",
      "Epoch: 3, step: 195/300, Loss: 0.01175\n",
      "Epoch: 3, step: 196/300, Loss: 0.00895\n",
      "Epoch: 3, step: 197/300, Loss: 0.02113\n",
      "Epoch: 3, step: 198/300, Loss: 0.00862\n",
      "Epoch: 3, step: 199/300, Loss: 0.03223\n",
      "Epoch: 3, step: 200/300, Loss: 0.00910\n",
      "Epoch: 3, step: 201/300, Loss: 0.00828\n",
      "Epoch: 3, step: 202/300, Loss: 0.00956\n",
      "Epoch: 3, step: 203/300, Loss: 0.00779\n",
      "Epoch: 3, step: 204/300, Loss: 0.00992\n",
      "Epoch: 3, step: 205/300, Loss: 0.05035\n",
      "Epoch: 3, step: 206/300, Loss: 0.00673\n",
      "Epoch: 3, step: 207/300, Loss: 0.03987\n",
      "Epoch: 3, step: 208/300, Loss: 0.10082\n",
      "Epoch: 3, step: 209/300, Loss: 0.42586\n",
      "Epoch: 3, step: 210/300, Loss: 0.02762\n",
      "Epoch: 3, step: 211/300, Loss: 0.01751\n",
      "Epoch: 3, step: 212/300, Loss: 0.10958\n",
      "Epoch: 3, step: 213/300, Loss: 0.58182\n",
      "Epoch: 3, step: 214/300, Loss: 0.02036\n",
      "Epoch: 3, step: 215/300, Loss: 0.02040\n",
      "Epoch: 3, step: 216/300, Loss: 0.01063\n",
      "Epoch: 3, step: 217/300, Loss: 0.03091\n",
      "Epoch: 3, step: 218/300, Loss: 0.03775\n",
      "Epoch: 3, step: 219/300, Loss: 1.40320\n",
      "Epoch: 3, step: 220/300, Loss: 0.03204\n",
      "Epoch: 3, step: 221/300, Loss: 0.02797\n",
      "Epoch: 3, step: 222/300, Loss: 0.05944\n",
      "Epoch: 3, step: 223/300, Loss: 0.01517\n",
      "Epoch: 3, step: 224/300, Loss: 0.14040\n",
      "Epoch: 3, step: 225/300, Loss: 0.02378\n",
      "Epoch: 3, step: 226/300, Loss: 1.01990\n",
      "Epoch: 3, step: 227/300, Loss: 0.31656\n",
      "Epoch: 3, step: 228/300, Loss: 0.02250\n",
      "Epoch: 3, step: 229/300, Loss: 0.62652\n",
      "Epoch: 3, step: 230/300, Loss: 1.05211\n",
      "Epoch: 3, step: 231/300, Loss: 0.13741\n",
      "Epoch: 3, step: 232/300, Loss: 0.01856\n",
      "Epoch: 3, step: 233/300, Loss: 0.57368\n",
      "Epoch: 3, step: 234/300, Loss: 0.27785\n",
      "Epoch: 3, step: 235/300, Loss: 0.06802\n",
      "Epoch: 3, step: 236/300, Loss: 0.01931\n",
      "Epoch: 3, step: 237/300, Loss: 0.01331\n",
      "Epoch: 3, step: 238/300, Loss: 0.03541\n",
      "Epoch: 3, step: 239/300, Loss: 0.10911\n",
      "Epoch: 3, step: 240/300, Loss: 0.13714\n",
      "Epoch: 3, step: 241/300, Loss: 1.86244\n",
      "Epoch: 3, step: 242/300, Loss: 0.03568\n",
      "Epoch: 3, step: 243/300, Loss: 0.01794\n",
      "Epoch: 3, step: 244/300, Loss: 0.02751\n",
      "Epoch: 3, step: 245/300, Loss: 0.01569\n",
      "Epoch: 3, step: 246/300, Loss: 0.03692\n",
      "Epoch: 3, step: 247/300, Loss: 0.89557\n",
      "Epoch: 3, step: 248/300, Loss: 2.28232\n",
      "Epoch: 3, step: 249/300, Loss: 0.04275\n",
      "Epoch: 3, step: 250/300, Loss: 0.04659\n",
      "Epoch: 3, step: 251/300, Loss: 0.04413\n",
      "Epoch: 3, step: 252/300, Loss: 0.17653\n",
      "Epoch: 3, step: 253/300, Loss: 0.04641\n",
      "Epoch: 3, step: 254/300, Loss: 0.55035\n",
      "Epoch: 3, step: 255/300, Loss: 0.05519\n",
      "Epoch: 3, step: 256/300, Loss: 0.05000\n",
      "Epoch: 3, step: 257/300, Loss: 0.60609\n",
      "Epoch: 3, step: 258/300, Loss: 0.00992\n",
      "Epoch: 3, step: 259/300, Loss: 0.05644\n",
      "Epoch: 3, step: 260/300, Loss: 1.92460\n",
      "Epoch: 3, step: 261/300, Loss: 0.07725\n",
      "Epoch: 3, step: 262/300, Loss: 0.64473\n",
      "Epoch: 3, step: 263/300, Loss: 0.12621\n",
      "Epoch: 3, step: 264/300, Loss: 0.04696\n",
      "Epoch: 3, step: 265/300, Loss: 0.21707\n",
      "Epoch: 3, step: 266/300, Loss: 0.50315\n",
      "Epoch: 3, step: 267/300, Loss: 0.04871\n",
      "Epoch: 3, step: 268/300, Loss: 0.16149\n",
      "Epoch: 3, step: 269/300, Loss: 0.01794\n",
      "Epoch: 3, step: 270/300, Loss: 0.30948\n",
      "Epoch: 3, step: 271/300, Loss: 0.02202\n",
      "Epoch: 3, step: 272/300, Loss: 1.95380\n",
      "Epoch: 3, step: 273/300, Loss: 0.01749\n",
      "Epoch: 3, step: 274/300, Loss: 0.02326\n",
      "Epoch: 3, step: 275/300, Loss: 0.89835\n",
      "Epoch: 3, step: 276/300, Loss: 0.98270\n",
      "Epoch: 3, step: 277/300, Loss: 1.27604\n",
      "Epoch: 3, step: 278/300, Loss: 0.17499\n",
      "Epoch: 3, step: 279/300, Loss: 0.04820\n",
      "Epoch: 3, step: 280/300, Loss: 0.01649\n",
      "Epoch: 3, step: 281/300, Loss: 0.87944\n",
      "Epoch: 3, step: 282/300, Loss: 0.26260\n",
      "Epoch: 3, step: 283/300, Loss: 0.01539\n",
      "Epoch: 3, step: 284/300, Loss: 0.27114\n",
      "Epoch: 3, step: 285/300, Loss: 0.22849\n",
      "Epoch: 3, step: 286/300, Loss: 0.61536\n",
      "Epoch: 3, step: 287/300, Loss: 0.08826\n",
      "Epoch: 3, step: 288/300, Loss: 0.08752\n",
      "Epoch: 3, step: 289/300, Loss: 0.00962\n",
      "Epoch: 3, step: 290/300, Loss: 0.03586\n",
      "Epoch: 3, step: 291/300, Loss: 0.01741\n",
      "Epoch: 3, step: 292/300, Loss: 0.92228\n",
      "Epoch: 3, step: 293/300, Loss: 0.20721\n",
      "Epoch: 3, step: 294/300, Loss: 0.05736\n",
      "Epoch: 3, step: 295/300, Loss: 1.46890\n",
      "Epoch: 3, step: 296/300, Loss: 0.04646\n",
      "Epoch: 3, step: 297/300, Loss: 0.05187\n",
      "Epoch: 3, step: 298/300, Loss: 0.01018\n",
      "Epoch: 3, step: 299/300, Loss: 0.03539\n",
      "Epoch: 4, step: 0/300, Loss: 0.03316\n",
      "Epoch: 4, step: 1/300, Loss: 3.02220\n",
      "Epoch: 4, step: 2/300, Loss: 0.14014\n",
      "Epoch: 4, step: 3/300, Loss: 0.52215\n",
      "Epoch: 4, step: 4/300, Loss: 0.12403\n",
      "Epoch: 4, step: 5/300, Loss: 0.04255\n",
      "Epoch: 4, step: 6/300, Loss: 0.84930\n",
      "Epoch: 4, step: 7/300, Loss: 0.06544\n",
      "Epoch: 4, step: 8/300, Loss: 0.10615\n",
      "Epoch: 4, step: 9/300, Loss: 0.33921\n",
      "Epoch: 4, step: 10/300, Loss: 0.09325\n",
      "Epoch: 4, step: 11/300, Loss: 0.06931\n",
      "Epoch: 4, step: 12/300, Loss: 0.03743\n",
      "Epoch: 4, step: 13/300, Loss: 0.01551\n",
      "Epoch: 4, step: 14/300, Loss: 0.07500\n",
      "Epoch: 4, step: 15/300, Loss: 0.19014\n",
      "Epoch: 4, step: 16/300, Loss: 0.23660\n",
      "Epoch: 4, step: 17/300, Loss: 0.04751\n",
      "Epoch: 4, step: 18/300, Loss: 0.00686\n",
      "Epoch: 4, step: 19/300, Loss: 0.02359\n",
      "Epoch: 4, step: 20/300, Loss: 0.04369\n",
      "Epoch: 4, step: 21/300, Loss: 0.04690\n",
      "Epoch: 4, step: 22/300, Loss: 0.14950\n",
      "Epoch: 4, step: 23/300, Loss: 0.08718\n",
      "Epoch: 4, step: 24/300, Loss: 0.00929\n",
      "Epoch: 4, step: 25/300, Loss: 2.67560\n",
      "Epoch: 4, step: 26/300, Loss: 0.33691\n",
      "Epoch: 4, step: 27/300, Loss: 0.08311\n",
      "Epoch: 4, step: 28/300, Loss: 0.05908\n",
      "Epoch: 4, step: 29/300, Loss: 0.00500\n",
      "Epoch: 4, step: 30/300, Loss: 0.13339\n",
      "Epoch: 4, step: 31/300, Loss: 0.66714\n",
      "Epoch: 4, step: 32/300, Loss: 0.02318\n",
      "Epoch: 4, step: 33/300, Loss: 0.01691\n",
      "Epoch: 4, step: 34/300, Loss: 0.23372\n",
      "Epoch: 4, step: 35/300, Loss: 0.06735\n",
      "Epoch: 4, step: 36/300, Loss: 0.09569\n",
      "Epoch: 4, step: 37/300, Loss: 0.15958\n",
      "Epoch: 4, step: 38/300, Loss: 0.03441\n",
      "Epoch: 4, step: 39/300, Loss: 1.12182\n",
      "Epoch: 4, step: 40/300, Loss: 0.02900\n",
      "Epoch: 4, step: 41/300, Loss: 0.06569\n",
      "Epoch: 4, step: 42/300, Loss: 0.02385\n",
      "Epoch: 4, step: 43/300, Loss: 0.06398\n",
      "Epoch: 4, step: 44/300, Loss: 0.01879\n",
      "Epoch: 4, step: 45/300, Loss: 0.18422\n",
      "Epoch: 4, step: 46/300, Loss: 0.10745\n",
      "Epoch: 4, step: 47/300, Loss: 0.22373\n",
      "Epoch: 4, step: 48/300, Loss: 0.03512\n",
      "Epoch: 4, step: 49/300, Loss: 0.00945\n",
      "Epoch: 4, step: 50/300, Loss: 0.01254\n",
      "Epoch: 4, step: 51/300, Loss: 0.02018\n",
      "Epoch: 4, step: 52/300, Loss: 0.07117\n",
      "Epoch: 4, step: 53/300, Loss: 0.17034\n",
      "Epoch: 4, step: 54/300, Loss: 0.07449\n",
      "Epoch: 4, step: 55/300, Loss: 0.18887\n",
      "Epoch: 4, step: 56/300, Loss: 0.09150\n",
      "Epoch: 4, step: 57/300, Loss: 0.12448\n",
      "Epoch: 4, step: 58/300, Loss: 0.00620\n",
      "Epoch: 4, step: 59/300, Loss: 0.16185\n",
      "Epoch: 4, step: 60/300, Loss: 0.12598\n",
      "Epoch: 4, step: 61/300, Loss: 0.13366\n",
      "Epoch: 4, step: 62/300, Loss: 2.34295\n",
      "Epoch: 4, step: 63/300, Loss: 0.51784\n",
      "Epoch: 4, step: 64/300, Loss: 0.11296\n",
      "Epoch: 4, step: 65/300, Loss: 0.10657\n",
      "Epoch: 4, step: 66/300, Loss: 0.00864\n",
      "Epoch: 4, step: 67/300, Loss: 0.02047\n",
      "Epoch: 4, step: 68/300, Loss: 0.11986\n",
      "Epoch: 4, step: 69/300, Loss: 0.00935\n",
      "Epoch: 4, step: 70/300, Loss: 0.04404\n",
      "Epoch: 4, step: 71/300, Loss: 0.04522\n",
      "Epoch: 4, step: 72/300, Loss: 0.01661\n",
      "Epoch: 4, step: 73/300, Loss: 0.00882\n",
      "Epoch: 4, step: 74/300, Loss: 0.04291\n",
      "Epoch: 4, step: 75/300, Loss: 0.03110\n",
      "Epoch: 4, step: 76/300, Loss: 0.00709\n",
      "Epoch: 4, step: 77/300, Loss: 0.04262\n",
      "Epoch: 4, step: 78/300, Loss: 0.02500\n",
      "Epoch: 4, step: 79/300, Loss: 0.03062\n",
      "Epoch: 4, step: 80/300, Loss: 0.50130\n",
      "Epoch: 4, step: 81/300, Loss: 0.03934\n",
      "Epoch: 4, step: 82/300, Loss: 0.04916\n",
      "Epoch: 4, step: 83/300, Loss: 0.03078\n",
      "Epoch: 4, step: 84/300, Loss: 0.01228\n",
      "Epoch: 4, step: 85/300, Loss: 0.02499\n",
      "Epoch: 4, step: 86/300, Loss: 0.03180\n",
      "Epoch: 4, step: 87/300, Loss: 0.05066\n",
      "Epoch: 4, step: 88/300, Loss: 0.08204\n",
      "Epoch: 4, step: 89/300, Loss: 0.01947\n",
      "Epoch: 4, step: 90/300, Loss: 0.21781\n",
      "Epoch: 4, step: 91/300, Loss: 0.31292\n",
      "Epoch: 4, step: 92/300, Loss: 0.17135\n",
      "Epoch: 4, step: 93/300, Loss: 0.05120\n",
      "Epoch: 4, step: 94/300, Loss: 0.07595\n",
      "Epoch: 4, step: 95/300, Loss: 0.05106\n",
      "Epoch: 4, step: 96/300, Loss: 0.02206\n",
      "Epoch: 4, step: 97/300, Loss: 0.02551\n",
      "Epoch: 4, step: 98/300, Loss: 0.15260\n",
      "Epoch: 4, step: 99/300, Loss: 0.03141\n",
      "Epoch: 4, step: 100/300, Loss: 0.16349\n",
      "Epoch: 4, step: 101/300, Loss: 0.00887\n",
      "Epoch: 4, step: 102/300, Loss: 0.03277\n",
      "Epoch: 4, step: 103/300, Loss: 0.10152\n",
      "Epoch: 4, step: 104/300, Loss: 0.31015\n",
      "Epoch: 4, step: 105/300, Loss: 0.02319\n",
      "Epoch: 4, step: 106/300, Loss: 0.21949\n",
      "Epoch: 4, step: 107/300, Loss: 0.04237\n",
      "Epoch: 4, step: 108/300, Loss: 0.02918\n",
      "Epoch: 4, step: 109/300, Loss: 0.02348\n",
      "Epoch: 4, step: 110/300, Loss: 0.03627\n",
      "Epoch: 4, step: 111/300, Loss: 0.04835\n",
      "Epoch: 4, step: 112/300, Loss: 0.16562\n",
      "Epoch: 4, step: 113/300, Loss: 0.01770\n",
      "Epoch: 4, step: 114/300, Loss: 0.01369\n",
      "Epoch: 4, step: 115/300, Loss: 0.01069\n",
      "Epoch: 4, step: 116/300, Loss: 0.09776\n",
      "Epoch: 4, step: 117/300, Loss: 0.02673\n",
      "Epoch: 4, step: 118/300, Loss: 0.07439\n",
      "Epoch: 4, step: 119/300, Loss: 0.01541\n",
      "Epoch: 4, step: 120/300, Loss: 0.03845\n",
      "Epoch: 4, step: 121/300, Loss: 0.02389\n",
      "Epoch: 4, step: 122/300, Loss: 0.10631\n",
      "Epoch: 4, step: 123/300, Loss: 0.02638\n",
      "Epoch: 4, step: 124/300, Loss: 0.32554\n",
      "Epoch: 4, step: 125/300, Loss: 0.02522\n",
      "Epoch: 4, step: 126/300, Loss: 0.00549\n",
      "Epoch: 4, step: 127/300, Loss: 0.12423\n",
      "Epoch: 4, step: 128/300, Loss: 0.01373\n",
      "Epoch: 4, step: 129/300, Loss: 0.00470\n",
      "Epoch: 4, step: 130/300, Loss: 1.81584\n",
      "Epoch: 4, step: 131/300, Loss: 0.00384\n",
      "Epoch: 4, step: 132/300, Loss: 0.14620\n",
      "Epoch: 4, step: 133/300, Loss: 0.02057\n",
      "Epoch: 4, step: 134/300, Loss: 0.02923\n",
      "Epoch: 4, step: 135/300, Loss: 0.06192\n",
      "Epoch: 4, step: 136/300, Loss: 0.00622\n",
      "Epoch: 4, step: 137/300, Loss: 0.01792\n",
      "Epoch: 4, step: 138/300, Loss: 0.01648\n",
      "Epoch: 4, step: 139/300, Loss: 0.04389\n",
      "Epoch: 4, step: 140/300, Loss: 0.04733\n",
      "Epoch: 4, step: 141/300, Loss: 0.03812\n",
      "Epoch: 4, step: 142/300, Loss: 0.03175\n",
      "Epoch: 4, step: 143/300, Loss: 0.03819\n",
      "Epoch: 4, step: 144/300, Loss: 0.05920\n",
      "Epoch: 4, step: 145/300, Loss: 0.02527\n",
      "Epoch: 4, step: 146/300, Loss: 0.10377\n",
      "Epoch: 4, step: 147/300, Loss: 0.01575\n",
      "Epoch: 4, step: 148/300, Loss: 0.04145\n",
      "Epoch: 4, step: 149/300, Loss: 0.00515\n",
      "Epoch: 4, step: 150/300, Loss: 0.03831\n",
      "Epoch: 4, step: 151/300, Loss: 0.01818\n",
      "Epoch: 4, step: 152/300, Loss: 0.01956\n",
      "Epoch: 4, step: 153/300, Loss: 0.14386\n",
      "Epoch: 4, step: 154/300, Loss: 0.01940\n",
      "Epoch: 4, step: 155/300, Loss: 0.51831\n",
      "Epoch: 4, step: 156/300, Loss: 0.00609\n",
      "Epoch: 4, step: 157/300, Loss: 0.01116\n",
      "Epoch: 4, step: 158/300, Loss: 0.01809\n",
      "Epoch: 4, step: 159/300, Loss: 0.02636\n",
      "Epoch: 4, step: 160/300, Loss: 0.01852\n",
      "Epoch: 4, step: 161/300, Loss: 0.02952\n",
      "Epoch: 4, step: 162/300, Loss: 0.06702\n",
      "Epoch: 4, step: 163/300, Loss: 0.01605\n",
      "Epoch: 4, step: 164/300, Loss: 0.00759\n",
      "Epoch: 4, step: 165/300, Loss: 0.01088\n",
      "Epoch: 4, step: 166/300, Loss: 0.03207\n",
      "Epoch: 4, step: 167/300, Loss: 1.42126\n",
      "Epoch: 4, step: 168/300, Loss: 0.02223\n",
      "Epoch: 4, step: 169/300, Loss: 0.01026\n",
      "Epoch: 4, step: 170/300, Loss: 0.02619\n",
      "Epoch: 4, step: 171/300, Loss: 0.00852\n",
      "Epoch: 4, step: 172/300, Loss: 0.01394\n",
      "Epoch: 4, step: 173/300, Loss: 0.88146\n",
      "Epoch: 4, step: 174/300, Loss: 0.03349\n",
      "Epoch: 4, step: 175/300, Loss: 0.08110\n",
      "Epoch: 4, step: 176/300, Loss: 0.00579\n",
      "Epoch: 4, step: 177/300, Loss: 0.00611\n",
      "Epoch: 4, step: 178/300, Loss: 0.05244\n",
      "Epoch: 4, step: 179/300, Loss: 0.17571\n",
      "Epoch: 4, step: 180/300, Loss: 0.01208\n",
      "Epoch: 4, step: 181/300, Loss: 0.57211\n",
      "Epoch: 4, step: 182/300, Loss: 0.18551\n",
      "Epoch: 4, step: 183/300, Loss: 0.02740\n",
      "Epoch: 4, step: 184/300, Loss: 0.95120\n",
      "Epoch: 4, step: 185/300, Loss: 0.09307\n",
      "Epoch: 4, step: 186/300, Loss: 0.98542\n",
      "Epoch: 4, step: 187/300, Loss: 0.41589\n",
      "Epoch: 4, step: 188/300, Loss: 0.36306\n",
      "Epoch: 4, step: 189/300, Loss: 0.06879\n",
      "Epoch: 4, step: 190/300, Loss: 0.03348\n",
      "Epoch: 4, step: 191/300, Loss: 0.57939\n",
      "Epoch: 4, step: 192/300, Loss: 0.02778\n",
      "Epoch: 4, step: 193/300, Loss: 0.08039\n",
      "Epoch: 4, step: 194/300, Loss: 1.08775\n",
      "Epoch: 4, step: 195/300, Loss: 0.10006\n",
      "Epoch: 4, step: 196/300, Loss: 0.01095\n",
      "Epoch: 4, step: 197/300, Loss: 0.06307\n",
      "Epoch: 4, step: 198/300, Loss: 0.03227\n",
      "Epoch: 4, step: 199/300, Loss: 0.11788\n",
      "Epoch: 4, step: 200/300, Loss: 0.24451\n",
      "Epoch: 4, step: 201/300, Loss: 0.04428\n",
      "Epoch: 4, step: 202/300, Loss: 0.31187\n",
      "Epoch: 4, step: 203/300, Loss: 0.01854\n",
      "Epoch: 4, step: 204/300, Loss: 0.04076\n",
      "Epoch: 4, step: 205/300, Loss: 0.03896\n",
      "Epoch: 4, step: 206/300, Loss: 0.19052\n",
      "Epoch: 4, step: 207/300, Loss: 0.01512\n",
      "Epoch: 4, step: 208/300, Loss: 0.00729\n",
      "Epoch: 4, step: 209/300, Loss: 0.00473\n",
      "Epoch: 4, step: 210/300, Loss: 0.00579\n",
      "Epoch: 4, step: 211/300, Loss: 0.02373\n",
      "Epoch: 4, step: 212/300, Loss: 1.94350\n",
      "Epoch: 4, step: 213/300, Loss: 0.02134\n",
      "Epoch: 4, step: 214/300, Loss: 0.03634\n",
      "Epoch: 4, step: 215/300, Loss: 0.42124\n",
      "Epoch: 4, step: 216/300, Loss: 0.30721\n",
      "Epoch: 4, step: 217/300, Loss: 1.04576\n",
      "Epoch: 4, step: 218/300, Loss: 0.12731\n",
      "Epoch: 4, step: 219/300, Loss: 0.01756\n",
      "Epoch: 4, step: 220/300, Loss: 0.10692\n",
      "Epoch: 4, step: 221/300, Loss: 0.38908\n",
      "Epoch: 4, step: 222/300, Loss: 0.00650\n",
      "Epoch: 4, step: 223/300, Loss: 0.28541\n",
      "Epoch: 4, step: 224/300, Loss: 0.20167\n",
      "Epoch: 4, step: 225/300, Loss: 0.04098\n",
      "Epoch: 4, step: 226/300, Loss: 0.00364\n",
      "Epoch: 4, step: 227/300, Loss: 0.53329\n",
      "Epoch: 4, step: 228/300, Loss: 0.00695\n",
      "Epoch: 4, step: 229/300, Loss: 0.00479\n",
      "Epoch: 4, step: 230/300, Loss: 0.04819\n",
      "Epoch: 4, step: 231/300, Loss: 1.67630\n",
      "Epoch: 4, step: 232/300, Loss: 3.35035\n",
      "Epoch: 4, step: 233/300, Loss: 0.20548\n",
      "Epoch: 4, step: 234/300, Loss: 0.08218\n",
      "Epoch: 4, step: 235/300, Loss: 0.00556\n",
      "Epoch: 4, step: 236/300, Loss: 0.02782\n",
      "Epoch: 4, step: 237/300, Loss: 0.01244\n",
      "Epoch: 4, step: 238/300, Loss: 0.05068\n",
      "Epoch: 4, step: 239/300, Loss: 0.02557\n",
      "Epoch: 4, step: 240/300, Loss: 0.02313\n",
      "Epoch: 4, step: 241/300, Loss: 0.15876\n",
      "Epoch: 4, step: 242/300, Loss: 3.03099\n",
      "Epoch: 4, step: 243/300, Loss: 0.04252\n",
      "Epoch: 4, step: 244/300, Loss: 0.37072\n",
      "Epoch: 4, step: 245/300, Loss: 0.02189\n",
      "Epoch: 4, step: 246/300, Loss: 0.37464\n",
      "Epoch: 4, step: 247/300, Loss: 0.28150\n",
      "Epoch: 4, step: 248/300, Loss: 0.05742\n",
      "Epoch: 4, step: 249/300, Loss: 0.81508\n",
      "Epoch: 4, step: 250/300, Loss: 0.41601\n",
      "Epoch: 4, step: 251/300, Loss: 0.05700\n",
      "Epoch: 4, step: 252/300, Loss: 0.12084\n",
      "Epoch: 4, step: 253/300, Loss: 0.03854\n",
      "Epoch: 4, step: 254/300, Loss: 0.37444\n",
      "Epoch: 4, step: 255/300, Loss: 0.04389\n",
      "Epoch: 4, step: 256/300, Loss: 0.22124\n",
      "Epoch: 4, step: 257/300, Loss: 0.03904\n",
      "Epoch: 4, step: 258/300, Loss: 0.10184\n",
      "Epoch: 4, step: 259/300, Loss: 0.02324\n",
      "Epoch: 4, step: 260/300, Loss: 0.13282\n",
      "Epoch: 4, step: 261/300, Loss: 0.74768\n",
      "Epoch: 4, step: 262/300, Loss: 0.08044\n",
      "Epoch: 4, step: 263/300, Loss: 0.08535\n",
      "Epoch: 4, step: 264/300, Loss: 0.02323\n",
      "Epoch: 4, step: 265/300, Loss: 0.29514\n",
      "Epoch: 4, step: 266/300, Loss: 0.01273\n",
      "Epoch: 4, step: 267/300, Loss: 0.02357\n",
      "Epoch: 4, step: 268/300, Loss: 0.03889\n",
      "Epoch: 4, step: 269/300, Loss: 0.99479\n",
      "Epoch: 4, step: 270/300, Loss: 0.07465\n",
      "Epoch: 4, step: 271/300, Loss: 0.11931\n",
      "Epoch: 4, step: 272/300, Loss: 0.02293\n",
      "Epoch: 4, step: 273/300, Loss: 1.01696\n",
      "Epoch: 4, step: 274/300, Loss: 0.46790\n",
      "Epoch: 4, step: 275/300, Loss: 0.04047\n",
      "Epoch: 4, step: 276/300, Loss: 0.01338\n",
      "Epoch: 4, step: 277/300, Loss: 0.31143\n",
      "Epoch: 4, step: 278/300, Loss: 0.17319\n",
      "Epoch: 4, step: 279/300, Loss: 0.25330\n",
      "Epoch: 4, step: 280/300, Loss: 0.71529\n",
      "Epoch: 4, step: 281/300, Loss: 0.01747\n",
      "Epoch: 4, step: 282/300, Loss: 0.01808\n",
      "Epoch: 4, step: 283/300, Loss: 0.72735\n",
      "Epoch: 4, step: 284/300, Loss: 0.07976\n",
      "Epoch: 4, step: 285/300, Loss: 1.25112\n",
      "Epoch: 4, step: 286/300, Loss: 0.47528\n",
      "Epoch: 4, step: 287/300, Loss: 0.09480\n",
      "Epoch: 4, step: 288/300, Loss: 0.07357\n",
      "Epoch: 4, step: 289/300, Loss: 0.01587\n",
      "Epoch: 4, step: 290/300, Loss: 0.09866\n",
      "Epoch: 4, step: 291/300, Loss: 0.57027\n",
      "Epoch: 4, step: 292/300, Loss: 0.13799\n",
      "Epoch: 4, step: 293/300, Loss: 0.01773\n",
      "Epoch: 4, step: 294/300, Loss: 0.06512\n",
      "Epoch: 4, step: 295/300, Loss: 0.18671\n",
      "Epoch: 4, step: 296/300, Loss: 0.03166\n",
      "Epoch: 4, step: 297/300, Loss: 0.02622\n",
      "Epoch: 4, step: 298/300, Loss: 0.04236\n",
      "Epoch: 4, step: 299/300, Loss: 0.34416\n",
      "Epoch: 5, step: 0/300, Loss: 1.44855\n",
      "Epoch: 5, step: 1/300, Loss: 0.01962\n",
      "Epoch: 5, step: 2/300, Loss: 0.01659\n",
      "Epoch: 5, step: 3/300, Loss: 0.09428\n",
      "Epoch: 5, step: 4/300, Loss: 0.15448\n",
      "Epoch: 5, step: 5/300, Loss: 0.01670\n",
      "Epoch: 5, step: 6/300, Loss: 0.15386\n",
      "Epoch: 5, step: 7/300, Loss: 0.02985\n",
      "Epoch: 5, step: 8/300, Loss: 0.01689\n",
      "Epoch: 5, step: 9/300, Loss: 0.19303\n",
      "Epoch: 5, step: 10/300, Loss: 0.01029\n",
      "Epoch: 5, step: 11/300, Loss: 0.11305\n",
      "Epoch: 5, step: 12/300, Loss: 0.03340\n",
      "Epoch: 5, step: 13/300, Loss: 0.03327\n",
      "Epoch: 5, step: 14/300, Loss: 0.02940\n",
      "Epoch: 5, step: 15/300, Loss: 0.19775\n",
      "Epoch: 5, step: 16/300, Loss: 0.39567\n",
      "Epoch: 5, step: 17/300, Loss: 0.01222\n",
      "Epoch: 5, step: 18/300, Loss: 0.03193\n",
      "Epoch: 5, step: 19/300, Loss: 0.02437\n",
      "Epoch: 5, step: 20/300, Loss: 0.05665\n",
      "Epoch: 5, step: 21/300, Loss: 2.14420\n",
      "Epoch: 5, step: 22/300, Loss: 0.12175\n",
      "Epoch: 5, step: 23/300, Loss: 0.01442\n",
      "Epoch: 5, step: 24/300, Loss: 0.72369\n",
      "Epoch: 5, step: 25/300, Loss: 0.06988\n",
      "Epoch: 5, step: 26/300, Loss: 0.09294\n",
      "Epoch: 5, step: 27/300, Loss: 0.01703\n",
      "Epoch: 5, step: 28/300, Loss: 0.00851\n",
      "Epoch: 5, step: 29/300, Loss: 0.04239\n",
      "Epoch: 5, step: 30/300, Loss: 0.03762\n",
      "Epoch: 5, step: 31/300, Loss: 0.02221\n",
      "Epoch: 5, step: 32/300, Loss: 0.03373\n",
      "Epoch: 5, step: 33/300, Loss: 0.00801\n",
      "Epoch: 5, step: 34/300, Loss: 0.02662\n",
      "Epoch: 5, step: 35/300, Loss: 0.02007\n",
      "Epoch: 5, step: 36/300, Loss: 0.00986\n",
      "Epoch: 5, step: 37/300, Loss: 0.05195\n",
      "Epoch: 5, step: 38/300, Loss: 0.01067\n",
      "Epoch: 5, step: 39/300, Loss: 0.09049\n",
      "Epoch: 5, step: 40/300, Loss: 0.01125\n",
      "Epoch: 5, step: 41/300, Loss: 0.07849\n",
      "Epoch: 5, step: 42/300, Loss: 0.25189\n",
      "Epoch: 5, step: 43/300, Loss: 0.29218\n",
      "Epoch: 5, step: 44/300, Loss: 0.05657\n",
      "Epoch: 5, step: 45/300, Loss: 0.07989\n",
      "Epoch: 5, step: 46/300, Loss: 0.01366\n",
      "Epoch: 5, step: 47/300, Loss: 0.16530\n",
      "Epoch: 5, step: 48/300, Loss: 0.01396\n",
      "Epoch: 5, step: 49/300, Loss: 0.02644\n",
      "Epoch: 5, step: 50/300, Loss: 0.03855\n",
      "Epoch: 5, step: 51/300, Loss: 0.02191\n",
      "Epoch: 5, step: 52/300, Loss: 0.71970\n",
      "Epoch: 5, step: 53/300, Loss: 0.04530\n",
      "Epoch: 5, step: 54/300, Loss: 0.01858\n",
      "Epoch: 5, step: 55/300, Loss: 0.05248\n",
      "Epoch: 5, step: 56/300, Loss: 0.01033\n",
      "Epoch: 5, step: 57/300, Loss: 0.02259\n",
      "Epoch: 5, step: 58/300, Loss: 0.03193\n",
      "Epoch: 5, step: 59/300, Loss: 2.11231\n",
      "Epoch: 5, step: 60/300, Loss: 0.06754\n",
      "Epoch: 5, step: 61/300, Loss: 0.04509\n",
      "Epoch: 5, step: 62/300, Loss: 0.01181\n",
      "Epoch: 5, step: 63/300, Loss: 0.01832\n",
      "Epoch: 5, step: 64/300, Loss: 2.82235\n",
      "Epoch: 5, step: 65/300, Loss: 0.17309\n",
      "Epoch: 5, step: 66/300, Loss: 0.02944\n",
      "Epoch: 5, step: 67/300, Loss: 0.03669\n",
      "Epoch: 5, step: 68/300, Loss: 0.01300\n",
      "Epoch: 5, step: 69/300, Loss: 0.05043\n",
      "Epoch: 5, step: 70/300, Loss: 0.03217\n",
      "Epoch: 5, step: 71/300, Loss: 0.04641\n",
      "Epoch: 5, step: 72/300, Loss: 0.42571\n",
      "Epoch: 5, step: 73/300, Loss: 0.05183\n",
      "Epoch: 5, step: 74/300, Loss: 0.01700\n",
      "Epoch: 5, step: 75/300, Loss: 0.01624\n",
      "Epoch: 5, step: 76/300, Loss: 0.03437\n",
      "Epoch: 5, step: 77/300, Loss: 0.04991\n",
      "Epoch: 5, step: 78/300, Loss: 0.04302\n",
      "Epoch: 5, step: 79/300, Loss: 0.05738\n",
      "Epoch: 5, step: 80/300, Loss: 0.10018\n",
      "Epoch: 5, step: 81/300, Loss: 0.00694\n",
      "Epoch: 5, step: 82/300, Loss: 0.01605\n",
      "Epoch: 5, step: 83/300, Loss: 0.01241\n",
      "Epoch: 5, step: 84/300, Loss: 0.14627\n",
      "Epoch: 5, step: 85/300, Loss: 0.16180\n",
      "Epoch: 5, step: 86/300, Loss: 0.17005\n",
      "Epoch: 5, step: 87/300, Loss: 0.15197\n",
      "Epoch: 5, step: 88/300, Loss: 0.29764\n",
      "Epoch: 5, step: 89/300, Loss: 0.63872\n",
      "Epoch: 5, step: 90/300, Loss: 0.10228\n",
      "Epoch: 5, step: 91/300, Loss: 0.04171\n",
      "Epoch: 5, step: 92/300, Loss: 0.02930\n",
      "Epoch: 5, step: 93/300, Loss: 0.12094\n",
      "Epoch: 5, step: 94/300, Loss: 0.00989\n",
      "Epoch: 5, step: 95/300, Loss: 0.01133\n",
      "Epoch: 5, step: 96/300, Loss: 0.01550\n",
      "Epoch: 5, step: 97/300, Loss: 0.02555\n",
      "Epoch: 5, step: 98/300, Loss: 0.03011\n",
      "Epoch: 5, step: 99/300, Loss: 0.02983\n",
      "Epoch: 5, step: 100/300, Loss: 0.53050\n",
      "Epoch: 5, step: 101/300, Loss: 0.01972\n",
      "Epoch: 5, step: 102/300, Loss: 0.00782\n",
      "Epoch: 5, step: 103/300, Loss: 0.02325\n",
      "Epoch: 5, step: 104/300, Loss: 0.35492\n",
      "Epoch: 5, step: 105/300, Loss: 1.93009\n",
      "Epoch: 5, step: 106/300, Loss: 0.45284\n",
      "Epoch: 5, step: 107/300, Loss: 0.07424\n",
      "Epoch: 5, step: 108/300, Loss: 0.39091\n",
      "Epoch: 5, step: 109/300, Loss: 0.01309\n",
      "Epoch: 5, step: 110/300, Loss: 0.13001\n",
      "Epoch: 5, step: 111/300, Loss: 0.03581\n",
      "Epoch: 5, step: 112/300, Loss: 0.01468\n",
      "Epoch: 5, step: 113/300, Loss: 0.00672\n",
      "Epoch: 5, step: 114/300, Loss: 0.04490\n",
      "Epoch: 5, step: 115/300, Loss: 0.01659\n",
      "Epoch: 5, step: 116/300, Loss: 0.05690\n",
      "Epoch: 5, step: 117/300, Loss: 0.06598\n",
      "Epoch: 5, step: 118/300, Loss: 0.00429\n",
      "Epoch: 5, step: 119/300, Loss: 0.21828\n",
      "Epoch: 5, step: 120/300, Loss: 0.00925\n",
      "Epoch: 5, step: 121/300, Loss: 0.00397\n",
      "Epoch: 5, step: 122/300, Loss: 0.06639\n",
      "Epoch: 5, step: 123/300, Loss: 0.00837\n",
      "Epoch: 5, step: 124/300, Loss: 0.00685\n",
      "Epoch: 5, step: 125/300, Loss: 0.05241\n",
      "Epoch: 5, step: 126/300, Loss: 0.01704\n",
      "Epoch: 5, step: 127/300, Loss: 0.01254\n",
      "Epoch: 5, step: 128/300, Loss: 0.98975\n",
      "Epoch: 5, step: 129/300, Loss: 0.03237\n",
      "Epoch: 5, step: 130/300, Loss: 0.03056\n",
      "Epoch: 5, step: 131/300, Loss: 0.08864\n",
      "Epoch: 5, step: 132/300, Loss: 0.00680\n",
      "Epoch: 5, step: 133/300, Loss: 0.09409\n",
      "Epoch: 5, step: 134/300, Loss: 0.02104\n",
      "Epoch: 5, step: 135/300, Loss: 0.02789\n",
      "Epoch: 5, step: 136/300, Loss: 0.00777\n",
      "Epoch: 5, step: 137/300, Loss: 0.01056\n",
      "Epoch: 5, step: 138/300, Loss: 0.02654\n",
      "Epoch: 5, step: 139/300, Loss: 0.43513\n",
      "Epoch: 5, step: 140/300, Loss: 0.02429\n",
      "Epoch: 5, step: 141/300, Loss: 0.00852\n",
      "Epoch: 5, step: 142/300, Loss: 0.01714\n",
      "Epoch: 5, step: 143/300, Loss: 0.61445\n",
      "Epoch: 5, step: 144/300, Loss: 0.00483\n",
      "Epoch: 5, step: 145/300, Loss: 0.19847\n",
      "Epoch: 5, step: 146/300, Loss: 0.01398\n",
      "Epoch: 5, step: 147/300, Loss: 0.00716\n",
      "Epoch: 5, step: 148/300, Loss: 0.02518\n",
      "Epoch: 5, step: 149/300, Loss: 0.03295\n",
      "Epoch: 5, step: 150/300, Loss: 0.00726\n",
      "Epoch: 5, step: 151/300, Loss: 0.00853\n",
      "Epoch: 5, step: 152/300, Loss: 0.03333\n",
      "Epoch: 5, step: 153/300, Loss: 0.02005\n",
      "Epoch: 5, step: 154/300, Loss: 0.00559\n",
      "Epoch: 5, step: 155/300, Loss: 0.75603\n",
      "Epoch: 5, step: 156/300, Loss: 0.06898\n",
      "Epoch: 5, step: 157/300, Loss: 0.01206\n",
      "Epoch: 5, step: 158/300, Loss: 0.00468\n",
      "Epoch: 5, step: 159/300, Loss: 0.01899\n",
      "Epoch: 5, step: 160/300, Loss: 0.60691\n",
      "Epoch: 5, step: 161/300, Loss: 0.01135\n",
      "Epoch: 5, step: 162/300, Loss: 0.06556\n",
      "Epoch: 5, step: 163/300, Loss: 0.01271\n",
      "Epoch: 5, step: 164/300, Loss: 2.76682\n",
      "Epoch: 5, step: 165/300, Loss: 0.01066\n",
      "Epoch: 5, step: 166/300, Loss: 0.00766\n",
      "Epoch: 5, step: 167/300, Loss: 0.56130\n",
      "Epoch: 5, step: 168/300, Loss: 0.30251\n",
      "Epoch: 5, step: 169/300, Loss: 0.81801\n",
      "Epoch: 5, step: 170/300, Loss: 0.00600\n",
      "Epoch: 5, step: 171/300, Loss: 0.06748\n",
      "Epoch: 5, step: 172/300, Loss: 0.13262\n",
      "Epoch: 5, step: 173/300, Loss: 0.00265\n",
      "Epoch: 5, step: 174/300, Loss: 0.01173\n",
      "Epoch: 5, step: 175/300, Loss: 0.02102\n",
      "Epoch: 5, step: 176/300, Loss: 0.01662\n",
      "Epoch: 5, step: 177/300, Loss: 0.16109\n",
      "Epoch: 5, step: 178/300, Loss: 1.20867\n",
      "Epoch: 5, step: 179/300, Loss: 0.08679\n",
      "Epoch: 5, step: 180/300, Loss: 0.05377\n",
      "Epoch: 5, step: 181/300, Loss: 0.03419\n",
      "Epoch: 5, step: 182/300, Loss: 0.05816\n",
      "Epoch: 5, step: 183/300, Loss: 0.07780\n",
      "Epoch: 5, step: 184/300, Loss: 0.72029\n",
      "Epoch: 5, step: 185/300, Loss: 0.29518\n",
      "Epoch: 5, step: 186/300, Loss: 0.00786\n",
      "Epoch: 5, step: 187/300, Loss: 0.01024\n",
      "Epoch: 5, step: 188/300, Loss: 0.15098\n",
      "Epoch: 5, step: 189/300, Loss: 0.01962\n",
      "Epoch: 5, step: 190/300, Loss: 0.18230\n",
      "Epoch: 5, step: 191/300, Loss: 0.08651\n",
      "Epoch: 5, step: 192/300, Loss: 0.38448\n",
      "Epoch: 5, step: 193/300, Loss: 0.06068\n",
      "Epoch: 5, step: 194/300, Loss: 1.32383\n",
      "Epoch: 5, step: 195/300, Loss: 0.00372\n",
      "Epoch: 5, step: 196/300, Loss: 0.01203\n",
      "Epoch: 5, step: 197/300, Loss: 0.23450\n",
      "Epoch: 5, step: 198/300, Loss: 0.00597\n",
      "Epoch: 5, step: 199/300, Loss: 0.03330\n",
      "Epoch: 5, step: 200/300, Loss: 0.50049\n",
      "Epoch: 5, step: 201/300, Loss: 0.00292\n",
      "Epoch: 5, step: 202/300, Loss: 0.01838\n",
      "Epoch: 5, step: 203/300, Loss: 0.04370\n",
      "Epoch: 5, step: 204/300, Loss: 0.01448\n",
      "Epoch: 5, step: 205/300, Loss: 0.09126\n",
      "Epoch: 5, step: 206/300, Loss: 0.02207\n",
      "Epoch: 5, step: 207/300, Loss: 0.01120\n",
      "Epoch: 5, step: 208/300, Loss: 0.01561\n",
      "Epoch: 5, step: 209/300, Loss: 0.01556\n",
      "Epoch: 5, step: 210/300, Loss: 0.03050\n",
      "Epoch: 5, step: 211/300, Loss: 0.02860\n",
      "Epoch: 5, step: 212/300, Loss: 0.02585\n",
      "Epoch: 5, step: 213/300, Loss: 0.08822\n",
      "Epoch: 5, step: 214/300, Loss: 0.01674\n",
      "Epoch: 5, step: 215/300, Loss: 0.12636\n",
      "Epoch: 5, step: 216/300, Loss: 0.00380\n",
      "Epoch: 5, step: 217/300, Loss: 0.00522\n",
      "Epoch: 5, step: 218/300, Loss: 0.00453\n",
      "Epoch: 5, step: 219/300, Loss: 0.01589\n",
      "Epoch: 5, step: 220/300, Loss: 0.02109\n",
      "Epoch: 5, step: 221/300, Loss: 0.18698\n",
      "Epoch: 5, step: 222/300, Loss: 0.04044\n",
      "Epoch: 5, step: 223/300, Loss: 0.01711\n",
      "Epoch: 5, step: 224/300, Loss: 0.24990\n",
      "Epoch: 5, step: 225/300, Loss: 0.77204\n",
      "Epoch: 5, step: 226/300, Loss: 0.01355\n",
      "Epoch: 5, step: 227/300, Loss: 0.02205\n",
      "Epoch: 5, step: 228/300, Loss: 0.00957\n",
      "Epoch: 5, step: 229/300, Loss: 0.23332\n",
      "Epoch: 5, step: 230/300, Loss: 0.02195\n",
      "Epoch: 5, step: 231/300, Loss: 0.00551\n",
      "Epoch: 5, step: 232/300, Loss: 0.70338\n",
      "Epoch: 5, step: 233/300, Loss: 0.01169\n",
      "Epoch: 5, step: 234/300, Loss: 0.02078\n",
      "Epoch: 5, step: 235/300, Loss: 0.01180\n",
      "Epoch: 5, step: 236/300, Loss: 0.83949\n",
      "Epoch: 5, step: 237/300, Loss: 0.01482\n",
      "Epoch: 5, step: 238/300, Loss: 0.01589\n",
      "Epoch: 5, step: 239/300, Loss: 0.02974\n",
      "Epoch: 5, step: 240/300, Loss: 0.39396\n",
      "Epoch: 5, step: 241/300, Loss: 0.04540\n",
      "Epoch: 5, step: 242/300, Loss: 0.05561\n",
      "Epoch: 5, step: 243/300, Loss: 0.00694\n",
      "Epoch: 5, step: 244/300, Loss: 0.00416\n",
      "Epoch: 5, step: 245/300, Loss: 0.05383\n",
      "Epoch: 5, step: 246/300, Loss: 0.33377\n",
      "Epoch: 5, step: 247/300, Loss: 0.00524\n",
      "Epoch: 5, step: 248/300, Loss: 0.02582\n",
      "Epoch: 5, step: 249/300, Loss: 0.00379\n",
      "Epoch: 5, step: 250/300, Loss: 0.13760\n",
      "Epoch: 5, step: 251/300, Loss: 0.02352\n",
      "Epoch: 5, step: 252/300, Loss: 0.45598\n",
      "Epoch: 5, step: 253/300, Loss: 0.03426\n",
      "Epoch: 5, step: 254/300, Loss: 0.13017\n",
      "Epoch: 5, step: 255/300, Loss: 0.07886\n",
      "Epoch: 5, step: 256/300, Loss: 0.09368\n",
      "Epoch: 5, step: 257/300, Loss: 0.02745\n",
      "Epoch: 5, step: 258/300, Loss: 0.08056\n",
      "Epoch: 5, step: 259/300, Loss: 0.10139\n",
      "Epoch: 5, step: 260/300, Loss: 0.03239\n",
      "Epoch: 5, step: 261/300, Loss: 0.01387\n",
      "Epoch: 5, step: 262/300, Loss: 0.00936\n",
      "Epoch: 5, step: 263/300, Loss: 0.01205\n",
      "Epoch: 5, step: 264/300, Loss: 0.05714\n",
      "Epoch: 5, step: 265/300, Loss: 0.01911\n",
      "Epoch: 5, step: 266/300, Loss: 0.02095\n",
      "Epoch: 5, step: 267/300, Loss: 0.01707\n",
      "Epoch: 5, step: 268/300, Loss: 0.05766\n",
      "Epoch: 5, step: 269/300, Loss: 0.02087\n",
      "Epoch: 5, step: 270/300, Loss: 1.43117\n",
      "Epoch: 5, step: 271/300, Loss: 0.02731\n",
      "Epoch: 5, step: 272/300, Loss: 1.90463\n",
      "Epoch: 5, step: 273/300, Loss: 0.01170\n",
      "Epoch: 5, step: 274/300, Loss: 0.03291\n",
      "Epoch: 5, step: 275/300, Loss: 0.03740\n",
      "Epoch: 5, step: 276/300, Loss: 0.00497\n",
      "Epoch: 5, step: 277/300, Loss: 0.05841\n",
      "Epoch: 5, step: 278/300, Loss: 0.03889\n",
      "Epoch: 5, step: 279/300, Loss: 0.66428\n",
      "Epoch: 5, step: 280/300, Loss: 0.16631\n",
      "Epoch: 5, step: 281/300, Loss: 0.05386\n",
      "Epoch: 5, step: 282/300, Loss: 0.52391\n",
      "Epoch: 5, step: 283/300, Loss: 0.01223\n",
      "Epoch: 5, step: 284/300, Loss: 1.99959\n",
      "Epoch: 5, step: 285/300, Loss: 0.01097\n",
      "Epoch: 5, step: 286/300, Loss: 0.07949\n",
      "Epoch: 5, step: 287/300, Loss: 0.02176\n",
      "Epoch: 5, step: 288/300, Loss: 0.02500\n",
      "Epoch: 5, step: 289/300, Loss: 0.03860\n",
      "Epoch: 5, step: 290/300, Loss: 0.03389\n",
      "Epoch: 5, step: 291/300, Loss: 0.00724\n",
      "Epoch: 5, step: 292/300, Loss: 0.00784\n",
      "Epoch: 5, step: 293/300, Loss: 0.01686\n",
      "Epoch: 5, step: 294/300, Loss: 0.01015\n",
      "Epoch: 5, step: 295/300, Loss: 0.00938\n",
      "Epoch: 5, step: 296/300, Loss: 0.03005\n",
      "Epoch: 5, step: 297/300, Loss: 0.01822\n",
      "Epoch: 5, step: 298/300, Loss: 0.30490\n",
      "Epoch: 5, step: 299/300, Loss: 0.04357\n",
      "Epoch: 6, step: 0/300, Loss: 0.00582\n",
      "Epoch: 6, step: 1/300, Loss: 0.14427\n",
      "Epoch: 6, step: 2/300, Loss: 0.01721\n",
      "Epoch: 6, step: 3/300, Loss: 0.00671\n",
      "Epoch: 6, step: 4/300, Loss: 0.01941\n",
      "Epoch: 6, step: 5/300, Loss: 0.01046\n",
      "Epoch: 6, step: 6/300, Loss: 0.02125\n",
      "Epoch: 6, step: 7/300, Loss: 0.01392\n",
      "Epoch: 6, step: 8/300, Loss: 0.01485\n",
      "Epoch: 6, step: 9/300, Loss: 0.00838\n",
      "Epoch: 6, step: 10/300, Loss: 0.08589\n",
      "Epoch: 6, step: 11/300, Loss: 0.02490\n",
      "Epoch: 6, step: 12/300, Loss: 0.00549\n",
      "Epoch: 6, step: 13/300, Loss: 0.05664\n",
      "Epoch: 6, step: 14/300, Loss: 3.59090\n",
      "Epoch: 6, step: 15/300, Loss: 0.01839\n",
      "Epoch: 6, step: 16/300, Loss: 0.01145\n",
      "Epoch: 6, step: 17/300, Loss: 0.01379\n",
      "Epoch: 6, step: 18/300, Loss: 0.60052\n",
      "Epoch: 6, step: 19/300, Loss: 0.06151\n",
      "Epoch: 6, step: 20/300, Loss: 0.00507\n",
      "Epoch: 6, step: 21/300, Loss: 0.00555\n",
      "Epoch: 6, step: 22/300, Loss: 0.01298\n",
      "Epoch: 6, step: 23/300, Loss: 0.02286\n",
      "Epoch: 6, step: 24/300, Loss: 0.03551\n",
      "Epoch: 6, step: 25/300, Loss: 0.07721\n",
      "Epoch: 6, step: 26/300, Loss: 0.02299\n",
      "Epoch: 6, step: 27/300, Loss: 0.03494\n",
      "Epoch: 6, step: 28/300, Loss: 1.42786\n",
      "Epoch: 6, step: 29/300, Loss: 0.00415\n",
      "Epoch: 6, step: 30/300, Loss: 0.04735\n",
      "Epoch: 6, step: 31/300, Loss: 0.02478\n",
      "Epoch: 6, step: 32/300, Loss: 0.03567\n",
      "Epoch: 6, step: 33/300, Loss: 0.09284\n",
      "Epoch: 6, step: 34/300, Loss: 0.01177\n",
      "Epoch: 6, step: 35/300, Loss: 0.03824\n",
      "Epoch: 6, step: 36/300, Loss: 0.04966\n",
      "Epoch: 6, step: 37/300, Loss: 0.06631\n",
      "Epoch: 6, step: 38/300, Loss: 0.01308\n",
      "Epoch: 6, step: 39/300, Loss: 0.01910\n",
      "Epoch: 6, step: 40/300, Loss: 0.01183\n",
      "Epoch: 6, step: 41/300, Loss: 3.73392\n",
      "Epoch: 6, step: 42/300, Loss: 0.02665\n",
      "Epoch: 6, step: 43/300, Loss: 0.01175\n",
      "Epoch: 6, step: 44/300, Loss: 0.05946\n",
      "Epoch: 6, step: 45/300, Loss: 0.11212\n",
      "Epoch: 6, step: 46/300, Loss: 0.53548\n",
      "Epoch: 6, step: 47/300, Loss: 0.00621\n",
      "Epoch: 6, step: 48/300, Loss: 0.18974\n",
      "Epoch: 6, step: 49/300, Loss: 1.26584\n",
      "Epoch: 6, step: 50/300, Loss: 0.01509\n",
      "Epoch: 6, step: 51/300, Loss: 0.05562\n",
      "Epoch: 6, step: 52/300, Loss: 0.15134\n",
      "Epoch: 6, step: 53/300, Loss: 0.04549\n",
      "Epoch: 6, step: 54/300, Loss: 0.10040\n",
      "Epoch: 6, step: 55/300, Loss: 0.01560\n",
      "Epoch: 6, step: 56/300, Loss: 0.06086\n",
      "Epoch: 6, step: 57/300, Loss: 0.02608\n",
      "Epoch: 6, step: 58/300, Loss: 0.01760\n",
      "Epoch: 6, step: 59/300, Loss: 0.01093\n",
      "Epoch: 6, step: 60/300, Loss: 0.01936\n",
      "Epoch: 6, step: 61/300, Loss: 0.04002\n",
      "Epoch: 6, step: 62/300, Loss: 0.16850\n",
      "Epoch: 6, step: 63/300, Loss: 0.07812\n",
      "Epoch: 6, step: 64/300, Loss: 0.08986\n",
      "Epoch: 6, step: 65/300, Loss: 0.07067\n",
      "Epoch: 6, step: 66/300, Loss: 0.84447\n",
      "Epoch: 6, step: 67/300, Loss: 0.02979\n",
      "Epoch: 6, step: 68/300, Loss: 0.05074\n",
      "Epoch: 6, step: 69/300, Loss: 0.12568\n",
      "Epoch: 6, step: 70/300, Loss: 0.07534\n",
      "Epoch: 6, step: 71/300, Loss: 0.00267\n",
      "Epoch: 6, step: 72/300, Loss: 0.13436\n",
      "Epoch: 6, step: 73/300, Loss: 0.03834\n",
      "Epoch: 6, step: 74/300, Loss: 0.02182\n",
      "Epoch: 6, step: 75/300, Loss: 0.00762\n",
      "Epoch: 6, step: 76/300, Loss: 0.04308\n",
      "Epoch: 6, step: 77/300, Loss: 0.55682\n",
      "Epoch: 6, step: 78/300, Loss: 0.07356\n",
      "Epoch: 6, step: 79/300, Loss: 0.11504\n",
      "Epoch: 6, step: 80/300, Loss: 0.01525\n",
      "Epoch: 6, step: 81/300, Loss: 0.34615\n",
      "Epoch: 6, step: 82/300, Loss: 0.00347\n",
      "Epoch: 6, step: 83/300, Loss: 0.29635\n",
      "Epoch: 6, step: 84/300, Loss: 0.05829\n",
      "Epoch: 6, step: 85/300, Loss: 0.00564\n",
      "Epoch: 6, step: 86/300, Loss: 0.00462\n",
      "Epoch: 6, step: 87/300, Loss: 0.01835\n",
      "Epoch: 6, step: 88/300, Loss: 0.02442\n",
      "Epoch: 6, step: 89/300, Loss: 0.03661\n",
      "Epoch: 6, step: 90/300, Loss: 0.01376\n",
      "Epoch: 6, step: 91/300, Loss: 0.01191\n",
      "Epoch: 6, step: 92/300, Loss: 0.05408\n",
      "Epoch: 6, step: 93/300, Loss: 0.19561\n",
      "Epoch: 6, step: 94/300, Loss: 0.01484\n",
      "Epoch: 6, step: 95/300, Loss: 0.05592\n",
      "Epoch: 6, step: 96/300, Loss: 0.01560\n",
      "Epoch: 6, step: 97/300, Loss: 0.00598\n",
      "Epoch: 6, step: 98/300, Loss: 0.66843\n",
      "Epoch: 6, step: 99/300, Loss: 0.01744\n",
      "Epoch: 6, step: 100/300, Loss: 0.01034\n",
      "Epoch: 6, step: 101/300, Loss: 0.76064\n",
      "Epoch: 6, step: 102/300, Loss: 0.01449\n",
      "Epoch: 6, step: 103/300, Loss: 0.00289\n",
      "Epoch: 6, step: 104/300, Loss: 0.02365\n",
      "Epoch: 6, step: 105/300, Loss: 0.04295\n",
      "Epoch: 6, step: 106/300, Loss: 0.01040\n",
      "Epoch: 6, step: 107/300, Loss: 0.21327\n",
      "Epoch: 6, step: 108/300, Loss: 0.04150\n",
      "Epoch: 6, step: 109/300, Loss: 0.00960\n",
      "Epoch: 6, step: 110/300, Loss: 0.00429\n",
      "Epoch: 6, step: 111/300, Loss: 0.00346\n",
      "Epoch: 6, step: 112/300, Loss: 0.00311\n",
      "Epoch: 6, step: 113/300, Loss: 0.35746\n",
      "Epoch: 6, step: 114/300, Loss: 0.00255\n",
      "Epoch: 6, step: 115/300, Loss: 0.00583\n",
      "Epoch: 6, step: 116/300, Loss: 0.06121\n",
      "Epoch: 6, step: 117/300, Loss: 0.00730\n",
      "Epoch: 6, step: 118/300, Loss: 0.02144\n",
      "Epoch: 6, step: 119/300, Loss: 0.64060\n",
      "Epoch: 6, step: 120/300, Loss: 0.02351\n",
      "Epoch: 6, step: 121/300, Loss: 0.16838\n",
      "Epoch: 6, step: 122/300, Loss: 0.06173\n",
      "Epoch: 6, step: 123/300, Loss: 0.08165\n",
      "Epoch: 6, step: 124/300, Loss: 2.10673\n",
      "Epoch: 6, step: 125/300, Loss: 0.06323\n",
      "Epoch: 6, step: 126/300, Loss: 0.09040\n",
      "Epoch: 6, step: 127/300, Loss: 0.01539\n",
      "Epoch: 6, step: 128/300, Loss: 0.42903\n",
      "Epoch: 6, step: 129/300, Loss: 0.01231\n",
      "Epoch: 6, step: 130/300, Loss: 0.01088\n",
      "Epoch: 6, step: 131/300, Loss: 0.01650\n",
      "Epoch: 6, step: 132/300, Loss: 0.00580\n",
      "Epoch: 6, step: 133/300, Loss: 0.00807\n",
      "Epoch: 6, step: 134/300, Loss: 0.00685\n",
      "Epoch: 6, step: 135/300, Loss: 0.02901\n",
      "Epoch: 6, step: 136/300, Loss: 0.10131\n",
      "Epoch: 6, step: 137/300, Loss: 0.37474\n",
      "Epoch: 6, step: 138/300, Loss: 0.01952\n",
      "Epoch: 6, step: 139/300, Loss: 0.01122\n",
      "Epoch: 6, step: 140/300, Loss: 0.00878\n",
      "Epoch: 6, step: 141/300, Loss: 0.01326\n",
      "Epoch: 6, step: 142/300, Loss: 0.04723\n",
      "Epoch: 6, step: 143/300, Loss: 0.02788\n",
      "Epoch: 6, step: 144/300, Loss: 0.01126\n",
      "Epoch: 6, step: 145/300, Loss: 0.06605\n",
      "Epoch: 6, step: 146/300, Loss: 0.00854\n",
      "Epoch: 6, step: 147/300, Loss: 0.01239\n",
      "Epoch: 6, step: 148/300, Loss: 0.49336\n",
      "Epoch: 6, step: 149/300, Loss: 0.04200\n",
      "Epoch: 6, step: 150/300, Loss: 1.23511\n",
      "Epoch: 6, step: 151/300, Loss: 0.15034\n",
      "Epoch: 6, step: 152/300, Loss: 0.02448\n",
      "Epoch: 6, step: 153/300, Loss: 0.08769\n",
      "Epoch: 6, step: 154/300, Loss: 0.00328\n",
      "Epoch: 6, step: 155/300, Loss: 0.65946\n",
      "Epoch: 6, step: 156/300, Loss: 0.03954\n",
      "Epoch: 6, step: 157/300, Loss: 0.00528\n",
      "Epoch: 6, step: 158/300, Loss: 0.50694\n",
      "Epoch: 6, step: 159/300, Loss: 0.01622\n",
      "Epoch: 6, step: 160/300, Loss: 0.58152\n",
      "Epoch: 6, step: 161/300, Loss: 0.00464\n",
      "Epoch: 6, step: 162/300, Loss: 0.02361\n",
      "Epoch: 6, step: 163/300, Loss: 0.34377\n",
      "Epoch: 6, step: 164/300, Loss: 0.01888\n",
      "Epoch: 6, step: 165/300, Loss: 0.01454\n",
      "Epoch: 6, step: 166/300, Loss: 0.01957\n",
      "Epoch: 6, step: 167/300, Loss: 0.09179\n",
      "Epoch: 6, step: 168/300, Loss: 0.01440\n",
      "Epoch: 6, step: 169/300, Loss: 0.01252\n",
      "Epoch: 6, step: 170/300, Loss: 0.01160\n",
      "Epoch: 6, step: 171/300, Loss: 0.23358\n",
      "Epoch: 6, step: 172/300, Loss: 0.12527\n",
      "Epoch: 6, step: 173/300, Loss: 0.01269\n",
      "Epoch: 6, step: 174/300, Loss: 0.14381\n",
      "Epoch: 6, step: 175/300, Loss: 0.00337\n",
      "Epoch: 6, step: 176/300, Loss: 3.87805\n",
      "Epoch: 6, step: 177/300, Loss: 0.04614\n",
      "Epoch: 6, step: 178/300, Loss: 0.00847\n",
      "Epoch: 6, step: 179/300, Loss: 0.00940\n",
      "Epoch: 6, step: 180/300, Loss: 0.09192\n",
      "Epoch: 6, step: 181/300, Loss: 0.58134\n",
      "Epoch: 6, step: 182/300, Loss: 0.03474\n",
      "Epoch: 6, step: 183/300, Loss: 0.05100\n",
      "Epoch: 6, step: 184/300, Loss: 0.07404\n",
      "Epoch: 6, step: 185/300, Loss: 0.00830\n",
      "Epoch: 6, step: 186/300, Loss: 0.20050\n",
      "Epoch: 6, step: 187/300, Loss: 0.30786\n",
      "Epoch: 6, step: 188/300, Loss: 0.01088\n",
      "Epoch: 6, step: 189/300, Loss: 0.00571\n",
      "Epoch: 6, step: 190/300, Loss: 0.00720\n",
      "Epoch: 6, step: 191/300, Loss: 0.28143\n",
      "Epoch: 6, step: 192/300, Loss: 0.04939\n",
      "Epoch: 6, step: 193/300, Loss: 0.47739\n",
      "Epoch: 6, step: 194/300, Loss: 0.57688\n",
      "Epoch: 6, step: 195/300, Loss: 0.00302\n",
      "Epoch: 6, step: 196/300, Loss: 0.00421\n",
      "Epoch: 6, step: 197/300, Loss: 0.00509\n",
      "Epoch: 6, step: 198/300, Loss: 0.01278\n",
      "Epoch: 6, step: 199/300, Loss: 0.02246\n",
      "Epoch: 6, step: 200/300, Loss: 0.04362\n",
      "Epoch: 6, step: 201/300, Loss: 0.04418\n",
      "Epoch: 6, step: 202/300, Loss: 0.00278\n",
      "Epoch: 6, step: 203/300, Loss: 0.33917\n",
      "Epoch: 6, step: 204/300, Loss: 0.16666\n",
      "Epoch: 6, step: 205/300, Loss: 0.01088\n",
      "Epoch: 6, step: 206/300, Loss: 0.00909\n",
      "Epoch: 6, step: 207/300, Loss: 0.00641\n",
      "Epoch: 6, step: 208/300, Loss: 0.62649\n",
      "Epoch: 6, step: 209/300, Loss: 0.01112\n",
      "Epoch: 6, step: 210/300, Loss: 1.86792\n",
      "Epoch: 6, step: 211/300, Loss: 0.02757\n",
      "Epoch: 6, step: 212/300, Loss: 0.03015\n",
      "Epoch: 6, step: 213/300, Loss: 0.06874\n",
      "Epoch: 6, step: 214/300, Loss: 0.01021\n",
      "Epoch: 6, step: 215/300, Loss: 0.00598\n",
      "Epoch: 6, step: 216/300, Loss: 0.04023\n",
      "Epoch: 6, step: 217/300, Loss: 0.03075\n",
      "Epoch: 6, step: 218/300, Loss: 0.00952\n",
      "Epoch: 6, step: 219/300, Loss: 0.32230\n",
      "Epoch: 6, step: 220/300, Loss: 0.00919\n",
      "Epoch: 6, step: 221/300, Loss: 0.00454\n",
      "Epoch: 6, step: 222/300, Loss: 0.29200\n",
      "Epoch: 6, step: 223/300, Loss: 0.01635\n",
      "Epoch: 6, step: 224/300, Loss: 0.29127\n",
      "Epoch: 6, step: 225/300, Loss: 0.09737\n",
      "Epoch: 6, step: 226/300, Loss: 0.00248\n",
      "Epoch: 6, step: 227/300, Loss: 0.00902\n",
      "Epoch: 6, step: 228/300, Loss: 0.00330\n",
      "Epoch: 6, step: 229/300, Loss: 0.00946\n",
      "Epoch: 6, step: 230/300, Loss: 0.00438\n",
      "Epoch: 6, step: 231/300, Loss: 0.02849\n",
      "Epoch: 6, step: 232/300, Loss: 0.06629\n",
      "Epoch: 6, step: 233/300, Loss: 0.00391\n",
      "Epoch: 6, step: 234/300, Loss: 0.03996\n",
      "Epoch: 6, step: 235/300, Loss: 0.13000\n",
      "Epoch: 6, step: 236/300, Loss: 0.26903\n",
      "Epoch: 6, step: 237/300, Loss: 0.01520\n",
      "Epoch: 6, step: 238/300, Loss: 0.00765\n",
      "Epoch: 6, step: 239/300, Loss: 0.02980\n",
      "Epoch: 6, step: 240/300, Loss: 0.01341\n",
      "Epoch: 6, step: 241/300, Loss: 0.00606\n",
      "Epoch: 6, step: 242/300, Loss: 0.00397\n",
      "Epoch: 6, step: 243/300, Loss: 0.02172\n",
      "Epoch: 6, step: 244/300, Loss: 0.01221\n",
      "Epoch: 6, step: 245/300, Loss: 0.02608\n",
      "Epoch: 6, step: 246/300, Loss: 3.14056\n",
      "Epoch: 6, step: 247/300, Loss: 0.01307\n",
      "Epoch: 6, step: 248/300, Loss: 0.04941\n",
      "Epoch: 6, step: 249/300, Loss: 0.17268\n",
      "Epoch: 6, step: 250/300, Loss: 0.01698\n",
      "Epoch: 6, step: 251/300, Loss: 0.02850\n",
      "Epoch: 6, step: 252/300, Loss: 0.02880\n",
      "Epoch: 6, step: 253/300, Loss: 0.01381\n",
      "Epoch: 6, step: 254/300, Loss: 0.06337\n",
      "Epoch: 6, step: 255/300, Loss: 0.03854\n",
      "Epoch: 6, step: 256/300, Loss: 0.02086\n",
      "Epoch: 6, step: 257/300, Loss: 0.03613\n",
      "Epoch: 6, step: 258/300, Loss: 0.01011\n",
      "Epoch: 6, step: 259/300, Loss: 0.01185\n",
      "Epoch: 6, step: 260/300, Loss: 0.05451\n",
      "Epoch: 6, step: 261/300, Loss: 1.87389\n",
      "Epoch: 6, step: 262/300, Loss: 0.00844\n",
      "Epoch: 6, step: 263/300, Loss: 0.04446\n",
      "Epoch: 6, step: 264/300, Loss: 0.02157\n",
      "Epoch: 6, step: 265/300, Loss: 0.42678\n",
      "Epoch: 6, step: 266/300, Loss: 0.03326\n",
      "Epoch: 6, step: 267/300, Loss: 0.09525\n",
      "Epoch: 6, step: 268/300, Loss: 0.01693\n",
      "Epoch: 6, step: 269/300, Loss: 0.01490\n",
      "Epoch: 6, step: 270/300, Loss: 0.02280\n",
      "Epoch: 6, step: 271/300, Loss: 0.03616\n",
      "Epoch: 6, step: 272/300, Loss: 0.01144\n",
      "Epoch: 6, step: 273/300, Loss: 0.01492\n",
      "Epoch: 6, step: 274/300, Loss: 0.01718\n",
      "Epoch: 6, step: 275/300, Loss: 0.03714\n",
      "Epoch: 6, step: 276/300, Loss: 0.02898\n",
      "Epoch: 6, step: 277/300, Loss: 0.24893\n",
      "Epoch: 6, step: 278/300, Loss: 0.01232\n",
      "Epoch: 6, step: 279/300, Loss: 0.04046\n",
      "Epoch: 6, step: 280/300, Loss: 0.09232\n",
      "Epoch: 6, step: 281/300, Loss: 0.03439\n",
      "Epoch: 6, step: 282/300, Loss: 0.05741\n",
      "Epoch: 6, step: 283/300, Loss: 0.13791\n",
      "Epoch: 6, step: 284/300, Loss: 0.02362\n",
      "Epoch: 6, step: 285/300, Loss: 0.01065\n",
      "Epoch: 6, step: 286/300, Loss: 0.93003\n",
      "Epoch: 6, step: 287/300, Loss: 0.08299\n",
      "Epoch: 6, step: 288/300, Loss: 0.09015\n",
      "Epoch: 6, step: 289/300, Loss: 0.06871\n",
      "Epoch: 6, step: 290/300, Loss: 0.01623\n",
      "Epoch: 6, step: 291/300, Loss: 1.21846\n",
      "Epoch: 6, step: 292/300, Loss: 0.08305\n",
      "Epoch: 6, step: 293/300, Loss: 0.02937\n",
      "Epoch: 6, step: 294/300, Loss: 0.00219\n",
      "Epoch: 6, step: 295/300, Loss: 0.09236\n",
      "Epoch: 6, step: 296/300, Loss: 0.00839\n",
      "Epoch: 6, step: 297/300, Loss: 0.03509\n",
      "Epoch: 6, step: 298/300, Loss: 0.02192\n",
      "Epoch: 6, step: 299/300, Loss: 0.03221\n",
      "Epoch: 7, step: 0/300, Loss: 0.03400\n",
      "Epoch: 7, step: 1/300, Loss: 0.06181\n",
      "Epoch: 7, step: 2/300, Loss: 0.01237\n",
      "Epoch: 7, step: 3/300, Loss: 0.04322\n",
      "Epoch: 7, step: 4/300, Loss: 0.02532\n",
      "Epoch: 7, step: 5/300, Loss: 0.02499\n",
      "Epoch: 7, step: 6/300, Loss: 0.01291\n",
      "Epoch: 7, step: 7/300, Loss: 0.49545\n",
      "Epoch: 7, step: 8/300, Loss: 0.02617\n",
      "Epoch: 7, step: 9/300, Loss: 0.02471\n",
      "Epoch: 7, step: 10/300, Loss: 0.05050\n",
      "Epoch: 7, step: 11/300, Loss: 0.02460\n",
      "Epoch: 7, step: 12/300, Loss: 0.01637\n",
      "Epoch: 7, step: 13/300, Loss: 0.02006\n",
      "Epoch: 7, step: 14/300, Loss: 0.01895\n",
      "Epoch: 7, step: 15/300, Loss: 0.02733\n",
      "Epoch: 7, step: 16/300, Loss: 0.01469\n",
      "Epoch: 7, step: 17/300, Loss: 0.01638\n",
      "Epoch: 7, step: 18/300, Loss: 0.01043\n",
      "Epoch: 7, step: 19/300, Loss: 0.01801\n",
      "Epoch: 7, step: 20/300, Loss: 0.01542\n",
      "Epoch: 7, step: 21/300, Loss: 0.00507\n",
      "Epoch: 7, step: 22/300, Loss: 0.01104\n",
      "Epoch: 7, step: 23/300, Loss: 0.09025\n",
      "Epoch: 7, step: 24/300, Loss: 0.01082\n",
      "Epoch: 7, step: 25/300, Loss: 0.19805\n",
      "Epoch: 7, step: 26/300, Loss: 0.01087\n",
      "Epoch: 7, step: 27/300, Loss: 0.00656\n",
      "Epoch: 7, step: 28/300, Loss: 0.03214\n",
      "Epoch: 7, step: 29/300, Loss: 0.01221\n",
      "Epoch: 7, step: 30/300, Loss: 0.11064\n",
      "Epoch: 7, step: 31/300, Loss: 0.89850\n",
      "Epoch: 7, step: 32/300, Loss: 0.02357\n",
      "Epoch: 7, step: 33/300, Loss: 0.07133\n",
      "Epoch: 7, step: 34/300, Loss: 0.19702\n",
      "Epoch: 7, step: 35/300, Loss: 0.00647\n",
      "Epoch: 7, step: 36/300, Loss: 0.06921\n",
      "Epoch: 7, step: 37/300, Loss: 1.07397\n",
      "Epoch: 7, step: 38/300, Loss: 0.00200\n",
      "Epoch: 7, step: 39/300, Loss: 0.04653\n",
      "Epoch: 7, step: 40/300, Loss: 0.00584\n",
      "Epoch: 7, step: 41/300, Loss: 0.03105\n",
      "Epoch: 7, step: 42/300, Loss: 0.01200\n",
      "Epoch: 7, step: 43/300, Loss: 0.01823\n",
      "Epoch: 7, step: 44/300, Loss: 0.01433\n",
      "Epoch: 7, step: 45/300, Loss: 0.06325\n",
      "Epoch: 7, step: 46/300, Loss: 0.02615\n",
      "Epoch: 7, step: 47/300, Loss: 0.08999\n",
      "Epoch: 7, step: 48/300, Loss: 0.01636\n",
      "Epoch: 7, step: 49/300, Loss: 0.05581\n",
      "Epoch: 7, step: 50/300, Loss: 0.04960\n",
      "Epoch: 7, step: 51/300, Loss: 0.23209\n",
      "Epoch: 7, step: 52/300, Loss: 0.37756\n",
      "Epoch: 7, step: 53/300, Loss: 0.02644\n",
      "Epoch: 7, step: 54/300, Loss: 0.00874\n",
      "Epoch: 7, step: 55/300, Loss: 0.01126\n",
      "Epoch: 7, step: 56/300, Loss: 0.11471\n",
      "Epoch: 7, step: 57/300, Loss: 0.00971\n",
      "Epoch: 7, step: 58/300, Loss: 0.00640\n",
      "Epoch: 7, step: 59/300, Loss: 0.00933\n",
      "Epoch: 7, step: 60/300, Loss: 0.00692\n",
      "Epoch: 7, step: 61/300, Loss: 0.01352\n",
      "Epoch: 7, step: 62/300, Loss: 0.02745\n",
      "Epoch: 7, step: 63/300, Loss: 0.00556\n",
      "Epoch: 7, step: 64/300, Loss: 0.01583\n",
      "Epoch: 7, step: 65/300, Loss: 0.01029\n",
      "Epoch: 7, step: 66/300, Loss: 0.01110\n",
      "Epoch: 7, step: 67/300, Loss: 0.01236\n",
      "Epoch: 7, step: 68/300, Loss: 0.03390\n",
      "Epoch: 7, step: 69/300, Loss: 0.02137\n",
      "Epoch: 7, step: 70/300, Loss: 0.00395\n",
      "Epoch: 7, step: 71/300, Loss: 0.01179\n",
      "Epoch: 7, step: 72/300, Loss: 0.00821\n",
      "Epoch: 7, step: 73/300, Loss: 0.00711\n",
      "Epoch: 7, step: 74/300, Loss: 0.02155\n",
      "Epoch: 7, step: 75/300, Loss: 0.01417\n",
      "Epoch: 7, step: 76/300, Loss: 0.00995\n",
      "Epoch: 7, step: 77/300, Loss: 0.00959\n",
      "Epoch: 7, step: 78/300, Loss: 0.13709\n",
      "Epoch: 7, step: 79/300, Loss: 0.33123\n",
      "Epoch: 7, step: 80/300, Loss: 0.05700\n",
      "Epoch: 7, step: 81/300, Loss: 0.02394\n",
      "Epoch: 7, step: 82/300, Loss: 0.02409\n",
      "Epoch: 7, step: 83/300, Loss: 0.01329\n",
      "Epoch: 7, step: 84/300, Loss: 0.02247\n",
      "Epoch: 7, step: 85/300, Loss: 0.05806\n",
      "Epoch: 7, step: 86/300, Loss: 0.00377\n",
      "Epoch: 7, step: 87/300, Loss: 0.02082\n",
      "Epoch: 7, step: 88/300, Loss: 0.04855\n",
      "Epoch: 7, step: 89/300, Loss: 0.00560\n",
      "Epoch: 7, step: 90/300, Loss: 0.03585\n",
      "Epoch: 7, step: 91/300, Loss: 0.00470\n",
      "Epoch: 7, step: 92/300, Loss: 0.03563\n",
      "Epoch: 7, step: 93/300, Loss: 0.00581\n",
      "Epoch: 7, step: 94/300, Loss: 0.17939\n",
      "Epoch: 7, step: 95/300, Loss: 0.08026\n",
      "Epoch: 7, step: 96/300, Loss: 0.00582\n",
      "Epoch: 7, step: 97/300, Loss: 0.01930\n",
      "Epoch: 7, step: 98/300, Loss: 0.01999\n",
      "Epoch: 7, step: 99/300, Loss: 0.01906\n",
      "Epoch: 7, step: 100/300, Loss: 0.03296\n",
      "Epoch: 7, step: 101/300, Loss: 0.00871\n",
      "Epoch: 7, step: 102/300, Loss: 0.01686\n",
      "Epoch: 7, step: 103/300, Loss: 0.00196\n",
      "Epoch: 7, step: 104/300, Loss: 0.01226\n",
      "Epoch: 7, step: 105/300, Loss: 0.03122\n",
      "Epoch: 7, step: 106/300, Loss: 0.01896\n",
      "Epoch: 7, step: 107/300, Loss: 0.00249\n",
      "Epoch: 7, step: 108/300, Loss: 0.00372\n",
      "Epoch: 7, step: 109/300, Loss: 0.00286\n",
      "Epoch: 7, step: 110/300, Loss: 0.00353\n",
      "Epoch: 7, step: 111/300, Loss: 0.00561\n",
      "Epoch: 7, step: 112/300, Loss: 0.00662\n",
      "Epoch: 7, step: 113/300, Loss: 0.01744\n",
      "Epoch: 7, step: 114/300, Loss: 0.02970\n",
      "Epoch: 7, step: 115/300, Loss: 0.00258\n",
      "Epoch: 7, step: 116/300, Loss: 0.02603\n",
      "Epoch: 7, step: 117/300, Loss: 0.00331\n",
      "Epoch: 7, step: 118/300, Loss: 0.03871\n",
      "Epoch: 7, step: 119/300, Loss: 0.01715\n",
      "Epoch: 7, step: 120/300, Loss: 1.52829\n",
      "Epoch: 7, step: 121/300, Loss: 0.00830\n",
      "Epoch: 7, step: 122/300, Loss: 0.34028\n",
      "Epoch: 7, step: 123/300, Loss: 0.00306\n",
      "Epoch: 7, step: 124/300, Loss: 0.02136\n",
      "Epoch: 7, step: 125/300, Loss: 0.01623\n",
      "Epoch: 7, step: 126/300, Loss: 0.78318\n",
      "Epoch: 7, step: 127/300, Loss: 0.01038\n",
      "Epoch: 7, step: 128/300, Loss: 0.00290\n",
      "Epoch: 7, step: 129/300, Loss: 0.00508\n",
      "Epoch: 7, step: 130/300, Loss: 0.11569\n",
      "Epoch: 7, step: 131/300, Loss: 0.00515\n",
      "Epoch: 7, step: 132/300, Loss: 0.00975\n",
      "Epoch: 7, step: 133/300, Loss: 0.01226\n",
      "Epoch: 7, step: 134/300, Loss: 0.00651\n",
      "Epoch: 7, step: 135/300, Loss: 0.00541\n",
      "Epoch: 7, step: 136/300, Loss: 0.15261\n",
      "Epoch: 7, step: 137/300, Loss: 0.00361\n",
      "Epoch: 7, step: 138/300, Loss: 0.96245\n",
      "Epoch: 7, step: 139/300, Loss: 0.01171\n",
      "Epoch: 7, step: 140/300, Loss: 3.58545\n",
      "Epoch: 7, step: 141/300, Loss: 0.00482\n",
      "Epoch: 7, step: 142/300, Loss: 0.01009\n",
      "Epoch: 7, step: 143/300, Loss: 0.00436\n",
      "Epoch: 7, step: 144/300, Loss: 0.00255\n",
      "Epoch: 7, step: 145/300, Loss: 0.06587\n",
      "Epoch: 7, step: 146/300, Loss: 2.10371\n",
      "Epoch: 7, step: 147/300, Loss: 0.00292\n",
      "Epoch: 7, step: 148/300, Loss: 0.41738\n",
      "Epoch: 7, step: 149/300, Loss: 1.83193\n",
      "Epoch: 7, step: 150/300, Loss: 0.02945\n",
      "Epoch: 7, step: 151/300, Loss: 2.07296\n",
      "Epoch: 7, step: 152/300, Loss: 0.00993\n",
      "Epoch: 7, step: 153/300, Loss: 0.00640\n",
      "Epoch: 7, step: 154/300, Loss: 0.05331\n",
      "Epoch: 7, step: 155/300, Loss: 0.01165\n",
      "Epoch: 7, step: 156/300, Loss: 0.20179\n",
      "Epoch: 7, step: 157/300, Loss: 0.04489\n",
      "Epoch: 7, step: 158/300, Loss: 0.03109\n",
      "Epoch: 7, step: 159/300, Loss: 0.02859\n",
      "Epoch: 7, step: 160/300, Loss: 0.02093\n",
      "Epoch: 7, step: 161/300, Loss: 0.01727\n",
      "Epoch: 7, step: 162/300, Loss: 0.28823\n",
      "Epoch: 7, step: 163/300, Loss: 0.01142\n",
      "Epoch: 7, step: 164/300, Loss: 0.02889\n",
      "Epoch: 7, step: 165/300, Loss: 0.10724\n",
      "Epoch: 7, step: 166/300, Loss: 1.71981\n",
      "Epoch: 7, step: 167/300, Loss: 0.27197\n",
      "Epoch: 7, step: 168/300, Loss: 0.01495\n",
      "Epoch: 7, step: 169/300, Loss: 0.06312\n",
      "Epoch: 7, step: 170/300, Loss: 0.02187\n",
      "Epoch: 7, step: 171/300, Loss: 0.02689\n",
      "Epoch: 7, step: 172/300, Loss: 0.42764\n",
      "Epoch: 7, step: 173/300, Loss: 0.13279\n",
      "Epoch: 7, step: 174/300, Loss: 0.01885\n",
      "Epoch: 7, step: 175/300, Loss: 0.01561\n",
      "Epoch: 7, step: 176/300, Loss: 0.00836\n",
      "Epoch: 7, step: 177/300, Loss: 0.09362\n",
      "Epoch: 7, step: 178/300, Loss: 0.08599\n",
      "Epoch: 7, step: 179/300, Loss: 0.07561\n",
      "Epoch: 7, step: 180/300, Loss: 0.02855\n",
      "Epoch: 7, step: 181/300, Loss: 0.00377\n",
      "Epoch: 7, step: 182/300, Loss: 0.04281\n",
      "Epoch: 7, step: 183/300, Loss: 0.04382\n",
      "Epoch: 7, step: 184/300, Loss: 0.01488\n",
      "Epoch: 7, step: 185/300, Loss: 0.06253\n",
      "Epoch: 7, step: 186/300, Loss: 0.04519\n",
      "Epoch: 7, step: 187/300, Loss: 0.05814\n",
      "Epoch: 7, step: 188/300, Loss: 0.05327\n",
      "Epoch: 7, step: 189/300, Loss: 0.00401\n",
      "Epoch: 7, step: 190/300, Loss: 0.11375\n",
      "Epoch: 7, step: 191/300, Loss: 0.00367\n",
      "Epoch: 7, step: 192/300, Loss: 0.05952\n",
      "Epoch: 7, step: 193/300, Loss: 0.00410\n",
      "Epoch: 7, step: 194/300, Loss: 0.09642\n",
      "Epoch: 7, step: 195/300, Loss: 0.23727\n",
      "Epoch: 7, step: 196/300, Loss: 0.06974\n",
      "Epoch: 7, step: 197/300, Loss: 0.16345\n",
      "Epoch: 7, step: 198/300, Loss: 0.00660\n",
      "Epoch: 7, step: 199/300, Loss: 0.01454\n",
      "Epoch: 7, step: 200/300, Loss: 0.01607\n",
      "Epoch: 7, step: 201/300, Loss: 0.03431\n",
      "Epoch: 7, step: 202/300, Loss: 0.01342\n",
      "Epoch: 7, step: 203/300, Loss: 0.01283\n",
      "Epoch: 7, step: 204/300, Loss: 0.00415\n",
      "Epoch: 7, step: 205/300, Loss: 0.06842\n",
      "Epoch: 7, step: 206/300, Loss: 0.02042\n",
      "Epoch: 7, step: 207/300, Loss: 0.01189\n",
      "Epoch: 7, step: 208/300, Loss: 0.01286\n",
      "Epoch: 7, step: 209/300, Loss: 0.04878\n",
      "Epoch: 7, step: 210/300, Loss: 0.01086\n",
      "Epoch: 7, step: 211/300, Loss: 0.06985\n",
      "Epoch: 7, step: 212/300, Loss: 0.02723\n",
      "Epoch: 7, step: 213/300, Loss: 0.03793\n",
      "Epoch: 7, step: 214/300, Loss: 0.01990\n",
      "Epoch: 7, step: 215/300, Loss: 0.17268\n",
      "Epoch: 7, step: 216/300, Loss: 0.00534\n",
      "Epoch: 7, step: 217/300, Loss: 1.20249\n",
      "Epoch: 7, step: 218/300, Loss: 0.00842\n",
      "Epoch: 7, step: 219/300, Loss: 0.00652\n",
      "Epoch: 7, step: 220/300, Loss: 0.01932\n",
      "Epoch: 7, step: 221/300, Loss: 0.03530\n",
      "Epoch: 7, step: 222/300, Loss: 0.01916\n",
      "Epoch: 7, step: 223/300, Loss: 0.00512\n",
      "Epoch: 7, step: 224/300, Loss: 0.00532\n",
      "Epoch: 7, step: 225/300, Loss: 0.04220\n",
      "Epoch: 7, step: 226/300, Loss: 0.05310\n",
      "Epoch: 7, step: 227/300, Loss: 0.19357\n",
      "Epoch: 7, step: 228/300, Loss: 0.00614\n",
      "Epoch: 7, step: 229/300, Loss: 0.06531\n",
      "Epoch: 7, step: 230/300, Loss: 0.01874\n",
      "Epoch: 7, step: 231/300, Loss: 1.21871\n",
      "Epoch: 7, step: 232/300, Loss: 0.01743\n",
      "Epoch: 7, step: 233/300, Loss: 0.65674\n",
      "Epoch: 7, step: 234/300, Loss: 0.06805\n",
      "Epoch: 7, step: 235/300, Loss: 0.18353\n",
      "Epoch: 7, step: 236/300, Loss: 0.01064\n",
      "Epoch: 7, step: 237/300, Loss: 0.07310\n",
      "Epoch: 7, step: 238/300, Loss: 0.81644\n",
      "Epoch: 7, step: 239/300, Loss: 0.03690\n",
      "Epoch: 7, step: 240/300, Loss: 0.12103\n",
      "Epoch: 7, step: 241/300, Loss: 0.27484\n",
      "Epoch: 7, step: 242/300, Loss: 0.00371\n",
      "Epoch: 7, step: 243/300, Loss: 0.01575\n",
      "Epoch: 7, step: 244/300, Loss: 0.05556\n",
      "Epoch: 7, step: 245/300, Loss: 0.15215\n",
      "Epoch: 7, step: 246/300, Loss: 0.03312\n",
      "Epoch: 7, step: 247/300, Loss: 0.01945\n",
      "Epoch: 7, step: 248/300, Loss: 0.01864\n",
      "Epoch: 7, step: 249/300, Loss: 0.09250\n",
      "Epoch: 7, step: 250/300, Loss: 0.03255\n",
      "Epoch: 7, step: 251/300, Loss: 0.02261\n",
      "Epoch: 7, step: 252/300, Loss: 0.00824\n",
      "Epoch: 7, step: 253/300, Loss: 0.23334\n",
      "Epoch: 7, step: 254/300, Loss: 0.01906\n",
      "Epoch: 7, step: 255/300, Loss: 0.00951\n",
      "Epoch: 7, step: 256/300, Loss: 0.03820\n",
      "Epoch: 7, step: 257/300, Loss: 0.01548\n",
      "Epoch: 7, step: 258/300, Loss: 0.01251\n",
      "Epoch: 7, step: 259/300, Loss: 0.02003\n",
      "Epoch: 7, step: 260/300, Loss: 0.32556\n",
      "Epoch: 7, step: 261/300, Loss: 0.05775\n",
      "Epoch: 7, step: 262/300, Loss: 0.09428\n",
      "Epoch: 7, step: 263/300, Loss: 0.02198\n",
      "Epoch: 7, step: 264/300, Loss: 0.00338\n",
      "Epoch: 7, step: 265/300, Loss: 0.00634\n",
      "Epoch: 7, step: 266/300, Loss: 0.16100\n",
      "Epoch: 7, step: 267/300, Loss: 0.09873\n",
      "Epoch: 7, step: 268/300, Loss: 0.00848\n",
      "Epoch: 7, step: 269/300, Loss: 0.00471\n",
      "Epoch: 7, step: 270/300, Loss: 0.00778\n",
      "Epoch: 7, step: 271/300, Loss: 0.03623\n",
      "Epoch: 7, step: 272/300, Loss: 0.64742\n",
      "Epoch: 7, step: 273/300, Loss: 0.02675\n",
      "Epoch: 7, step: 274/300, Loss: 0.00651\n",
      "Epoch: 7, step: 275/300, Loss: 0.02210\n",
      "Epoch: 7, step: 276/300, Loss: 0.03833\n",
      "Epoch: 7, step: 277/300, Loss: 0.00468\n",
      "Epoch: 7, step: 278/300, Loss: 0.01223\n",
      "Epoch: 7, step: 279/300, Loss: 0.03577\n",
      "Epoch: 7, step: 280/300, Loss: 1.36968\n",
      "Epoch: 7, step: 281/300, Loss: 0.01978\n",
      "Epoch: 7, step: 282/300, Loss: 0.00631\n",
      "Epoch: 7, step: 283/300, Loss: 0.03131\n",
      "Epoch: 7, step: 284/300, Loss: 0.13604\n",
      "Epoch: 7, step: 285/300, Loss: 0.00175\n",
      "Epoch: 7, step: 286/300, Loss: 0.00306\n",
      "Epoch: 7, step: 287/300, Loss: 0.04042\n",
      "Epoch: 7, step: 288/300, Loss: 0.00283\n",
      "Epoch: 7, step: 289/300, Loss: 0.01545\n",
      "Epoch: 7, step: 290/300, Loss: 0.12844\n",
      "Epoch: 7, step: 291/300, Loss: 0.00141\n",
      "Epoch: 7, step: 292/300, Loss: 0.03091\n",
      "Epoch: 7, step: 293/300, Loss: 0.05293\n",
      "Epoch: 7, step: 294/300, Loss: 0.03331\n",
      "Epoch: 7, step: 295/300, Loss: 0.12692\n",
      "Epoch: 7, step: 296/300, Loss: 0.00775\n",
      "Epoch: 7, step: 297/300, Loss: 0.00181\n",
      "Epoch: 7, step: 298/300, Loss: 0.00435\n",
      "Epoch: 7, step: 299/300, Loss: 0.01698\n",
      "Epoch: 8, step: 0/300, Loss: 0.52172\n",
      "Epoch: 8, step: 1/300, Loss: 0.04011\n",
      "Epoch: 8, step: 2/300, Loss: 0.20030\n",
      "Epoch: 8, step: 3/300, Loss: 0.00737\n",
      "Epoch: 8, step: 4/300, Loss: 0.01573\n",
      "Epoch: 8, step: 5/300, Loss: 0.01255\n",
      "Epoch: 8, step: 6/300, Loss: 0.07611\n",
      "Epoch: 8, step: 7/300, Loss: 0.22390\n",
      "Epoch: 8, step: 8/300, Loss: 0.01723\n",
      "Epoch: 8, step: 9/300, Loss: 0.04101\n",
      "Epoch: 8, step: 10/300, Loss: 0.00274\n",
      "Epoch: 8, step: 11/300, Loss: 0.08391\n",
      "Epoch: 8, step: 12/300, Loss: 0.00409\n",
      "Epoch: 8, step: 13/300, Loss: 0.00175\n",
      "Epoch: 8, step: 14/300, Loss: 0.00585\n",
      "Epoch: 8, step: 15/300, Loss: 0.01689\n",
      "Epoch: 8, step: 16/300, Loss: 0.05574\n",
      "Epoch: 8, step: 17/300, Loss: 0.06072\n",
      "Epoch: 8, step: 18/300, Loss: 0.00689\n",
      "Epoch: 8, step: 19/300, Loss: 0.30610\n",
      "Epoch: 8, step: 20/300, Loss: 0.06773\n",
      "Epoch: 8, step: 21/300, Loss: 0.00656\n",
      "Epoch: 8, step: 22/300, Loss: 0.01250\n",
      "Epoch: 8, step: 23/300, Loss: 0.00813\n",
      "Epoch: 8, step: 24/300, Loss: 0.00802\n",
      "Epoch: 8, step: 25/300, Loss: 0.00715\n",
      "Epoch: 8, step: 26/300, Loss: 0.01810\n",
      "Epoch: 8, step: 27/300, Loss: 0.00459\n",
      "Epoch: 8, step: 28/300, Loss: 0.00359\n",
      "Epoch: 8, step: 29/300, Loss: 0.00168\n",
      "Epoch: 8, step: 30/300, Loss: 0.01426\n",
      "Epoch: 8, step: 31/300, Loss: 0.01819\n",
      "Epoch: 8, step: 32/300, Loss: 0.00916\n",
      "Epoch: 8, step: 33/300, Loss: 0.00619\n",
      "Epoch: 8, step: 34/300, Loss: 0.08916\n",
      "Epoch: 8, step: 35/300, Loss: 0.02372\n",
      "Epoch: 8, step: 36/300, Loss: 0.00500\n",
      "Epoch: 8, step: 37/300, Loss: 0.00768\n",
      "Epoch: 8, step: 38/300, Loss: 0.01174\n",
      "Epoch: 8, step: 39/300, Loss: 0.00811\n",
      "Epoch: 8, step: 40/300, Loss: 0.00865\n",
      "Epoch: 8, step: 41/300, Loss: 0.00681\n",
      "Epoch: 8, step: 42/300, Loss: 0.00819\n",
      "Epoch: 8, step: 43/300, Loss: 0.00854\n",
      "Epoch: 8, step: 44/300, Loss: 0.13340\n",
      "Epoch: 8, step: 45/300, Loss: 0.00196\n",
      "Epoch: 8, step: 46/300, Loss: 0.00591\n",
      "Epoch: 8, step: 47/300, Loss: 0.00624\n",
      "Epoch: 8, step: 48/300, Loss: 0.00364\n",
      "Epoch: 8, step: 49/300, Loss: 0.00266\n",
      "Epoch: 8, step: 50/300, Loss: 0.01071\n",
      "Epoch: 8, step: 51/300, Loss: 0.02616\n",
      "Epoch: 8, step: 52/300, Loss: 0.02550\n",
      "Epoch: 8, step: 53/300, Loss: 0.03849\n",
      "Epoch: 8, step: 54/300, Loss: 0.00869\n",
      "Epoch: 8, step: 55/300, Loss: 0.00685\n",
      "Epoch: 8, step: 56/300, Loss: 0.00333\n",
      "Epoch: 8, step: 57/300, Loss: 0.01467\n",
      "Epoch: 8, step: 58/300, Loss: 0.01547\n",
      "Epoch: 8, step: 59/300, Loss: 0.00399\n",
      "Epoch: 8, step: 60/300, Loss: 0.00719\n",
      "Epoch: 8, step: 61/300, Loss: 0.00687\n",
      "Epoch: 8, step: 62/300, Loss: 0.01070\n",
      "Epoch: 8, step: 63/300, Loss: 0.08247\n",
      "Epoch: 8, step: 64/300, Loss: 0.12496\n",
      "Epoch: 8, step: 65/300, Loss: 0.00331\n",
      "Epoch: 8, step: 66/300, Loss: 0.00975\n",
      "Epoch: 8, step: 67/300, Loss: 0.01284\n",
      "Epoch: 8, step: 68/300, Loss: 0.02417\n",
      "Epoch: 8, step: 69/300, Loss: 0.01551\n",
      "Epoch: 8, step: 70/300, Loss: 0.03257\n",
      "Epoch: 8, step: 71/300, Loss: 0.00381\n",
      "Epoch: 8, step: 72/300, Loss: 0.00690\n",
      "Epoch: 8, step: 73/300, Loss: 0.00565\n",
      "Epoch: 8, step: 74/300, Loss: 0.01233\n",
      "Epoch: 8, step: 75/300, Loss: 0.01092\n",
      "Epoch: 8, step: 76/300, Loss: 0.11609\n",
      "Epoch: 8, step: 77/300, Loss: 0.02727\n",
      "Epoch: 8, step: 78/300, Loss: 0.03257\n",
      "Epoch: 8, step: 79/300, Loss: 0.00857\n",
      "Epoch: 8, step: 80/300, Loss: 0.01091\n",
      "Epoch: 8, step: 81/300, Loss: 0.01241\n",
      "Epoch: 8, step: 82/300, Loss: 0.00653\n",
      "Epoch: 8, step: 83/300, Loss: 0.12205\n",
      "Epoch: 8, step: 84/300, Loss: 0.01320\n",
      "Epoch: 8, step: 85/300, Loss: 0.00194\n",
      "Epoch: 8, step: 86/300, Loss: 0.00310\n",
      "Epoch: 8, step: 87/300, Loss: 0.00521\n",
      "Epoch: 8, step: 88/300, Loss: 0.01101\n",
      "Epoch: 8, step: 89/300, Loss: 0.00890\n",
      "Epoch: 8, step: 90/300, Loss: 0.02278\n",
      "Epoch: 8, step: 91/300, Loss: 0.00767\n",
      "Epoch: 8, step: 92/300, Loss: 0.01040\n",
      "Epoch: 8, step: 93/300, Loss: 0.00882\n",
      "Epoch: 8, step: 94/300, Loss: 0.02083\n",
      "Epoch: 8, step: 95/300, Loss: 0.00964\n",
      "Epoch: 8, step: 96/300, Loss: 0.05296\n",
      "Epoch: 8, step: 97/300, Loss: 0.00150\n",
      "Epoch: 8, step: 98/300, Loss: 0.04139\n",
      "Epoch: 8, step: 99/300, Loss: 0.01672\n",
      "Epoch: 8, step: 100/300, Loss: 0.01723\n",
      "Epoch: 8, step: 101/300, Loss: 0.00281\n",
      "Epoch: 8, step: 102/300, Loss: 0.00297\n",
      "Epoch: 8, step: 103/300, Loss: 0.00457\n",
      "Epoch: 8, step: 104/300, Loss: 0.00161\n",
      "Epoch: 8, step: 105/300, Loss: 0.01259\n",
      "Epoch: 8, step: 106/300, Loss: 0.00158\n",
      "Epoch: 8, step: 107/300, Loss: 0.00248\n",
      "Epoch: 8, step: 108/300, Loss: 0.00604\n",
      "Epoch: 8, step: 109/300, Loss: 0.01658\n",
      "Epoch: 8, step: 110/300, Loss: 0.00376\n",
      "Epoch: 8, step: 111/300, Loss: 0.00312\n",
      "Epoch: 8, step: 112/300, Loss: 0.00258\n",
      "Epoch: 8, step: 113/300, Loss: 0.01282\n",
      "Epoch: 8, step: 114/300, Loss: 0.08264\n",
      "Epoch: 8, step: 115/300, Loss: 0.00204\n",
      "Epoch: 8, step: 116/300, Loss: 0.01286\n",
      "Epoch: 8, step: 117/300, Loss: 0.00401\n",
      "Epoch: 8, step: 118/300, Loss: 0.00258\n",
      "Epoch: 8, step: 119/300, Loss: 0.00521\n",
      "Epoch: 8, step: 120/300, Loss: 0.00782\n",
      "Epoch: 8, step: 121/300, Loss: 0.23266\n",
      "Epoch: 8, step: 122/300, Loss: 0.03121\n",
      "Epoch: 8, step: 123/300, Loss: 0.00670\n",
      "Epoch: 8, step: 124/300, Loss: 0.01880\n",
      "Epoch: 8, step: 125/300, Loss: 0.00916\n",
      "Epoch: 8, step: 126/300, Loss: 0.01216\n",
      "Epoch: 8, step: 127/300, Loss: 0.00189\n",
      "Epoch: 8, step: 128/300, Loss: 0.00144\n",
      "Epoch: 8, step: 129/300, Loss: 0.03708\n",
      "Epoch: 8, step: 130/300, Loss: 0.00595\n",
      "Epoch: 8, step: 131/300, Loss: 0.19803\n",
      "Epoch: 8, step: 132/300, Loss: 0.00633\n",
      "Epoch: 8, step: 133/300, Loss: 0.15805\n",
      "Epoch: 8, step: 134/300, Loss: 0.00242\n",
      "Epoch: 8, step: 135/300, Loss: 0.00650\n",
      "Epoch: 8, step: 136/300, Loss: 0.01961\n",
      "Epoch: 8, step: 137/300, Loss: 0.04710\n",
      "Epoch: 8, step: 138/300, Loss: 0.04110\n",
      "Epoch: 8, step: 139/300, Loss: 0.01224\n",
      "Epoch: 8, step: 140/300, Loss: 0.00144\n",
      "Epoch: 8, step: 141/300, Loss: 0.00365\n",
      "Epoch: 8, step: 142/300, Loss: 0.01214\n",
      "Epoch: 8, step: 143/300, Loss: 0.05276\n",
      "Epoch: 8, step: 144/300, Loss: 0.00292\n",
      "Epoch: 8, step: 145/300, Loss: 0.02857\n",
      "Epoch: 8, step: 146/300, Loss: 0.00306\n",
      "Epoch: 8, step: 147/300, Loss: 0.01596\n",
      "Epoch: 8, step: 148/300, Loss: 0.00468\n",
      "Epoch: 8, step: 149/300, Loss: 0.00782\n",
      "Epoch: 8, step: 150/300, Loss: 0.01652\n",
      "Epoch: 8, step: 151/300, Loss: 0.00683\n",
      "Epoch: 8, step: 152/300, Loss: 0.00875\n",
      "Epoch: 8, step: 153/300, Loss: 0.02388\n",
      "Epoch: 8, step: 154/300, Loss: 0.00923\n",
      "Epoch: 8, step: 155/300, Loss: 0.01819\n",
      "Epoch: 8, step: 156/300, Loss: 0.00319\n",
      "Epoch: 8, step: 157/300, Loss: 0.30346\n",
      "Epoch: 8, step: 158/300, Loss: 0.00182\n",
      "Epoch: 8, step: 159/300, Loss: 0.02526\n",
      "Epoch: 8, step: 160/300, Loss: 0.00109\n",
      "Epoch: 8, step: 161/300, Loss: 0.00106\n",
      "Epoch: 8, step: 162/300, Loss: 0.00364\n",
      "Epoch: 8, step: 163/300, Loss: 0.00614\n",
      "Epoch: 8, step: 164/300, Loss: 0.00717\n",
      "Epoch: 8, step: 165/300, Loss: 0.21074\n",
      "Epoch: 8, step: 166/300, Loss: 0.02258\n",
      "Epoch: 8, step: 167/300, Loss: 0.00376\n",
      "Epoch: 8, step: 168/300, Loss: 0.00736\n",
      "Epoch: 8, step: 169/300, Loss: 0.29847\n",
      "Epoch: 8, step: 170/300, Loss: 0.00872\n",
      "Epoch: 8, step: 171/300, Loss: 0.00785\n",
      "Epoch: 8, step: 172/300, Loss: 0.02455\n",
      "Epoch: 8, step: 173/300, Loss: 0.00522\n",
      "Epoch: 8, step: 174/300, Loss: 0.01157\n",
      "Epoch: 8, step: 175/300, Loss: 0.07678\n",
      "Epoch: 8, step: 176/300, Loss: 0.01057\n",
      "Epoch: 8, step: 177/300, Loss: 0.00599\n",
      "Epoch: 8, step: 178/300, Loss: 0.01118\n",
      "Epoch: 8, step: 179/300, Loss: 0.00237\n",
      "Epoch: 8, step: 180/300, Loss: 0.00479\n",
      "Epoch: 8, step: 181/300, Loss: 0.00192\n",
      "Epoch: 8, step: 182/300, Loss: 0.00140\n",
      "Epoch: 8, step: 183/300, Loss: 0.05346\n",
      "Epoch: 8, step: 184/300, Loss: 0.01829\n",
      "Epoch: 8, step: 185/300, Loss: 0.02632\n",
      "Epoch: 8, step: 186/300, Loss: 0.00565\n",
      "Epoch: 8, step: 187/300, Loss: 0.01212\n",
      "Epoch: 8, step: 188/300, Loss: 0.07816\n",
      "Epoch: 8, step: 189/300, Loss: 0.00236\n",
      "Epoch: 8, step: 190/300, Loss: 0.00142\n",
      "Epoch: 8, step: 191/300, Loss: 0.00489\n",
      "Epoch: 8, step: 192/300, Loss: 0.00610\n",
      "Epoch: 8, step: 193/300, Loss: 0.00427\n",
      "Epoch: 8, step: 194/300, Loss: 0.00153\n",
      "Epoch: 8, step: 195/300, Loss: 0.07452\n",
      "Epoch: 8, step: 196/300, Loss: 0.01879\n",
      "Epoch: 8, step: 197/300, Loss: 0.01001\n",
      "Epoch: 8, step: 198/300, Loss: 0.00409\n",
      "Epoch: 8, step: 199/300, Loss: 0.00199\n",
      "Epoch: 8, step: 200/300, Loss: 0.00412\n",
      "Epoch: 8, step: 201/300, Loss: 0.00647\n",
      "Epoch: 8, step: 202/300, Loss: 0.00910\n",
      "Epoch: 8, step: 203/300, Loss: 0.02986\n",
      "Epoch: 8, step: 204/300, Loss: 0.04355\n",
      "Epoch: 8, step: 205/300, Loss: 0.00349\n",
      "Epoch: 8, step: 206/300, Loss: 0.00694\n",
      "Epoch: 8, step: 207/300, Loss: 0.00164\n",
      "Epoch: 8, step: 208/300, Loss: 0.01169\n",
      "Epoch: 8, step: 209/300, Loss: 0.00436\n",
      "Epoch: 8, step: 210/300, Loss: 0.00364\n",
      "Epoch: 8, step: 211/300, Loss: 0.00610\n",
      "Epoch: 8, step: 212/300, Loss: 0.05051\n",
      "Epoch: 8, step: 213/300, Loss: 0.00681\n",
      "Epoch: 8, step: 214/300, Loss: 0.00317\n",
      "Epoch: 8, step: 215/300, Loss: 0.00127\n",
      "Epoch: 8, step: 216/300, Loss: 0.00454\n",
      "Epoch: 8, step: 217/300, Loss: 0.42061\n",
      "Epoch: 8, step: 218/300, Loss: 0.28325\n",
      "Epoch: 8, step: 219/300, Loss: 0.11769\n",
      "Epoch: 8, step: 220/300, Loss: 0.01122\n",
      "Epoch: 8, step: 221/300, Loss: 0.00700\n",
      "Epoch: 8, step: 222/300, Loss: 0.00210\n",
      "Epoch: 8, step: 223/300, Loss: 0.00410\n",
      "Epoch: 8, step: 224/300, Loss: 0.00377\n",
      "Epoch: 8, step: 225/300, Loss: 0.00992\n",
      "Epoch: 8, step: 226/300, Loss: 0.00546\n",
      "Epoch: 8, step: 227/300, Loss: 0.74561\n",
      "Epoch: 8, step: 228/300, Loss: 0.00757\n",
      "Epoch: 8, step: 229/300, Loss: 1.38984\n",
      "Epoch: 8, step: 230/300, Loss: 0.01040\n",
      "Epoch: 8, step: 231/300, Loss: 0.00565\n",
      "Epoch: 8, step: 232/300, Loss: 0.00176\n",
      "Epoch: 8, step: 233/300, Loss: 0.06550\n",
      "Epoch: 8, step: 234/300, Loss: 0.07974\n",
      "Epoch: 8, step: 235/300, Loss: 0.00296\n",
      "Epoch: 8, step: 236/300, Loss: 0.04640\n",
      "Epoch: 8, step: 237/300, Loss: 0.00244\n",
      "Epoch: 8, step: 238/300, Loss: 0.00983\n",
      "Epoch: 8, step: 239/300, Loss: 0.00779\n",
      "Epoch: 8, step: 240/300, Loss: 0.01564\n",
      "Epoch: 8, step: 241/300, Loss: 0.13885\n",
      "Epoch: 8, step: 242/300, Loss: 3.40452\n",
      "Epoch: 8, step: 243/300, Loss: 2.70307\n",
      "Epoch: 8, step: 244/300, Loss: 0.00244\n",
      "Epoch: 8, step: 245/300, Loss: 0.00544\n",
      "Epoch: 8, step: 246/300, Loss: 0.00543\n",
      "Epoch: 8, step: 247/300, Loss: 0.01225\n",
      "Epoch: 8, step: 248/300, Loss: 0.01376\n",
      "Epoch: 8, step: 249/300, Loss: 0.01691\n",
      "Epoch: 8, step: 250/300, Loss: 0.00958\n",
      "Epoch: 8, step: 251/300, Loss: 0.00827\n",
      "Epoch: 8, step: 252/300, Loss: 0.00690\n",
      "Epoch: 8, step: 253/300, Loss: 0.00347\n",
      "Epoch: 8, step: 254/300, Loss: 0.01000\n",
      "Epoch: 8, step: 255/300, Loss: 0.73865\n",
      "Epoch: 8, step: 256/300, Loss: 0.07571\n",
      "Epoch: 8, step: 257/300, Loss: 0.94116\n",
      "Epoch: 8, step: 258/300, Loss: 0.01331\n",
      "Epoch: 8, step: 259/300, Loss: 0.00489\n",
      "Epoch: 8, step: 260/300, Loss: 0.01402\n",
      "Epoch: 8, step: 261/300, Loss: 0.18694\n",
      "Epoch: 8, step: 262/300, Loss: 0.05813\n",
      "Epoch: 8, step: 263/300, Loss: 0.46304\n",
      "Epoch: 8, step: 264/300, Loss: 0.12151\n",
      "Epoch: 8, step: 265/300, Loss: 0.01043\n",
      "Epoch: 8, step: 266/300, Loss: 0.45341\n",
      "Epoch: 8, step: 267/300, Loss: 0.03293\n",
      "Epoch: 8, step: 268/300, Loss: 0.00806\n",
      "Epoch: 8, step: 269/300, Loss: 0.03507\n",
      "Epoch: 8, step: 270/300, Loss: 0.00600\n",
      "Epoch: 8, step: 271/300, Loss: 0.00440\n",
      "Epoch: 8, step: 272/300, Loss: 0.02435\n",
      "Epoch: 8, step: 273/300, Loss: 0.02397\n",
      "Epoch: 8, step: 274/300, Loss: 0.04610\n",
      "Epoch: 8, step: 275/300, Loss: 0.01103\n",
      "Epoch: 8, step: 276/300, Loss: 0.01381\n",
      "Epoch: 8, step: 277/300, Loss: 0.00697\n",
      "Epoch: 8, step: 278/300, Loss: 0.01333\n",
      "Epoch: 8, step: 279/300, Loss: 0.00506\n",
      "Epoch: 8, step: 280/300, Loss: 0.02216\n",
      "Epoch: 8, step: 281/300, Loss: 0.00896\n",
      "Epoch: 8, step: 282/300, Loss: 0.00558\n",
      "Epoch: 8, step: 283/300, Loss: 0.00432\n",
      "Epoch: 8, step: 284/300, Loss: 1.46628\n",
      "Epoch: 8, step: 285/300, Loss: 0.28722\n",
      "Epoch: 8, step: 286/300, Loss: 0.06238\n",
      "Epoch: 8, step: 287/300, Loss: 0.01064\n",
      "Epoch: 8, step: 288/300, Loss: 0.08811\n",
      "Epoch: 8, step: 289/300, Loss: 0.00203\n",
      "Epoch: 8, step: 290/300, Loss: 0.08903\n",
      "Epoch: 8, step: 291/300, Loss: 0.24599\n",
      "Epoch: 8, step: 292/300, Loss: 0.02608\n",
      "Epoch: 8, step: 293/300, Loss: 0.00340\n",
      "Epoch: 8, step: 294/300, Loss: 0.01059\n",
      "Epoch: 8, step: 295/300, Loss: 0.04047\n",
      "Epoch: 8, step: 296/300, Loss: 0.00755\n",
      "Epoch: 8, step: 297/300, Loss: 0.00396\n",
      "Epoch: 8, step: 298/300, Loss: 0.05698\n",
      "Epoch: 8, step: 299/300, Loss: 0.09891\n",
      "Epoch: 9, step: 0/300, Loss: 0.00934\n",
      "Epoch: 9, step: 1/300, Loss: 0.03820\n",
      "Epoch: 9, step: 2/300, Loss: 0.01760\n",
      "Epoch: 9, step: 3/300, Loss: 0.00211\n",
      "Epoch: 9, step: 4/300, Loss: 0.00518\n",
      "Epoch: 9, step: 5/300, Loss: 0.01470\n",
      "Epoch: 9, step: 6/300, Loss: 0.01174\n",
      "Epoch: 9, step: 7/300, Loss: 0.02452\n",
      "Epoch: 9, step: 8/300, Loss: 0.00147\n",
      "Epoch: 9, step: 9/300, Loss: 0.06089\n",
      "Epoch: 9, step: 10/300, Loss: 0.01253\n",
      "Epoch: 9, step: 11/300, Loss: 0.00309\n",
      "Epoch: 9, step: 12/300, Loss: 0.01258\n",
      "Epoch: 9, step: 13/300, Loss: 0.00476\n",
      "Epoch: 9, step: 14/300, Loss: 0.03176\n",
      "Epoch: 9, step: 15/300, Loss: 0.01571\n",
      "Epoch: 9, step: 16/300, Loss: 0.70571\n",
      "Epoch: 9, step: 17/300, Loss: 0.01820\n",
      "Epoch: 9, step: 18/300, Loss: 0.00172\n",
      "Epoch: 9, step: 19/300, Loss: 0.01331\n",
      "Epoch: 9, step: 20/300, Loss: 0.45762\n",
      "Epoch: 9, step: 21/300, Loss: 0.02254\n",
      "Epoch: 9, step: 22/300, Loss: 0.00869\n",
      "Epoch: 9, step: 23/300, Loss: 0.22543\n",
      "Epoch: 9, step: 24/300, Loss: 0.01783\n",
      "Epoch: 9, step: 25/300, Loss: 0.02144\n",
      "Epoch: 9, step: 26/300, Loss: 0.00771\n",
      "Epoch: 9, step: 27/300, Loss: 0.01586\n",
      "Epoch: 9, step: 28/300, Loss: 0.00579\n",
      "Epoch: 9, step: 29/300, Loss: 0.03502\n",
      "Epoch: 9, step: 30/300, Loss: 0.00658\n",
      "Epoch: 9, step: 31/300, Loss: 0.01048\n",
      "Epoch: 9, step: 32/300, Loss: 0.23262\n",
      "Epoch: 9, step: 33/300, Loss: 0.00594\n",
      "Epoch: 9, step: 34/300, Loss: 0.01519\n",
      "Epoch: 9, step: 35/300, Loss: 0.00692\n",
      "Epoch: 9, step: 36/300, Loss: 0.01064\n",
      "Epoch: 9, step: 37/300, Loss: 0.00207\n",
      "Epoch: 9, step: 38/300, Loss: 0.00762\n",
      "Epoch: 9, step: 39/300, Loss: 0.00711\n",
      "Epoch: 9, step: 40/300, Loss: 0.00290\n",
      "Epoch: 9, step: 41/300, Loss: 0.00247\n",
      "Epoch: 9, step: 42/300, Loss: 0.00228\n",
      "Epoch: 9, step: 43/300, Loss: 0.00445\n",
      "Epoch: 9, step: 44/300, Loss: 0.00246\n",
      "Epoch: 9, step: 45/300, Loss: 0.01042\n",
      "Epoch: 9, step: 46/300, Loss: 0.14115\n",
      "Epoch: 9, step: 47/300, Loss: 0.30773\n",
      "Epoch: 9, step: 48/300, Loss: 0.00383\n",
      "Epoch: 9, step: 49/300, Loss: 0.00382\n",
      "Epoch: 9, step: 50/300, Loss: 0.01390\n",
      "Epoch: 9, step: 51/300, Loss: 0.00946\n",
      "Epoch: 9, step: 52/300, Loss: 0.00899\n",
      "Epoch: 9, step: 53/300, Loss: 0.00510\n",
      "Epoch: 9, step: 54/300, Loss: 0.51821\n",
      "Epoch: 9, step: 55/300, Loss: 0.00468\n",
      "Epoch: 9, step: 56/300, Loss: 0.09976\n",
      "Epoch: 9, step: 57/300, Loss: 0.00242\n",
      "Epoch: 9, step: 58/300, Loss: 0.02668\n",
      "Epoch: 9, step: 59/300, Loss: 0.00587\n",
      "Epoch: 9, step: 60/300, Loss: 0.01277\n",
      "Epoch: 9, step: 61/300, Loss: 0.01028\n",
      "Epoch: 9, step: 62/300, Loss: 0.00318\n",
      "Epoch: 9, step: 63/300, Loss: 0.00392\n",
      "Epoch: 9, step: 64/300, Loss: 0.00699\n",
      "Epoch: 9, step: 65/300, Loss: 0.00479\n",
      "Epoch: 9, step: 66/300, Loss: 0.25108\n",
      "Epoch: 9, step: 67/300, Loss: 0.01187\n",
      "Epoch: 9, step: 68/300, Loss: 0.01024\n",
      "Epoch: 9, step: 69/300, Loss: 0.01093\n",
      "Epoch: 9, step: 70/300, Loss: 0.00749\n",
      "Epoch: 9, step: 71/300, Loss: 0.00389\n",
      "Epoch: 9, step: 72/300, Loss: 0.08386\n",
      "Epoch: 9, step: 73/300, Loss: 0.02382\n",
      "Epoch: 9, step: 74/300, Loss: 0.00163\n",
      "Epoch: 9, step: 75/300, Loss: 0.04427\n",
      "Epoch: 9, step: 76/300, Loss: 0.00162\n",
      "Epoch: 9, step: 77/300, Loss: 0.03039\n",
      "Epoch: 9, step: 78/300, Loss: 0.12600\n",
      "Epoch: 9, step: 79/300, Loss: 0.01168\n",
      "Epoch: 9, step: 80/300, Loss: 0.00691\n",
      "Epoch: 9, step: 81/300, Loss: 0.04405\n",
      "Epoch: 9, step: 82/300, Loss: 0.00480\n",
      "Epoch: 9, step: 83/300, Loss: 0.01892\n",
      "Epoch: 9, step: 84/300, Loss: 0.02061\n",
      "Epoch: 9, step: 85/300, Loss: 0.00984\n",
      "Epoch: 9, step: 86/300, Loss: 0.01534\n",
      "Epoch: 9, step: 87/300, Loss: 0.00259\n",
      "Epoch: 9, step: 88/300, Loss: 0.01443\n",
      "Epoch: 9, step: 89/300, Loss: 0.00163\n",
      "Epoch: 9, step: 90/300, Loss: 0.00604\n",
      "Epoch: 9, step: 91/300, Loss: 0.02158\n",
      "Epoch: 9, step: 92/300, Loss: 0.05771\n",
      "Epoch: 9, step: 93/300, Loss: 0.01159\n",
      "Epoch: 9, step: 94/300, Loss: 0.00403\n",
      "Epoch: 9, step: 95/300, Loss: 0.05133\n",
      "Epoch: 9, step: 96/300, Loss: 0.00516\n",
      "Epoch: 9, step: 97/300, Loss: 0.03606\n",
      "Epoch: 9, step: 98/300, Loss: 0.00273\n",
      "Epoch: 9, step: 99/300, Loss: 0.02656\n",
      "Epoch: 9, step: 100/300, Loss: 0.00371\n",
      "Epoch: 9, step: 101/300, Loss: 0.03249\n",
      "Epoch: 9, step: 102/300, Loss: 0.00451\n",
      "Epoch: 9, step: 103/300, Loss: 0.00298\n",
      "Epoch: 9, step: 104/300, Loss: 0.00393\n",
      "Epoch: 9, step: 105/300, Loss: 0.00644\n",
      "Epoch: 9, step: 106/300, Loss: 0.00178\n",
      "Epoch: 9, step: 107/300, Loss: 0.00300\n",
      "Epoch: 9, step: 108/300, Loss: 0.00535\n",
      "Epoch: 9, step: 109/300, Loss: 0.10979\n",
      "Epoch: 9, step: 110/300, Loss: 0.34389\n",
      "Epoch: 9, step: 111/300, Loss: 0.00567\n",
      "Epoch: 9, step: 112/300, Loss: 0.01375\n",
      "Epoch: 9, step: 113/300, Loss: 0.00300\n",
      "Epoch: 9, step: 114/300, Loss: 0.16510\n",
      "Epoch: 9, step: 115/300, Loss: 0.00432\n",
      "Epoch: 9, step: 116/300, Loss: 0.02250\n",
      "Epoch: 9, step: 117/300, Loss: 0.15141\n",
      "Epoch: 9, step: 118/300, Loss: 0.00468\n",
      "Epoch: 9, step: 119/300, Loss: 0.19273\n",
      "Epoch: 9, step: 120/300, Loss: 0.00112\n",
      "Epoch: 9, step: 121/300, Loss: 0.00534\n",
      "Epoch: 9, step: 122/300, Loss: 0.00393\n",
      "Epoch: 9, step: 123/300, Loss: 0.09235\n",
      "Epoch: 9, step: 124/300, Loss: 0.09012\n",
      "Epoch: 9, step: 125/300, Loss: 0.07081\n",
      "Epoch: 9, step: 126/300, Loss: 0.01233\n",
      "Epoch: 9, step: 127/300, Loss: 0.07336\n",
      "Epoch: 9, step: 128/300, Loss: 0.00179\n",
      "Epoch: 9, step: 129/300, Loss: 0.02152\n",
      "Epoch: 9, step: 130/300, Loss: 0.00751\n",
      "Epoch: 9, step: 131/300, Loss: 0.00124\n",
      "Epoch: 9, step: 132/300, Loss: 0.00318\n",
      "Epoch: 9, step: 133/300, Loss: 0.00480\n",
      "Epoch: 9, step: 134/300, Loss: 0.00647\n",
      "Epoch: 9, step: 135/300, Loss: 0.00085\n",
      "Epoch: 9, step: 136/300, Loss: 0.00394\n",
      "Epoch: 9, step: 137/300, Loss: 0.01617\n",
      "Epoch: 9, step: 138/300, Loss: 0.00123\n",
      "Epoch: 9, step: 139/300, Loss: 0.00194\n",
      "Epoch: 9, step: 140/300, Loss: 0.19134\n",
      "Epoch: 9, step: 141/300, Loss: 0.01288\n",
      "Epoch: 9, step: 142/300, Loss: 0.00594\n",
      "Epoch: 9, step: 143/300, Loss: 0.11171\n",
      "Epoch: 9, step: 144/300, Loss: 0.00259\n",
      "Epoch: 9, step: 145/300, Loss: 0.02016\n",
      "Epoch: 9, step: 146/300, Loss: 0.06962\n",
      "Epoch: 9, step: 147/300, Loss: 0.00307\n",
      "Epoch: 9, step: 148/300, Loss: 0.00210\n",
      "Epoch: 9, step: 149/300, Loss: 0.00121\n",
      "Epoch: 9, step: 150/300, Loss: 0.00319\n",
      "Epoch: 9, step: 151/300, Loss: 0.00526\n",
      "Epoch: 9, step: 152/300, Loss: 0.00387\n",
      "Epoch: 9, step: 153/300, Loss: 0.02079\n",
      "Epoch: 9, step: 154/300, Loss: 0.00489\n",
      "Epoch: 9, step: 155/300, Loss: 0.00192\n",
      "Epoch: 9, step: 156/300, Loss: 0.01680\n",
      "Epoch: 9, step: 157/300, Loss: 0.00543\n",
      "Epoch: 9, step: 158/300, Loss: 0.00271\n",
      "Epoch: 9, step: 159/300, Loss: 0.01109\n",
      "Epoch: 9, step: 160/300, Loss: 0.00303\n",
      "Epoch: 9, step: 161/300, Loss: 0.00178\n",
      "Epoch: 9, step: 162/300, Loss: 0.00215\n",
      "Epoch: 9, step: 163/300, Loss: 0.01396\n",
      "Epoch: 9, step: 164/300, Loss: 0.00981\n",
      "Epoch: 9, step: 165/300, Loss: 0.02727\n",
      "Epoch: 9, step: 166/300, Loss: 0.00407\n",
      "Epoch: 9, step: 167/300, Loss: 0.00365\n",
      "Epoch: 9, step: 168/300, Loss: 0.00300\n",
      "Epoch: 9, step: 169/300, Loss: 0.01803\n",
      "Epoch: 9, step: 170/300, Loss: 0.00323\n",
      "Epoch: 9, step: 171/300, Loss: 0.00232\n",
      "Epoch: 9, step: 172/300, Loss: 0.01448\n",
      "Epoch: 9, step: 173/300, Loss: 0.01337\n",
      "Epoch: 9, step: 174/300, Loss: 0.00199\n",
      "Epoch: 9, step: 175/300, Loss: 0.03707\n",
      "Epoch: 9, step: 176/300, Loss: 0.02180\n",
      "Epoch: 9, step: 177/300, Loss: 0.00204\n",
      "Epoch: 9, step: 178/300, Loss: 0.00136\n",
      "Epoch: 9, step: 179/300, Loss: 0.00612\n",
      "Epoch: 9, step: 180/300, Loss: 0.01548\n",
      "Epoch: 9, step: 181/300, Loss: 0.00255\n",
      "Epoch: 9, step: 182/300, Loss: 0.00278\n",
      "Epoch: 9, step: 183/300, Loss: 0.00194\n",
      "Epoch: 9, step: 184/300, Loss: 0.00640\n",
      "Epoch: 9, step: 185/300, Loss: 0.00730\n",
      "Epoch: 9, step: 186/300, Loss: 0.01247\n",
      "Epoch: 9, step: 187/300, Loss: 0.00238\n",
      "Epoch: 9, step: 188/300, Loss: 0.00646\n",
      "Epoch: 9, step: 189/300, Loss: 0.00620\n",
      "Epoch: 9, step: 190/300, Loss: 0.00207\n",
      "Epoch: 9, step: 191/300, Loss: 0.00468\n",
      "Epoch: 9, step: 192/300, Loss: 0.00131\n",
      "Epoch: 9, step: 193/300, Loss: 0.08492\n",
      "Epoch: 9, step: 194/300, Loss: 0.00394\n",
      "Epoch: 9, step: 195/300, Loss: 0.00352\n",
      "Epoch: 9, step: 196/300, Loss: 0.01032\n",
      "Epoch: 9, step: 197/300, Loss: 0.00521\n",
      "Epoch: 9, step: 198/300, Loss: 0.02011\n",
      "Epoch: 9, step: 199/300, Loss: 0.00192\n",
      "Epoch: 9, step: 200/300, Loss: 0.00162\n",
      "Epoch: 9, step: 201/300, Loss: 0.00148\n",
      "Epoch: 9, step: 202/300, Loss: 0.00528\n",
      "Epoch: 9, step: 203/300, Loss: 0.00376\n",
      "Epoch: 9, step: 204/300, Loss: 0.00518\n",
      "Epoch: 9, step: 205/300, Loss: 0.00358\n",
      "Epoch: 9, step: 206/300, Loss: 0.00083\n",
      "Epoch: 9, step: 207/300, Loss: 0.00455\n",
      "Epoch: 9, step: 208/300, Loss: 0.02083\n",
      "Epoch: 9, step: 209/300, Loss: 0.00348\n",
      "Epoch: 9, step: 210/300, Loss: 0.00282\n",
      "Epoch: 9, step: 211/300, Loss: 0.01323\n",
      "Epoch: 9, step: 212/300, Loss: 0.00547\n",
      "Epoch: 9, step: 213/300, Loss: 0.01141\n",
      "Epoch: 9, step: 214/300, Loss: 0.00245\n",
      "Epoch: 9, step: 215/300, Loss: 0.00226\n",
      "Epoch: 9, step: 216/300, Loss: 0.02136\n",
      "Epoch: 9, step: 217/300, Loss: 0.01883\n",
      "Epoch: 9, step: 218/300, Loss: 0.03356\n",
      "Epoch: 9, step: 219/300, Loss: 0.00250\n",
      "Epoch: 9, step: 220/300, Loss: 0.00618\n",
      "Epoch: 9, step: 221/300, Loss: 0.01520\n",
      "Epoch: 9, step: 222/300, Loss: 0.00106\n",
      "Epoch: 9, step: 223/300, Loss: 0.01493\n",
      "Epoch: 9, step: 224/300, Loss: 0.00580\n",
      "Epoch: 9, step: 225/300, Loss: 0.00133\n",
      "Epoch: 9, step: 226/300, Loss: 0.00247\n",
      "Epoch: 9, step: 227/300, Loss: 0.00104\n",
      "Epoch: 9, step: 228/300, Loss: 0.00292\n",
      "Epoch: 9, step: 229/300, Loss: 0.00265\n",
      "Epoch: 9, step: 230/300, Loss: 0.04386\n",
      "Epoch: 9, step: 231/300, Loss: 0.00346\n",
      "Epoch: 9, step: 232/300, Loss: 0.01055\n",
      "Epoch: 9, step: 233/300, Loss: 0.03384\n",
      "Epoch: 9, step: 234/300, Loss: 0.00183\n",
      "Epoch: 9, step: 235/300, Loss: 0.00276\n",
      "Epoch: 9, step: 236/300, Loss: 0.01446\n",
      "Epoch: 9, step: 237/300, Loss: 0.00779\n",
      "Epoch: 9, step: 238/300, Loss: 0.00360\n",
      "Epoch: 9, step: 239/300, Loss: 0.00636\n",
      "Epoch: 9, step: 240/300, Loss: 0.01158\n",
      "Epoch: 9, step: 241/300, Loss: 0.00531\n",
      "Epoch: 9, step: 242/300, Loss: 0.00148\n",
      "Epoch: 9, step: 243/300, Loss: 0.00583\n",
      "Epoch: 9, step: 244/300, Loss: 0.00950\n",
      "Epoch: 9, step: 245/300, Loss: 0.03218\n",
      "Epoch: 9, step: 246/300, Loss: 0.01287\n",
      "Epoch: 9, step: 247/300, Loss: 0.00130\n",
      "Epoch: 9, step: 248/300, Loss: 0.00442\n",
      "Epoch: 9, step: 249/300, Loss: 0.00563\n",
      "Epoch: 9, step: 250/300, Loss: 0.00103\n",
      "Epoch: 9, step: 251/300, Loss: 0.02015\n",
      "Epoch: 9, step: 252/300, Loss: 0.00273\n",
      "Epoch: 9, step: 253/300, Loss: 0.00143\n",
      "Epoch: 9, step: 254/300, Loss: 0.09080\n",
      "Epoch: 9, step: 255/300, Loss: 0.00490\n",
      "Epoch: 9, step: 256/300, Loss: 0.00506\n",
      "Epoch: 9, step: 257/300, Loss: 0.00403\n",
      "Epoch: 9, step: 258/300, Loss: 0.00223\n",
      "Epoch: 9, step: 259/300, Loss: 0.00196\n",
      "Epoch: 9, step: 260/300, Loss: 0.00816\n",
      "Epoch: 9, step: 261/300, Loss: 0.00631\n",
      "Epoch: 9, step: 262/300, Loss: 0.00129\n",
      "Epoch: 9, step: 263/300, Loss: 0.02035\n",
      "Epoch: 9, step: 264/300, Loss: 0.00319\n",
      "Epoch: 9, step: 265/300, Loss: 0.07504\n",
      "Epoch: 9, step: 266/300, Loss: 0.00233\n",
      "Epoch: 9, step: 267/300, Loss: 0.29005\n",
      "Epoch: 9, step: 268/300, Loss: 0.02063\n",
      "Epoch: 9, step: 269/300, Loss: 0.00314\n",
      "Epoch: 9, step: 270/300, Loss: 0.00960\n",
      "Epoch: 9, step: 271/300, Loss: 0.00508\n",
      "Epoch: 9, step: 272/300, Loss: 0.25593\n",
      "Epoch: 9, step: 273/300, Loss: 0.01042\n",
      "Epoch: 9, step: 274/300, Loss: 0.00319\n",
      "Epoch: 9, step: 275/300, Loss: 0.00124\n",
      "Epoch: 9, step: 276/300, Loss: 0.00250\n",
      "Epoch: 9, step: 277/300, Loss: 1.02149\n",
      "Epoch: 9, step: 278/300, Loss: 0.00647\n",
      "Epoch: 9, step: 279/300, Loss: 0.00502\n",
      "Epoch: 9, step: 280/300, Loss: 0.81115\n",
      "Epoch: 9, step: 281/300, Loss: 0.00804\n",
      "Epoch: 9, step: 282/300, Loss: 0.00486\n",
      "Epoch: 9, step: 283/300, Loss: 0.00465\n",
      "Epoch: 9, step: 284/300, Loss: 0.84284\n",
      "Epoch: 9, step: 285/300, Loss: 0.02862\n",
      "Epoch: 9, step: 286/300, Loss: 0.00513\n",
      "Epoch: 9, step: 287/300, Loss: 0.02925\n",
      "Epoch: 9, step: 288/300, Loss: 2.56658\n",
      "Epoch: 9, step: 289/300, Loss: 0.03369\n",
      "Epoch: 9, step: 290/300, Loss: 0.00560\n",
      "Epoch: 9, step: 291/300, Loss: 0.54025\n",
      "Epoch: 9, step: 292/300, Loss: 0.00631\n",
      "Epoch: 9, step: 293/300, Loss: 0.03084\n",
      "Epoch: 9, step: 294/300, Loss: 0.23529\n",
      "Epoch: 9, step: 295/300, Loss: 0.16464\n",
      "Epoch: 9, step: 296/300, Loss: 0.16640\n",
      "Epoch: 9, step: 297/300, Loss: 0.01023\n",
      "Epoch: 9, step: 298/300, Loss: 1.01892\n",
      "Epoch: 9, step: 299/300, Loss: 0.01607\n"
     ]
    }
   ],
   "source": [
    "dataloader=DataLoader(dataset=actDataset,shuffle=True)\n",
    "model=ModelSTGCN(3,2)\n",
    "Train_val(model,dataloader,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for epoch in range(2):\n",
    "# #     for i,data in enumerate (dataloader):\n",
    "# #         print(f'Epoch: {epoch}, Step: {i+1}/{len(dataloader)}, label: {data[1]}')\n",
    "# dataview=iter(dataloader)\n",
    "# data = dataview.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile=pds.read_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testact=ActionDataset(ToTensor())\n",
    "testact.append(testfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([126, 17, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.expand_copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1], device='cuda:0') tensor(1)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    testdata,testlabel = testact[0]\n",
    "    testdata=testdata.unsqueeze(0).to('cuda')\n",
    "    outputtest = model(testdata)\n",
    "    _,predict = torch.max(outputtest,1)\n",
    "    print(predict,testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=4\n",
    "# datalst=pds.read_pickle('train.pkl')\n",
    "# actDataset=ActionDataset(datalst[0])\n",
    "# dataloader=DataLoader(dataset=actDataset,batch_size=batch_size,shuffle=True)\n",
    "# n_sample=len(actDataset)\n",
    "# epochs=10\n",
    "# n_iter=round(n_sample/batch_size)\n",
    "# for epoch in range(epochs-8):\n",
    "#     for i,data in enumerate (dataloader):\n",
    "#         if (i+1)% (batch_size)==0:\n",
    "#             print(f'Epoch: {epoch}, Step: {i+1}/{n_iter}, Input shap: {data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# math.ceil(len(actDataset)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=4\n",
    "# datalst=pds.read_pickle('train.pkl')\n",
    "# actDataset=ActionDataset(datalst[0])\n",
    "# dataloader=DataLoader(dataset=actDataset,batch_size=batch_size,shuffle=True)\n",
    "# n_sample=len(actDataset)\n",
    "# n_iter=round(n_sample/batch_size)\n",
    "# model = ModelSTGCN(3,5)\n",
    "# lr = 1e-3\n",
    "# optim = torch.optim.Adam(model.parameters(),lr)\n",
    "# lr_schedule = torch.optim.lr_scheduler.MultiStepLR(optim,[15,30],gamma=0.1)\n",
    "# epochs = 10\n",
    "# for epoch in range(epochs):\n",
    "#     for i,data in enumerate (dataloader):\n",
    "#         if (i+1)% (batch_size)==0:\n",
    "#             print(f'Epoch: {epoch}, Step: {i+1}/{n_iter}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
