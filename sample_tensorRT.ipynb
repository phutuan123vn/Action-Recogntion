{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PhuTuan\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\PhuTuan\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\mmcv\\__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os.path as osp\n",
    "import os\n",
    "import glob\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import shutil\n",
    "from Pose.Hrnet import Hrnet\n",
    "from Pose.Yolov7 import Yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.58703389778664 FPS\n",
      "128.25116708704206 FPS\n"
     ]
    }
   ],
   "source": [
    "hrnet = Hrnet(engine_path='Pose/Hrnet48_fp32.trt')\n",
    "hrnet.get_fps()\n",
    "hrnet.destory()\n",
    "yolov7 = Yolov7(engine_path='Pose/yolov7_fp16.trt')\n",
    "yolov7.get_fps()\n",
    "yolov7.destory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_edge = [(15, 13), (13, 11), (16, 14), (14, 12), (11, 12),\n",
    "                                (5, 11), (6, 12), (5, 6), (5, 7), (6, 8), (7, 9),\n",
    "                                (8, 10), (1, 2), (0, 1), (0, 2), (1, 3), (2, 4),\n",
    "                                (3, 5), (4, 6)]\n",
    "\n",
    "def inference_image(img,detect:Yolov7,pose:Hrnet):\n",
    "    det_results = detect.inference(img)\n",
    "    pose_results = pose.inference_from_bbox(img,det_results)\n",
    "    return pose_results\n",
    "\n",
    "\n",
    "\n",
    "def vis_pose(image, pose_result,threshold = 0.5):\n",
    "        bbox = []\n",
    "        bbox_score = []\n",
    "        keypoints = []\n",
    "        keypoints_score = []\n",
    "        if pose_result is None:\n",
    "            return image\n",
    "        for pos in pose_result:\n",
    "            bbox.append(pos['bbox'][:4])\n",
    "            bbox_score.append(pos['bbox'][4])\n",
    "            keypoints.append(pos['keypoints'][:,:2])\n",
    "            keypoints_score.append(pos['keypoints'][:,2])\n",
    "        # max_score_indx = np.argmax(bbox_score)\n",
    "        # bbox = bbox[max_score_indx]\n",
    "        # keypoints = keypoints[max_score_indx]\n",
    "        # skeleton_features = pose_result[max_score_indx]['keypoints']\n",
    "        # keypoints = keypoints\n",
    "        # for edge in skeleton_edge:\n",
    "        #     start = keypoints[edge[0]]\n",
    "        #     end = keypoints[edge[1]]\n",
    "        #     image = cv2.line(image, (int(start[0]), int(start[1])), (int(end[0]), int(end[1])), (255,255,0), 2)\n",
    "        # for i in range(17):\n",
    "        #     (x, y) = keypoints[i]\n",
    "        # #     if self.label[i] == 0:\n",
    "        # #         color = (255, 255, 255)\n",
    "        # #     elif self.label[i] == 1:\n",
    "        # #         color = (0, 0, 255)\n",
    "        # #     elif self.label[i] == 2:\n",
    "        # #         color = (255, 0, 0)\n",
    "        #     image = cv2.circle(image, (int(x), int(y)), 4, (255, 255, 255), -1)\n",
    "\n",
    "        # image = cv2.rectangle(image, (int(bbox[0]), int(bbox[1])),(int(bbox[2]), int(bbox[3])) , (0,255,0), 1)\n",
    "        # return image\n",
    "        max_score_indx = np.argmax(bbox_score)\n",
    "        bbox = bbox[max_score_indx]\n",
    "        keypoints = keypoints[max_score_indx]\n",
    "        keypoints_score = keypoints_score[max_score_indx]\n",
    "        skeleton_features = pose_result[max_score_indx]['keypoints']\n",
    "        keypoints = keypoints\n",
    "        for edge in skeleton_edge:\n",
    "            start = keypoints[edge[0]]\n",
    "            end = keypoints[edge[1]]\n",
    "            # image = cv2.line(image, (int(start[0]), int(start[1])), (int(end[0]), int(end[1])), (255,255,0), 2)\n",
    "            if keypoints_score[edge[0]] < threshold or keypoints_score[edge[1]] < threshold:\n",
    "                continue\n",
    "            image = cv2.line(image, (int(start[0]), int(start[1])), (int(end[0]), int(end[1])), (255, 255, 0), 2)\n",
    "        for i in range(17):\n",
    "            (x, y) = keypoints[i]\n",
    "            if keypoints_score[i] < threshold:\n",
    "                continue\n",
    "            image = cv2.circle(image, (int(x), int(y)), 4, (255, 255, 255), -1)\n",
    "\n",
    "        image = cv2.rectangle(image, (int(bbox[0]), int(bbox[1])),(int(bbox[2]), int(bbox[3])) , (0,255,0), 1)\n",
    "        return image\n",
    "\n",
    "def extract_frame(video_path):\n",
    "    dname = 'temp'\n",
    "    os.makedirs(dname, exist_ok=True)\n",
    "    frame_tmpl = osp.join(dname, 'img_{:05d}.jpg')\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_paths = []\n",
    "    cnt = 0\n",
    "    while(cap.isOpened()):\n",
    "        flag, frame = cap.read()\n",
    "        if flag:\n",
    "            frame_path = frame_tmpl.format(cnt + 1)\n",
    "            frame_paths.append(frame_path)\n",
    "            frame=cv2.resize(frame,(640,480))\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            cnt += 1\n",
    "        else: break\n",
    "    cap.release()\n",
    "    return frame_paths\n",
    "\n",
    "def detection_inference(det_model:Yolov7,frame_paths,det_score=0.5):\n",
    "    results = []\n",
    "    print('Performing Human Detection for each frame')\n",
    "    prog_bar = mmcv.ProgressBar(len(frame_paths))\n",
    "    for frame_path in frame_paths:\n",
    "        img = cv2.imread(frame_path)\n",
    "        result = det_model.inference(img,det_score)\n",
    "        # We only keep human detections with score larger than det_score_thr\n",
    "        if len(result[2]) == 0:\n",
    "            results.append(result)\n",
    "            prog_bar.update()\n",
    "            continue\n",
    "        person_id = result[2] == 0\n",
    "        bbox = result[0][person_id]\n",
    "        score = result[1][person_id]\n",
    "        indx = result[2][result[2]==0]\n",
    "        results.append((bbox,score,indx))\n",
    "        prog_bar.update()\n",
    "    return results\n",
    "\n",
    "def pose_inference(pose_model:Hrnet,frame_paths,det_results):\n",
    "    print('Performing Human Pose Estimation for each frame')\n",
    "    prog_bar = mmcv.ProgressBar(len(frame_paths))\n",
    "    num_frame = len(det_results)\n",
    "    num_person = max([len(x[2]) for x in det_results])\n",
    "    if num_person == 0:\n",
    "        kp = np.zeros((1,num_frame,17,3),dtype=np.float32)\n",
    "        return kp\n",
    "    kp = np.zeros((num_person,num_frame,17,3))\n",
    "    for i ,(f,d) in enumerate(zip(frame_paths,det_results)):\n",
    "        img = cv2.imread(f)\n",
    "        pose_result = pose_model.inference_from_bbox(img,d)\n",
    "        if pose_result is None:\n",
    "            for person_id in range(num_person):\n",
    "                kp[person_id,i] = kp[person_id,i-1]\n",
    "        else:\n",
    "            for j,item in enumerate(pose_result):\n",
    "                kp [j,i] = item[\"keypoints\"]            \n",
    "        # if len(d[2]) == 0:\n",
    "        #     for person_id in range(num_person):\n",
    "        #         kp[person_id,i] = kp[person_id,i-1]\n",
    "        #     prog_bar.update()\n",
    "        #     continue\n",
    "        vis_image = vis_pose(img,pose_result)\n",
    "        cv2.imshow('',vis_image)\n",
    "        if cv2.waitKey(20)& 0xFF==ord('q'): break\n",
    "        prog_bar.update()\n",
    "    cv2.destroyAllWindows()\n",
    "    return kp\n",
    "\n",
    "def pose_extraction(vid,label,pose_model:Hrnet=hrnet,det_model:Yolov7=yolov7,det_score=0.5):\n",
    "    frame_paths = extract_frame(vid)\n",
    "    det_results = detection_inference(det_model,frame_paths,det_score)\n",
    "    img = cv2.imread(frame_paths[0])\n",
    "    img_shape = (img.shape[1],img.shape[0])\n",
    "    pose_results = pose_inference(pose_model,frame_paths,det_results)\n",
    "    anno = dict()\n",
    "    anno['kp'] = pose_results\n",
    "    anno['img_shape'] = img_shape\n",
    "    anno['total_frames'] = pose_results.shape[1]\n",
    "    anno['label'] = label\n",
    "    shutil.rmtree(osp.dirname(frame_paths[0]))\n",
    "    return anno\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='C:/Users/PhuTuan/Downloads/Video/Data_fall_171.mp4'\n",
    "# anno = pose_extraction(file,0,det_score=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 33.9 task/s, elapsed: 4s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "frame_paths = extract_frame(file)\n",
    "det_results = detection_inference(yolov7,frame_paths,0.8)\n",
    "img = cv2.imread(frame_paths[0])\n",
    "img_shape = (img.shape[1],img.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[273.  ,   1.25, 327.5 , 195.  ]]),\n",
       "  array([0.8691406], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[273.  ,   1.25, 327.5 , 195.25]]),\n",
       "  array([0.8803711], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[272.75,   1.25, 327.25, 195.25]]),\n",
       "  array([0.87890625], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[272.5   ,   1.8125, 327.5   , 194.5   ]]),\n",
       "  array([0.8930664], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[272.75  ,   2.3125, 327.75  , 195.5   ]]),\n",
       "  array([0.88623047], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[272.5  ,   3.625, 328.   , 197.5  ]]),\n",
       "  array([0.8828125], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[272.75,   3.75, 328.25, 198.  ]]),\n",
       "  array([0.8852539], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[272.75,   4.  , 328.25, 198.5 ]]),\n",
       "  array([0.8959961], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[273.    ,   5.4375, 328.5   , 201.    ]]),\n",
       "  array([0.8779297], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[273.    ,   4.8125, 328.5   , 205.75  ]]),\n",
       "  array([0.8964844], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[272.5   ,   4.4375, 328.5   , 207.    ]]),\n",
       "  array([0.9008789], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[272.75,   4.75, 328.75, 210.  ]]),\n",
       "  array([0.90283203], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[272.5 ,   5.25, 328.5 , 210.25]]),\n",
       "  array([0.90283203], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[272.25 ,   6.125, 328.75 , 212.   ]]),\n",
       "  array([0.9013672], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[271.75,   7.75, 328.25, 207.25]]),\n",
       "  array([0.890625], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[272.    ,   9.4375, 328.5   , 211.5   ]]),\n",
       "  array([0.88183594], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[272.25,   6.25, 328.75, 222.25]]),\n",
       "  array([0.8852539], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[272.   ,   6.375, 329.   , 222.   ]]),\n",
       "  array([0.8833008], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[271.75  ,   6.9375, 328.25  , 222.    ]]),\n",
       "  array([0.8964844], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[270.75  ,   7.0625, 329.25  , 222.    ]]),\n",
       "  array([0.8930664], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[270.25,   8.75, 329.75, 213.25]]),\n",
       "  array([0.8964844], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[269.75,   7.  , 330.75, 221.5 ]]),\n",
       "  array([0.8955078], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[270.  ,   7.  , 330.5 , 221.25]]),\n",
       "  array([0.8955078], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[269.75  ,   6.9375, 331.25  , 222.    ]]),\n",
       "  array([0.8925781], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[269.25  ,   7.1875, 331.75  , 223.5   ]]),\n",
       "  array([0.89746094], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[269.25 ,   7.625, 332.75 , 223.5  ]]),\n",
       "  array([0.9042969], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[269.5   ,   8.1875, 333.5   , 223.25  ]]),\n",
       "  array([0.9067383], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[269.5   ,   8.1875, 333.5   , 223.25  ]]),\n",
       "  array([0.9086914], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[269.75  ,   8.1875, 333.75  , 224.5   ]]),\n",
       "  array([0.9111328], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[269.75,   8.25, 333.75, 225.75]]),\n",
       "  array([0.91308594], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[270.    ,   8.1875, 334.    , 229.25  ]]),\n",
       "  array([0.91308594], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[271.   ,  11.625, 333.5  , 228.   ]]),\n",
       "  array([0.9003906], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[270.5  ,  11.125, 333.5  , 228.   ]]),\n",
       "  array([0.8989258], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[270.75,  13.  , 336.75, 238.5 ]]),\n",
       "  array([0.8725586], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[271.5   ,  13.0625, 337.    , 239.75  ]]),\n",
       "  array([0.8652344], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[273.25 ,  14.125, 337.75 , 231.5  ]]),\n",
       "  array([0.8647461], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[274.25 ,  14.125, 338.75 , 246.   ]]),\n",
       "  array([0.8725586], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[274.25 ,  14.125, 338.75 , 246.   ]]),\n",
       "  array([0.86865234], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[277.25,  17.5 , 337.75, 234.25]]),\n",
       "  array([0.88623047], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[278. ,  16.5, 337.5, 231.5]]),\n",
       "  array([0.89160156], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[278.  ,  16.25, 339.5 , 235.25]]),\n",
       "  array([0.87890625], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[279.25,  15.  , 341.25, 232.  ]]),\n",
       "  array([0.8720703], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[279.25,  15.  , 341.25, 232.75]]),\n",
       "  array([0.8666992], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[281.5  ,  15.875, 343.   , 231.   ]]),\n",
       "  array([0.86816406], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[282. ,  15.5, 345.5, 235.5]]),\n",
       "  array([0.90234375], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[284.   ,  15.125, 349.   , 236.5  ]]),\n",
       "  array([0.9057617], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[285.    ,  13.5625, 350.5   , 247.5   ]]),\n",
       "  array([0.89990234], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[284.75  ,  13.4375, 350.75  , 247.25  ]]),\n",
       "  array([0.9008789], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[285.75 ,  13.875, 351.75 , 248.5  ]]),\n",
       "  array([0.89697266], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[286.75  ,  14.6875, 353.75  , 247.5   ]]),\n",
       "  array([0.90185547], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[289.75  ,  15.3125, 357.75  , 249.25  ]]),\n",
       "  array([0.9082031], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[289.75,  17.25, 359.25, 249.25]]),\n",
       "  array([0.9086914], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[289.75  ,  17.4375, 359.25  , 249.    ]]),\n",
       "  array([0.9091797], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[290.    ,  18.5625, 362.    , 250.25  ]]),\n",
       "  array([0.90771484], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[289.5   ,  18.1875, 364.    , 251.    ]]),\n",
       "  array([0.90527344], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[289.75  ,  19.9375, 365.75  , 251.25  ]]),\n",
       "  array([0.9013672], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[290.5   ,  21.4375, 368.5   , 249.5   ]]),\n",
       "  array([0.9038086], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[290.5   ,  21.1875, 368.5   , 249.25  ]]),\n",
       "  array([0.9013672], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[291.5   ,  24.1875, 369.    , 253.25  ]]),\n",
       "  array([0.9003906], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[291.75 ,  26.125, 371.25 , 256.5  ]]),\n",
       "  array([0.9003906], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[291.25  ,  30.9375, 376.25  , 257.25  ]]),\n",
       "  array([0.8886719], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[291.5   ,  37.4375, 380.5   , 265.25  ]]),\n",
       "  array([0.8774414], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[291.25,  37.75, 381.25, 265.  ]]),\n",
       "  array([0.87597656], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[289.75 ,  44.125, 384.75 , 272.5  ]]),\n",
       "  array([0.8833008], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[294.5,  54.5, 380.5, 269. ]]),\n",
       "  array([0.8647461], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[299.  ,  71.75, 386.5 , 266.25]]),\n",
       "  array([0.8730469], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[302.25 ,  84.625, 387.25 , 267.5  ]]),\n",
       "  array([0.8261719], dtype=float32),\n",
       "  array([0])),\n",
       " (array([[303.25,  84.5 , 387.75, 267.25]]),\n",
       "  array([0.8144531], dtype=float32),\n",
       "  array([0])),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " ([], [], []),\n",
       " ([], [], []),\n",
       " ([], [], []),\n",
       " ([], [], []),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " ([], [], []),\n",
       " ([], [], []),\n",
       " ([], [], []),\n",
       " ([], [], []),\n",
       " ([], [], []),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " ([], [], []),\n",
       " ([], [], []),\n",
       " ([], [], []),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " ([], [], []),\n",
       " ([], [], []),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " ([], [], []),\n",
       " ([], [], []),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32)),\n",
       " (array([], shape=(0, 4), dtype=float64),\n",
       "  array([], dtype=float32),\n",
       "  array([], dtype=int32))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 18.9 task/s, elapsed: 7s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "pose_results = pose_inference(hrnet,frame_paths,det_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = dict()\n",
    "anno['kp'] = pose_results\n",
    "anno['img_shape'] = img_shape\n",
    "anno['total_frames'] = pose_results.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], shape=(0, 4), dtype=float64),\n",
       " array([], dtype=float32),\n",
       " array([], dtype=int32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_results[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_paths = extract_frame(file)\n",
    "det_results = detection_inference(yolov7,frame_paths,0.8)\n",
    "img = cv2.imread(frame_paths[0])\n",
    "img_shape = (img.shape[1],img.shape[0])\n",
    "pose_results = pose_inference(hrnet,frame_paths,det_results)\n",
    "anno = dict()\n",
    "anno['kp'] = pose_results\n",
    "anno['img_shape'] = img_shape\n",
    "anno['total_frames'] = pose_results.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(frame_paths[71])\n",
    "result = yolov7.inference(img,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2] == 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
