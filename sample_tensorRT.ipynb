{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PhuTuan\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\PhuTuan\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\mmcv\\__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os.path as osp\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import shutil\n",
    "from Pose.Hrnet import Hrnet\n",
    "from Pose.Yolov7 import Yolov7\n",
    "import mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.74011727707267 FPS\n",
      "150.90695077405823 FPS\n"
     ]
    }
   ],
   "source": [
    "pose_model = Hrnet(engine_path='Pose/Hrnet48_fp32.trt')\n",
    "pose_model.get_fps()\n",
    "pose_model.destory()\n",
    "det_model = Yolov7(engine_path='Pose/yolov7_fp16.trt')\n",
    "det_model.get_fps()\n",
    "det_model.destory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_edge = [(15, 13), (13, 11), (16, 14), (14, 12), (11, 12),\n",
    "                                (5, 11), (6, 12), (5, 6), (5, 7), (6, 8), (7, 9),\n",
    "                                (8, 10), (1, 2), (0, 1), (0, 2), (1, 3), (2, 4),\n",
    "                                (3, 5), (4, 6)]\n",
    "\n",
    "def inference_image(img,detect:Yolov7,pose:Hrnet):\n",
    "    det_results = detect.inference(img)\n",
    "    pose_results = pose.inference_from_bbox(img,det_results)\n",
    "    return pose_results\n",
    "\n",
    "\n",
    "\n",
    "def vis_pose(image, pose_result,threshold = 0.5):\n",
    "        bbox = []\n",
    "        bbox_score = []\n",
    "        keypoints = []\n",
    "        keypoints_score = []\n",
    "        if pose_result is None:\n",
    "            return image\n",
    "        for pos in pose_result:\n",
    "            bbox.append(pos['bbox'][:4])\n",
    "            bbox_score.append(pos['bbox'][4])\n",
    "            keypoints.append(pos['keypoints'][:,:2])\n",
    "            keypoints_score.append(pos['keypoints'][:,2])\n",
    "        # max_score_indx = np.argmax(bbox_score)\n",
    "        # bbox = bbox[max_score_indx]\n",
    "        # keypoints = keypoints[max_score_indx]\n",
    "        # skeleton_features = pose_result[max_score_indx]['keypoints']\n",
    "        # keypoints = keypoints\n",
    "        # for edge in skeleton_edge:\n",
    "        #     start = keypoints[edge[0]]\n",
    "        #     end = keypoints[edge[1]]\n",
    "        #     image = cv2.line(image, (int(start[0]), int(start[1])), (int(end[0]), int(end[1])), (255,255,0), 2)\n",
    "        # for i in range(17):\n",
    "        #     (x, y) = keypoints[i]\n",
    "        # #     if self.label[i] == 0:\n",
    "        # #         color = (255, 255, 255)\n",
    "        # #     elif self.label[i] == 1:\n",
    "        # #         color = (0, 0, 255)\n",
    "        # #     elif self.label[i] == 2:\n",
    "        # #         color = (255, 0, 0)\n",
    "        #     image = cv2.circle(image, (int(x), int(y)), 4, (255, 255, 255), -1)\n",
    "\n",
    "        # image = cv2.rectangle(image, (int(bbox[0]), int(bbox[1])),(int(bbox[2]), int(bbox[3])) , (0,255,0), 1)\n",
    "        # return image\n",
    "        max_score_indx = np.argmax(bbox_score)\n",
    "        bbox = bbox[max_score_indx]\n",
    "        keypoints = keypoints[max_score_indx]\n",
    "        keypoints_score = keypoints_score[max_score_indx]\n",
    "        skeleton_features = pose_result[max_score_indx]['keypoints']\n",
    "        keypoints = keypoints\n",
    "        for edge in skeleton_edge:\n",
    "            start = keypoints[edge[0]]\n",
    "            end = keypoints[edge[1]]\n",
    "            # image = cv2.line(image, (int(start[0]), int(start[1])), (int(end[0]), int(end[1])), (255,255,0), 2)\n",
    "            if keypoints_score[edge[0]] < threshold or keypoints_score[edge[1]] < threshold:\n",
    "                continue\n",
    "            image = cv2.line(image, (int(start[0]), int(start[1])), (int(end[0]), int(end[1])), (255, 255, 0), 2)\n",
    "        for i in range(17):\n",
    "            (x, y) = keypoints[i]\n",
    "            if keypoints_score[i] < threshold:\n",
    "                continue\n",
    "            image = cv2.circle(image, (int(x), int(y)), 4, (255, 255, 255), -1)\n",
    "\n",
    "        image = cv2.rectangle(image, (int(bbox[0]), int(bbox[1])),(int(bbox[2]), int(bbox[3])) , (0,255,0), 1)\n",
    "        return image\n",
    "\n",
    "def extract_frame(video_path):\n",
    "    dname = 'temp'\n",
    "    os.makedirs(dname, exist_ok=True)\n",
    "    frame_tmpl = osp.join(dname, 'img_{:05d}.jpg')\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_paths = []\n",
    "    cnt = 0\n",
    "    while(cap.isOpened()):\n",
    "        flag, frame = cap.read()\n",
    "        if flag:\n",
    "            frame_path = frame_tmpl.format(cnt + 1)\n",
    "            frame_paths.append(frame_path)\n",
    "            frame=cv2.resize(frame,(640,480))\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            cnt += 1\n",
    "        else: break\n",
    "    cap.release()\n",
    "    return frame_paths\n",
    "\n",
    "def detection_inference(det_model:Yolov7,frame_paths,det_score=0.5):\n",
    "    results = []\n",
    "    print('Performing Human Detection for each frame')\n",
    "    prog_bar = mmcv.ProgressBar(len(frame_paths))\n",
    "    for frame_path in frame_paths:\n",
    "        img = cv2.imread(frame_path)\n",
    "        result = det_model.inference(img,det_score)\n",
    "        # We only keep human detections with score larger than det_score_thr\n",
    "        if len(result[2]) == 0:\n",
    "            results.append(result)\n",
    "            prog_bar.update()\n",
    "            continue\n",
    "        person_id = result[2] == 0\n",
    "        bbox = result[0][person_id]\n",
    "        score = result[1][person_id]\n",
    "        indx = result[2][result[2]==0]\n",
    "        results.append((bbox,score,indx))\n",
    "        prog_bar.update()\n",
    "    return results\n",
    "\n",
    "def pose_inference(pose_model:Hrnet,frame_paths,det_results):\n",
    "    print('Performing Human Pose Estimation for each frame')\n",
    "    prog_bar = mmcv.ProgressBar(len(frame_paths))\n",
    "    num_frame = len(det_results)\n",
    "    num_person = max([len(x[2]) for x in det_results])\n",
    "    if num_person == 0:\n",
    "        kp = np.zeros((1,num_frame,17,3),dtype=np.float32)\n",
    "        return kp\n",
    "    kp = np.zeros((num_person,num_frame,17,3))\n",
    "    for i ,(f,d) in enumerate(zip(frame_paths,det_results)):\n",
    "        img = cv2.imread(f)\n",
    "        pose_result = pose_model.inference_from_bbox(img,d)\n",
    "        if pose_result is None:\n",
    "            for person_id in range(num_person):\n",
    "                kp[person_id,i] = kp[person_id,i-1]\n",
    "        else:\n",
    "            for j,item in enumerate(pose_result):\n",
    "                kp [j,i] = item[\"keypoints\"]            \n",
    "        # if len(d[2]) == 0:\n",
    "        #     for person_id in range(num_person):\n",
    "        #         kp[person_id,i] = kp[person_id,i-1]\n",
    "        #     prog_bar.update()\n",
    "        #     continue\n",
    "        vis_image = vis_pose(img,pose_result)\n",
    "        cv2.imshow('',vis_image)\n",
    "        if cv2.waitKey(20)& 0xFF==ord('q'): break\n",
    "        prog_bar.update()\n",
    "    cv2.destroyAllWindows()\n",
    "    return kp\n",
    "\n",
    "def pose_extraction(vid,label,pose_model:Hrnet=pose_model,det_model:Yolov7=det_model,det_score=0.5):\n",
    "    frame_paths = extract_frame(vid)\n",
    "    det_results = detection_inference(det_model,frame_paths,det_score)\n",
    "    img = cv2.imread(frame_paths[0])\n",
    "    img_shape = (img.shape[1],img.shape[0])\n",
    "    pose_results = pose_inference(pose_model,frame_paths,det_results)\n",
    "    anno = dict()\n",
    "    anno['kp'] = pose_results\n",
    "    anno['img_shape'] = img_shape\n",
    "    anno['total_frames'] = pose_results.shape[1]\n",
    "    anno['label'] = label\n",
    "    shutil.rmtree(osp.dirname(frame_paths[0]))\n",
    "    return anno\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TRAIN/FALL\\Data_fall_1.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 133/133, 40.5 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 133/133, 25.1 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_10.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 114/114, 38.9 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 114/114, 20.8 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_100.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 167/167, 41.8 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[                                                  ] 0/167, elapsed: 0s, ETA:Processing TRAIN/FALL\\Data_fall_101.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 341/341, 41.8 task/s, elapsed: 8s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 341/341, 27.6 task/s, elapsed: 12s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_102.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 107/107, 39.3 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 107/107, 24.0 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_103.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 132/132, 43.3 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 132/132, 23.5 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_104.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 103/103, 39.9 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 103/103, 24.0 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_106.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 49/49, 39.3 task/s, elapsed: 1s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 49/49, 21.8 task/s, elapsed: 2s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_107.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 93/93, 42.6 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 93/93, 20.6 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_108.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 75/75, 44.9 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 75/75, 25.7 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_109.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 93/93, 39.9 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 93/93, 20.9 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_110.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 63/63, 41.0 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 63/63, 22.2 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_111.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 130/130, 39.0 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 130/130, 18.7 task/s, elapsed: 7s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_112.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 127/127, 38.4 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 127/127, 21.3 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_113.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 37.8 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 20.5 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_114.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 115/115, 40.6 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 115/115, 21.4 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_116.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 107/107, 42.7 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 107/107, 21.4 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_117.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 83/83, 43.9 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 83/83, 25.5 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_118.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 57/57, 39.0 task/s, elapsed: 1s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 57/57, 24.9 task/s, elapsed: 2s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_12.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 233/233, 40.7 task/s, elapsed: 6s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 233/233, 23.1 task/s, elapsed: 10s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_121.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 123/123, 40.6 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 123/123, 25.3 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_122.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 38.9 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 26.0 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_123.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 88/88, 38.0 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[                                                  ] 0/88, elapsed: 0s, ETA:Processing TRAIN/FALL\\Data_fall_124.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 104/104, 39.9 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 104/104, 24.1 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_125.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 105/105, 38.8 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 105/105, 23.8 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_127.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 122/122, 37.8 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 122/122, 24.6 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_13.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 57/57, 37.4 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 57/57, 18.5 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_130.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 85/85, 42.2 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 85/85, 25.0 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_131.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 198/198, 39.8 task/s, elapsed: 5s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 198/198, 26.0 task/s, elapsed: 8s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_132.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 116/116, 38.8 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 116/116, 22.3 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_133.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 117/117, 42.4 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 117/117, 22.3 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_134.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 107/107, 41.7 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 107/107, 26.3 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_135.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 162/162, 38.6 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 162/162, 22.1 task/s, elapsed: 7s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_136.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 163/163, 42.5 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 163/163, 27.3 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_137.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 180/180, 39.2 task/s, elapsed: 5s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 180/180, 21.9 task/s, elapsed: 8s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_138.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 147/147, 42.0 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 147/147, 26.7 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_14.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 139/139, 40.1 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 139/139, 22.7 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_141.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 123/123, 42.6 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 123/123, 21.4 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_142.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 98/98, 42.6 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 98/98, 22.0 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_146.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 105/105, 42.0 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 105/105, 21.1 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_147.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 173/173, 42.6 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 173/173, 22.8 task/s, elapsed: 8s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_148.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 142/142, 39.1 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 142/142, 25.1 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_149.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 120/120, 40.0 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 120/120, 22.9 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_15.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 117/117, 40.1 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 117/117, 22.6 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_150.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 127/127, 41.9 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 127/127, 22.9 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_151.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 136/136, 37.9 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 136/136, 22.3 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_152.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 109/109, 39.2 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 109/109, 23.3 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_153.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 124/124, 39.1 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 124/124, 25.5 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_154.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 76/76, 38.4 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 76/76, 22.4 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_155.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 108/108, 41.2 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 108/108, 21.4 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_157.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 121/121, 42.5 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 121/121, 24.8 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_158.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 76/76, 38.9 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 76/76, 23.7 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_159.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 95/95, 38.3 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 95/95, 23.9 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_16.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 42.5 task/s, elapsed: 1s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 40/40, 26.2 task/s, elapsed: 2s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_160.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 106/106, 38.8 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 106/106, 22.8 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_161.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 100/100, 40.7 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 100/100, 22.6 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_163.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 77/77, 40.8 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 77/77, 22.7 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_164.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 101/101, 40.5 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 101/101, 23.2 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_165.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 154/154, 39.4 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 154/154, 22.2 task/s, elapsed: 7s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_166.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 111/111, 37.8 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 111/111, 25.7 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_167.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 144/144, 37.5 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 144/144, 26.0 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_168.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 123/123, 38.9 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 123/123, 20.7 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_169.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 160/160, 41.0 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 160/160, 23.3 task/s, elapsed: 7s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_17.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 90/90, 38.7 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 90/90, 20.7 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_170.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 154/154, 39.1 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 154/154, 24.8 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_172.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 124/124, 38.2 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 124/124, 22.9 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_173.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 98/98, 38.4 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 98/98, 24.9 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_174.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 124/124, 37.9 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 124/124, 24.2 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_175.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 156/156, 38.6 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 156/156, 26.8 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_176.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 112/112, 38.0 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[                                                  ] 0/112, elapsed: 0s, ETA:Processing TRAIN/FALL\\Data_fall_177.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 102/102, 39.3 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 102/102, 23.1 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_178.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 104/104, 39.6 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 104/104, 31.0 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_179.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 87/87, 38.3 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 87/87, 30.1 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_181.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 122/122, 38.4 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 122/122, 28.9 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_182.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 130/130, 38.4 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[                                                  ] 0/130, elapsed: 0s, ETA:Processing TRAIN/FALL\\Data_fall_183.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 104/104, 39.5 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 104/104, 24.4 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_184.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 134/134, 38.7 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 134/134, 23.4 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_185.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 111/111, 39.4 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 111/111, 28.0 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_186.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 87/87, 39.0 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[                                                  ] 0/87, elapsed: 0s, ETA:Processing TRAIN/FALL\\Data_fall_187.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 81/81, 39.3 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[                                                  ] 0/81, elapsed: 0s, ETA:Processing TRAIN/FALL\\Data_fall_189.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 108/108, 40.3 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 108/108, 25.4 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_19.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 144/144, 39.6 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 144/144, 21.4 task/s, elapsed: 7s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_194.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 128/128, 38.7 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 128/128, 24.2 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_195.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 91/91, 39.0 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 91/91, 25.8 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_198.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 194/194, 39.7 task/s, elapsed: 5s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 194/194, 23.4 task/s, elapsed: 8s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_199.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 100/100, 39.0 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 100/100, 23.6 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_2.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 38.9 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 22.5 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_20.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 76/76, 42.6 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 76/76, 23.2 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_200.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 122/122, 42.7 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 122/122, 25.6 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_21.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 139/139, 39.8 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 139/139, 21.6 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_22.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 121/121, 40.5 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 121/121, 23.6 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_23.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 54/54, 42.1 task/s, elapsed: 1s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 54/54, 22.7 task/s, elapsed: 2s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_25.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 112/112, 39.1 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 112/112, 21.4 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_26.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 81/81, 42.9 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 81/81, 22.9 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_27.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 103/103, 38.7 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 103/103, 22.3 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_3.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 72/72, 40.1 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 72/72, 20.4 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_30.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 103/103, 41.6 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 103/103, 21.3 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_32.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 166/166, 40.3 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 166/166, 22.5 task/s, elapsed: 7s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_33.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 143/143, 39.3 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 143/143, 20.2 task/s, elapsed: 7s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_35.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 39.7 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 21.0 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_36.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 72/72, 43.4 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 72/72, 24.2 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_39.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 103/103, 40.0 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 103/103, 25.0 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_4.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 236/236, 39.1 task/s, elapsed: 6s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 236/236, 25.0 task/s, elapsed: 9s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_40.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 112/112, 38.2 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 112/112, 21.9 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_42.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 72/72, 42.7 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 72/72, 20.4 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_43.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 40.2 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 21.1 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_44.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 49/49, 39.2 task/s, elapsed: 1s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 49/49, 22.5 task/s, elapsed: 2s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_45.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 76/76, 40.1 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 76/76, 20.9 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_46.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 103/103, 37.4 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 103/103, 20.9 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_47.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 144/144, 41.8 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 144/144, 20.8 task/s, elapsed: 7s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_49.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 62/62, 43.8 task/s, elapsed: 1s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 62/62, 22.1 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_5.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 202/202, 40.1 task/s, elapsed: 5s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 202/202, 21.2 task/s, elapsed: 10s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_50.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 72/72, 37.3 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 72/72, 26.0 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_52.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 144/144, 34.9 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 144/144, 22.6 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_53.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 130/130, 37.4 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 130/130, 21.8 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_54.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 112/112, 35.2 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 112/112, 23.4 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_55.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 71/71, 33.2 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 71/71, 19.7 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_56.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 143/143, 38.0 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 143/143, 23.3 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_58.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 117/117, 36.7 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 117/117, 21.1 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_60.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 90/90, 35.5 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 90/90, 23.4 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_61.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 89/89, 29.4 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 89/89, 21.2 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_65.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 194/194, 33.7 task/s, elapsed: 6s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 194/194, 22.7 task/s, elapsed: 9s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_68.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 164/164, 27.7 task/s, elapsed: 6s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 164/164, 23.3 task/s, elapsed: 7s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_69.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 226/226, 34.8 task/s, elapsed: 7s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 226/226, 23.6 task/s, elapsed: 10s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_7.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 139/139, 33.7 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 139/139, 19.9 task/s, elapsed: 7s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_71.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 37.7 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 24.3 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_72.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 173/173, 31.8 task/s, elapsed: 5s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 173/173, 25.0 task/s, elapsed: 7s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_73.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 125/125, 29.7 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 125/125, 20.3 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_74.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 131/131, 32.4 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 131/131, 22.0 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_75.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 152/152, 26.4 task/s, elapsed: 6s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 152/152, 21.4 task/s, elapsed: 7s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_77.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 174/174, 25.3 task/s, elapsed: 7s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 174/174, 20.3 task/s, elapsed: 9s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_78.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 138/138, 28.6 task/s, elapsed: 5s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 138/138, 23.4 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_79.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 161/161, 35.9 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 161/161, 20.0 task/s, elapsed: 8s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_81.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 142/142, 35.7 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 142/142, 20.5 task/s, elapsed: 7s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_82.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 77/77, 32.3 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 77/77, 19.1 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_83.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 64/64, 29.1 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 64/64, 17.1 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_84.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 85/85, 33.8 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 85/85, 19.8 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_85.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 128/128, 37.0 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 128/128, 24.4 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_86.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 65/65, 31.2 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 65/65, 17.5 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_87.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 109/109, 32.8 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 109/109, 18.8 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_88.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 130/130, 32.5 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 130/130, 21.0 task/s, elapsed: 6s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_89.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 140/140, 38.3 task/s, elapsed: 4s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 140/140, 29.3 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_91.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 56/56, 39.1 task/s, elapsed: 1s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 56/56, 22.5 task/s, elapsed: 2s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_92.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 58/58, 34.3 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 58/58, 19.3 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_93.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 59/59, 39.3 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 59/59, 20.8 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_94.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 94/94, 36.8 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 94/94, 22.7 task/s, elapsed: 4s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_95.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 57/57, 35.5 task/s, elapsed: 2s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 57/57, 18.6 task/s, elapsed: 3s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_96.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 131/131, 39.9 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 131/131, 28.0 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_97.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 109/109, 34.1 task/s, elapsed: 3s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 109/109, 20.5 task/s, elapsed: 5s, ETA:     0sProcessing TRAIN/FALL\\Data_fall_98.mp4\n",
      "Performing Human Detection for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 42/42, 32.2 task/s, elapsed: 1s, ETA:     0sPerforming Human Pose Estimation for each frame\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 42/42, 16.3 task/s, elapsed: 3s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "\n",
    "# files=glob.glob('VIDEO_TEST/*.mp4')\n",
    "# file='VIDEO_TEST/VIDEO11.mp4'\n",
    "lstfile = []\n",
    "# lstfile.append(sorted(glob.glob('TRAIN/NOT FALL/*.mp4'),key=os.path.getmtime))\n",
    "lstfile.append(sorted(glob.glob('TRAIN/FALL/*.mp4'),key=os.path.getmtime))\n",
    "# lstfile.append(sorted(glob.glob('Video_Lying/*.mp4'),key=os.path.getmtime))\n",
    "# lstfile=sorted(key=os.path.getmtime)\n",
    "anno_train = []\n",
    "for index,files in enumerate(lstfile):\n",
    "    for file in files:\n",
    "        print('Processing ' + file)\n",
    "        anno = pose_extraction(file,1,det_score=0.8) #LABEL NOT_FALL\n",
    "        anno_train.append(anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmcv.dump(anno,'Data/Fall.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file='C:/Users/PhuTuan/Downloads/Video/Data_fall_171.mp4'\n",
    "# # anno = pose_extraction(file,0,det_score=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_paths = extract_frame(file)\n",
    "# det_results = detection_inference(yolov7,frame_paths,0.8)\n",
    "# img = cv2.imread(frame_paths[0])\n",
    "# img_shape = (img.shape[1],img.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose_results = pose_inference(hrnet,frame_paths,det_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anno = dict()\n",
    "# anno['kp'] = pose_results\n",
    "# anno['img_shape'] = img_shape\n",
    "# anno['total_frames'] = pose_results.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# det_results[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_paths = extract_frame(file)\n",
    "# det_results = detection_inference(yolov7,frame_paths,0.8)\n",
    "# img = cv2.imread(frame_paths[0])\n",
    "# img_shape = (img.shape[1],img.shape[0])\n",
    "# pose_results = pose_inference(hrnet,frame_paths,det_results)\n",
    "# anno = dict()\n",
    "# anno['kp'] = pose_results\n",
    "# anno['img_shape'] = img_shape\n",
    "# anno['total_frames'] = pose_results.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(frame_paths[71])\n",
    "# result = yolov7.inference(img,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result[2] == 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
